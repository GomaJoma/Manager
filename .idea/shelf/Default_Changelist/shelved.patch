Index: venv/Lib/site-packages/django/contrib/gis/sitemaps/kml.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/gis/sitemaps/kml.py b/venv/Lib/site-packages/django/contrib/gis/sitemaps/kml.py
new file mode 100644
--- /dev/null	(date 1617030484461)
+++ b/venv/Lib/site-packages/django/contrib/gis/sitemaps/kml.py	(date 1617030484461)
@@ -0,0 +1,70 @@
+from django.apps import apps
+from django.contrib.gis.db.models import GeometryField
+from django.contrib.sitemaps import Sitemap
+from django.db import models
+from django.urls import reverse
+
+
+class KMLSitemap(Sitemap):
+    """
+    A minimal hook to produce KML sitemaps.
+    """
+    geo_format = 'kml'
+
+    def __init__(self, locations=None):
+        # If no locations specified, then we try to build for
+        # every model in installed applications.
+        self.locations = self._build_kml_sources(locations)
+
+    def _build_kml_sources(self, sources):
+        """
+        Go through the given sources and return a 3-tuple of the application
+        label, module name, and field name of every GeometryField encountered
+        in the sources.
+
+        If no sources are provided, then all models.
+        """
+        kml_sources = []
+        if sources is None:
+            sources = apps.get_models()
+        for source in sources:
+            if isinstance(source, models.base.ModelBase):
+                for field in source._meta.fields:
+                    if isinstance(field, GeometryField):
+                        kml_sources.append((source._meta.app_label,
+                                            source._meta.model_name,
+                                            field.name))
+            elif isinstance(source, (list, tuple)):
+                if len(source) != 3:
+                    raise ValueError('Must specify a 3-tuple of (app_label, module_name, field_name).')
+                kml_sources.append(source)
+            else:
+                raise TypeError('KML Sources must be a model or a 3-tuple.')
+        return kml_sources
+
+    def get_urls(self, page=1, site=None, protocol=None):
+        """
+        This method is overridden so the appropriate `geo_format` attribute
+        is placed on each URL element.
+        """
+        urls = Sitemap.get_urls(self, page=page, site=site, protocol=protocol)
+        for url in urls:
+            url['geo_format'] = self.geo_format
+        return urls
+
+    def items(self):
+        return self.locations
+
+    def location(self, obj):
+        return reverse(
+            'django.contrib.gis.sitemaps.views.%s' % self.geo_format,
+            kwargs={
+                'label': obj[0],
+                'model': obj[1],
+                'field_name': obj[2],
+            },
+        )
+
+
+class KMZSitemap(KMLSitemap):
+    geo_format = 'kmz'
Index: venv/Lib/site-packages/django/conf/locale/fy/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/fy/formats.py b/venv/Lib/site-packages/django/conf/locale/fy/formats.py
new file mode 100644
--- /dev/null	(date 1617030482510)
+++ b/venv/Lib/site-packages/django/conf/locale/fy/formats.py	(date 1617030482510)
@@ -0,0 +1,21 @@
+# This file is distributed under the same license as the Django package.
+#
+# The *_FORMAT strings use the Django date format syntax,
+# see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date
+# DATE_FORMAT =
+# TIME_FORMAT =
+# DATETIME_FORMAT =
+# YEAR_MONTH_FORMAT =
+# MONTH_DAY_FORMAT =
+# SHORT_DATE_FORMAT =
+# SHORT_DATETIME_FORMAT =
+# FIRST_DAY_OF_WEEK =
+
+# The *_INPUT_FORMATS strings use the Python strftime format syntax,
+# see https://docs.python.org/library/datetime.html#strftime-strptime-behavior
+# DATE_INPUT_FORMATS =
+# TIME_INPUT_FORMATS =
+# DATETIME_INPUT_FORMATS =
+# DECIMAL_SEPARATOR =
+# THOUSAND_SEPARATOR =
+# NUMBER_GROUPING =
Index: venv/Lib/site-packages/django/contrib/gis/sitemaps/views.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/gis/sitemaps/views.py b/venv/Lib/site-packages/django/contrib/gis/sitemaps/views.py
new file mode 100644
--- /dev/null	(date 1617030484461)
+++ b/venv/Lib/site-packages/django/contrib/gis/sitemaps/views.py	(date 1617030484461)
@@ -0,0 +1,61 @@
+from django.apps import apps
+from django.contrib.gis.db.models import GeometryField
+from django.contrib.gis.db.models.functions import AsKML, Transform
+from django.contrib.gis.shortcuts import render_to_kml, render_to_kmz
+from django.core.exceptions import FieldDoesNotExist
+from django.db import DEFAULT_DB_ALIAS, connections
+from django.http import Http404
+
+
+def kml(request, label, model, field_name=None, compress=False, using=DEFAULT_DB_ALIAS):
+    """
+    This view generates KML for the given app label, model, and field name.
+
+    The field name must be that of a geographic field.
+    """
+    placemarks = []
+    try:
+        klass = apps.get_model(label, model)
+    except LookupError:
+        raise Http404('You must supply a valid app label and module name.  Got "%s.%s"' % (label, model))
+
+    if field_name:
+        try:
+            field = klass._meta.get_field(field_name)
+            if not isinstance(field, GeometryField):
+                raise FieldDoesNotExist
+        except FieldDoesNotExist:
+            raise Http404('Invalid geometry field.')
+
+    connection = connections[using]
+
+    if connection.features.has_AsKML_function:
+        # Database will take care of transformation.
+        placemarks = klass._default_manager.using(using).annotate(kml=AsKML(field_name))
+    else:
+        # If the database offers no KML method, we use the `kml`
+        # attribute of the lazy geometry instead.
+        placemarks = []
+        if connection.features.has_Transform_function:
+            qs = klass._default_manager.using(using).annotate(
+                **{'%s_4326' % field_name: Transform(field_name, 4326)})
+            field_name += '_4326'
+        else:
+            qs = klass._default_manager.using(using).all()
+        for mod in qs:
+            mod.kml = getattr(mod, field_name).kml
+            placemarks.append(mod)
+
+    # Getting the render function and rendering to the correct.
+    if compress:
+        render = render_to_kmz
+    else:
+        render = render_to_kml
+    return render('gis/kml/placemarks.kml', {'places': placemarks})
+
+
+def kmz(request, label, model, field_name=None, using=DEFAULT_DB_ALIAS):
+    """
+    Return KMZ for the given app label, model, and field name.
+    """
+    return kml(request, label, model, field_name, compress=True, using=using)
Index: venv/Lib/site-packages/django/contrib/gis/sitemaps/__init__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/gis/sitemaps/__init__.py b/venv/Lib/site-packages/django/contrib/gis/sitemaps/__init__.py
new file mode 100644
--- /dev/null	(date 1617030484461)
+++ b/venv/Lib/site-packages/django/contrib/gis/sitemaps/__init__.py	(date 1617030484461)
@@ -0,0 +1,4 @@
+# Geo-enabled Sitemap classes.
+from django.contrib.gis.sitemaps.kml import KMLSitemap, KMZSitemap
+
+__all__ = ['KMLSitemap', 'KMZSitemap']
Index: venv/Lib/site-packages/django/conf/locale/ga/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/ga/formats.py b/venv/Lib/site-packages/django/conf/locale/ga/formats.py
new file mode 100644
--- /dev/null	(date 1617030482512)
+++ b/venv/Lib/site-packages/django/conf/locale/ga/formats.py	(date 1617030482512)
@@ -0,0 +1,21 @@
+# This file is distributed under the same license as the Django package.
+#
+# The *_FORMAT strings use the Django date format syntax,
+# see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date
+DATE_FORMAT = 'j F Y'
+TIME_FORMAT = 'H:i'
+# DATETIME_FORMAT =
+# YEAR_MONTH_FORMAT =
+MONTH_DAY_FORMAT = 'j F'
+SHORT_DATE_FORMAT = 'j M Y'
+# SHORT_DATETIME_FORMAT =
+# FIRST_DAY_OF_WEEK =
+
+# The *_INPUT_FORMATS strings use the Python strftime format syntax,
+# see https://docs.python.org/library/datetime.html#strftime-strptime-behavior
+# DATE_INPUT_FORMATS =
+# TIME_INPUT_FORMATS =
+# DATETIME_INPUT_FORMATS =
+DECIMAL_SEPARATOR = '.'
+THOUSAND_SEPARATOR = ','
+# NUMBER_GROUPING =
Index: venv/Lib/site-packages/django/conf/locale/gd/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/gd/formats.py b/venv/Lib/site-packages/django/conf/locale/gd/formats.py
new file mode 100644
--- /dev/null	(date 1617030482513)
+++ b/venv/Lib/site-packages/django/conf/locale/gd/formats.py	(date 1617030482513)
@@ -0,0 +1,21 @@
+# This file is distributed under the same license as the Django package.
+#
+# The *_FORMAT strings use the Django date format syntax,
+# see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date
+DATE_FORMAT = 'j F Y'
+TIME_FORMAT = 'h:ia'
+DATETIME_FORMAT = 'j F Y h:ia'
+# YEAR_MONTH_FORMAT =
+MONTH_DAY_FORMAT = 'j F'
+SHORT_DATE_FORMAT = 'j M Y'
+SHORT_DATETIME_FORMAT = 'j M Y h:ia'
+FIRST_DAY_OF_WEEK = 1  # Monday
+
+# The *_INPUT_FORMATS strings use the Python strftime format syntax,
+# see https://docs.python.org/library/datetime.html#strftime-strptime-behavior
+# DATE_INPUT_FORMATS =
+# TIME_INPUT_FORMATS =
+# DATETIME_INPUT_FORMATS =
+DECIMAL_SEPARATOR = '.'
+THOUSAND_SEPARATOR = ','
+# NUMBER_GROUPING =
Index: venv/Lib/site-packages/django/conf/locale/gl/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/gl/formats.py b/venv/Lib/site-packages/django/conf/locale/gl/formats.py
new file mode 100644
--- /dev/null	(date 1617030482515)
+++ b/venv/Lib/site-packages/django/conf/locale/gl/formats.py	(date 1617030482515)
@@ -0,0 +1,21 @@
+# This file is distributed under the same license as the Django package.
+#
+# The *_FORMAT strings use the Django date format syntax,
+# see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date
+DATE_FORMAT = r'j \d\e F \d\e Y'
+TIME_FORMAT = 'H:i'
+DATETIME_FORMAT = r'j \d\e F \d\e Y \á\s H:i'
+YEAR_MONTH_FORMAT = r'F \d\e Y'
+MONTH_DAY_FORMAT = r'j \d\e F'
+SHORT_DATE_FORMAT = 'd-m-Y'
+SHORT_DATETIME_FORMAT = 'd-m-Y, H:i'
+FIRST_DAY_OF_WEEK = 1  # Monday
+
+# The *_INPUT_FORMATS strings use the Python strftime format syntax,
+# see https://docs.python.org/library/datetime.html#strftime-strptime-behavior
+# DATE_INPUT_FORMATS =
+# TIME_INPUT_FORMATS =
+# DATETIME_INPUT_FORMATS =
+DECIMAL_SEPARATOR = ','
+THOUSAND_SEPARATOR = '.'
+# NUMBER_GROUPING =
Index: venv/Lib/site-packages/django/contrib/gis/serializers/geojson.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/gis/serializers/geojson.py b/venv/Lib/site-packages/django/contrib/gis/serializers/geojson.py
new file mode 100644
--- /dev/null	(date 1617030484460)
+++ b/venv/Lib/site-packages/django/contrib/gis/serializers/geojson.py	(date 1617030484460)
@@ -0,0 +1,67 @@
+from django.contrib.gis.gdal import CoordTransform, SpatialReference
+from django.core.serializers.base import SerializerDoesNotExist
+from django.core.serializers.json import Serializer as JSONSerializer
+
+
+class Serializer(JSONSerializer):
+    """
+    Convert a queryset to GeoJSON, http://geojson.org/
+    """
+    def _init_options(self):
+        super()._init_options()
+        self.geometry_field = self.json_kwargs.pop('geometry_field', None)
+        self.srid = self.json_kwargs.pop('srid', 4326)
+        if (self.selected_fields is not None and self.geometry_field is not None and
+                self.geometry_field not in self.selected_fields):
+            self.selected_fields = [*self.selected_fields, self.geometry_field]
+
+    def start_serialization(self):
+        self._init_options()
+        self._cts = {}  # cache of CoordTransform's
+        self.stream.write(
+            '{"type": "FeatureCollection", "crs": {"type": "name", "properties": {"name": "EPSG:%d"}},'
+            ' "features": [' % self.srid)
+
+    def end_serialization(self):
+        self.stream.write(']}')
+
+    def start_object(self, obj):
+        super().start_object(obj)
+        self._geometry = None
+        if self.geometry_field is None:
+            # Find the first declared geometry field
+            for field in obj._meta.fields:
+                if hasattr(field, 'geom_type'):
+                    self.geometry_field = field.name
+                    break
+
+    def get_dump_object(self, obj):
+        data = {
+            "type": "Feature",
+            "properties": self._current,
+        }
+        if ((self.selected_fields is None or 'pk' in self.selected_fields) and
+                'pk' not in data["properties"]):
+            data["properties"]["pk"] = obj._meta.pk.value_to_string(obj)
+        if self._geometry:
+            if self._geometry.srid != self.srid:
+                # If needed, transform the geometry in the srid of the global geojson srid
+                if self._geometry.srid not in self._cts:
+                    srs = SpatialReference(self.srid)
+                    self._cts[self._geometry.srid] = CoordTransform(self._geometry.srs, srs)
+                self._geometry.transform(self._cts[self._geometry.srid])
+            data["geometry"] = eval(self._geometry.geojson)
+        else:
+            data["geometry"] = None
+        return data
+
+    def handle_field(self, obj, field):
+        if field.name == self.geometry_field:
+            self._geometry = field.value_from_object(obj)
+        else:
+            super().handle_field(obj, field)
+
+
+class Deserializer:
+    def __init__(self, *args, **kwargs):
+        raise SerializerDoesNotExist("geojson is a serialization-only serializer")
Index: venv/Lib/site-packages/django/conf/locale/he/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/he/formats.py b/venv/Lib/site-packages/django/conf/locale/he/formats.py
new file mode 100644
--- /dev/null	(date 1617030482517)
+++ b/venv/Lib/site-packages/django/conf/locale/he/formats.py	(date 1617030482517)
@@ -0,0 +1,21 @@
+# This file is distributed under the same license as the Django package.
+#
+# The *_FORMAT strings use the Django date format syntax,
+# see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date
+DATE_FORMAT = 'j בF Y'
+TIME_FORMAT = 'H:i'
+DATETIME_FORMAT = 'j בF Y H:i'
+YEAR_MONTH_FORMAT = 'F Y'
+MONTH_DAY_FORMAT = 'j בF'
+SHORT_DATE_FORMAT = 'd/m/Y'
+SHORT_DATETIME_FORMAT = 'd/m/Y H:i'
+# FIRST_DAY_OF_WEEK =
+
+# The *_INPUT_FORMATS strings use the Python strftime format syntax,
+# see https://docs.python.org/library/datetime.html#strftime-strptime-behavior
+# DATE_INPUT_FORMATS =
+# TIME_INPUT_FORMATS =
+# DATETIME_INPUT_FORMATS =
+DECIMAL_SEPARATOR = '.'
+THOUSAND_SEPARATOR = ','
+# NUMBER_GROUPING =
Index: venv/Lib/site-packages/django/conf/locale/hi/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/hi/formats.py b/venv/Lib/site-packages/django/conf/locale/hi/formats.py
new file mode 100644
--- /dev/null	(date 1617030482518)
+++ b/venv/Lib/site-packages/django/conf/locale/hi/formats.py	(date 1617030482518)
@@ -0,0 +1,21 @@
+# This file is distributed under the same license as the Django package.
+#
+# The *_FORMAT strings use the Django date format syntax,
+# see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date
+DATE_FORMAT = 'j F Y'
+TIME_FORMAT = 'g:i A'
+# DATETIME_FORMAT =
+# YEAR_MONTH_FORMAT =
+MONTH_DAY_FORMAT = 'j F'
+SHORT_DATE_FORMAT = 'd-m-Y'
+# SHORT_DATETIME_FORMAT =
+# FIRST_DAY_OF_WEEK =
+
+# The *_INPUT_FORMATS strings use the Python strftime format syntax,
+# see https://docs.python.org/library/datetime.html#strftime-strptime-behavior
+# DATE_INPUT_FORMATS =
+# TIME_INPUT_FORMATS =
+# DATETIME_INPUT_FORMATS =
+DECIMAL_SEPARATOR = '.'
+THOUSAND_SEPARATOR = ','
+# NUMBER_GROUPING =
Index: venv/Lib/site-packages/django/conf/locale/hr/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/hr/formats.py b/venv/Lib/site-packages/django/conf/locale/hr/formats.py
new file mode 100644
--- /dev/null	(date 1617030482520)
+++ b/venv/Lib/site-packages/django/conf/locale/hr/formats.py	(date 1617030482520)
@@ -0,0 +1,42 @@
+# This file is distributed under the same license as the Django package.
+#
+# The *_FORMAT strings use the Django date format syntax,
+# see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date
+DATE_FORMAT = 'j. E Y.'
+TIME_FORMAT = 'H:i'
+DATETIME_FORMAT = 'j. E Y. H:i'
+YEAR_MONTH_FORMAT = 'F Y.'
+MONTH_DAY_FORMAT = 'j. F'
+SHORT_DATE_FORMAT = 'j.m.Y.'
+SHORT_DATETIME_FORMAT = 'j.m.Y. H:i'
+FIRST_DAY_OF_WEEK = 1
+
+# The *_INPUT_FORMATS strings use the Python strftime format syntax,
+# see https://docs.python.org/library/datetime.html#strftime-strptime-behavior
+# Kept ISO formats as they are in first position
+DATE_INPUT_FORMATS = [
+    '%Y-%m-%d',                     # '2006-10-25'
+    '%d.%m.%Y.', '%d.%m.%y.',       # '25.10.2006.', '25.10.06.'
+    '%d. %m. %Y.', '%d. %m. %y.',   # '25. 10. 2006.', '25. 10. 06.'
+]
+DATETIME_INPUT_FORMATS = [
+    '%Y-%m-%d %H:%M:%S',        # '2006-10-25 14:30:59'
+    '%Y-%m-%d %H:%M:%S.%f',     # '2006-10-25 14:30:59.000200'
+    '%Y-%m-%d %H:%M',           # '2006-10-25 14:30'
+    '%d.%m.%Y. %H:%M:%S',       # '25.10.2006. 14:30:59'
+    '%d.%m.%Y. %H:%M:%S.%f',    # '25.10.2006. 14:30:59.000200'
+    '%d.%m.%Y. %H:%M',          # '25.10.2006. 14:30'
+    '%d.%m.%y. %H:%M:%S',       # '25.10.06. 14:30:59'
+    '%d.%m.%y. %H:%M:%S.%f',    # '25.10.06. 14:30:59.000200'
+    '%d.%m.%y. %H:%M',          # '25.10.06. 14:30'
+    '%d. %m. %Y. %H:%M:%S',     # '25. 10. 2006. 14:30:59'
+    '%d. %m. %Y. %H:%M:%S.%f',  # '25. 10. 2006. 14:30:59.000200'
+    '%d. %m. %Y. %H:%M',        # '25. 10. 2006. 14:30'
+    '%d. %m. %y. %H:%M:%S',     # '25. 10. 06. 14:30:59'
+    '%d. %m. %y. %H:%M:%S.%f',  # '25. 10. 06. 14:30:59.000200'
+    '%d. %m. %y. %H:%M',        # '25. 10. 06. 14:30'
+]
+
+DECIMAL_SEPARATOR = ','
+THOUSAND_SEPARATOR = '.'
+NUMBER_GROUPING = 3
Index: venv/Lib/site-packages/django/conf/locale/hu/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/hu/formats.py b/venv/Lib/site-packages/django/conf/locale/hu/formats.py
new file mode 100644
--- /dev/null	(date 1617030482523)
+++ b/venv/Lib/site-packages/django/conf/locale/hu/formats.py	(date 1617030482523)
@@ -0,0 +1,30 @@
+# This file is distributed under the same license as the Django package.
+#
+# The *_FORMAT strings use the Django date format syntax,
+# see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date
+DATE_FORMAT = 'Y. F j.'
+TIME_FORMAT = 'H:i'
+DATETIME_FORMAT = 'Y. F j. H:i'
+YEAR_MONTH_FORMAT = 'Y. F'
+MONTH_DAY_FORMAT = 'F j.'
+SHORT_DATE_FORMAT = 'Y.m.d.'
+SHORT_DATETIME_FORMAT = 'Y.m.d. H:i'
+FIRST_DAY_OF_WEEK = 1  # Monday
+
+# The *_INPUT_FORMATS strings use the Python strftime format syntax,
+# see https://docs.python.org/library/datetime.html#strftime-strptime-behavior
+DATE_INPUT_FORMATS = [
+    '%Y.%m.%d.',  # '2006.10.25.'
+]
+TIME_INPUT_FORMATS = [
+    '%H:%M:%S',  # '14:30:59'
+    '%H:%M',    # '14:30'
+]
+DATETIME_INPUT_FORMATS = [
+    '%Y.%m.%d. %H:%M:%S',   # '2006.10.25. 14:30:59'
+    '%Y.%m.%d. %H:%M:%S.%f',  # '2006.10.25. 14:30:59.000200'
+    '%Y.%m.%d. %H:%M',      # '2006.10.25. 14:30'
+]
+DECIMAL_SEPARATOR = ','
+THOUSAND_SEPARATOR = ' '  # Non-breaking space
+NUMBER_GROUPING = 3
Index: venv/Lib/site-packages/django/conf/locale/id/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/id/formats.py b/venv/Lib/site-packages/django/conf/locale/id/formats.py
new file mode 100644
--- /dev/null	(date 1617030482527)
+++ b/venv/Lib/site-packages/django/conf/locale/id/formats.py	(date 1617030482527)
@@ -0,0 +1,46 @@
+# This file is distributed under the same license as the Django package.
+#
+# The *_FORMAT strings use the Django date format syntax,
+# see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date
+DATE_FORMAT = 'j N Y'
+DATETIME_FORMAT = "j N Y, G.i"
+TIME_FORMAT = 'G.i'
+YEAR_MONTH_FORMAT = 'F Y'
+MONTH_DAY_FORMAT = 'j F'
+SHORT_DATE_FORMAT = 'd-m-Y'
+SHORT_DATETIME_FORMAT = 'd-m-Y G.i'
+FIRST_DAY_OF_WEEK = 1  # Monday
+
+# The *_INPUT_FORMATS strings use the Python strftime format syntax,
+# see https://docs.python.org/library/datetime.html#strftime-strptime-behavior
+DATE_INPUT_FORMATS = [
+    '%d-%m-%Y', '%d/%m/%Y',             # '25-10-2009', 25/10/2009'
+    '%d-%m-%y', '%d/%m/%y',             # '25-10-09', 25/10/09'
+    '%d %b %Y',                         # '25 Oct 2006',
+    '%d %B %Y',                         # '25 October 2006'
+    '%m/%d/%y', '%m/%d/%Y',             # '10/25/06', '10/25/2009'
+]
+
+TIME_INPUT_FORMATS = [
+    '%H.%M.%S',                         # '14.30.59'
+    '%H.%M',                            # '14.30'
+]
+
+DATETIME_INPUT_FORMATS = [
+    '%d-%m-%Y %H.%M.%S',                # '25-10-2009 14.30.59'
+    '%d-%m-%Y %H.%M.%S.%f',             # '25-10-2009 14.30.59.000200'
+    '%d-%m-%Y %H.%M',                   # '25-10-2009 14.30'
+    '%d-%m-%y %H.%M.%S',                # '25-10-09' 14.30.59'
+    '%d-%m-%y %H.%M.%S.%f',             # '25-10-09' 14.30.59.000200'
+    '%d-%m-%y %H.%M',                   # '25-10-09' 14.30'
+    '%m/%d/%y %H.%M.%S',                # '10/25/06 14.30.59'
+    '%m/%d/%y %H.%M.%S.%f',             # '10/25/06 14.30.59.000200'
+    '%m/%d/%y %H.%M',                   # '10/25/06 14.30'
+    '%m/%d/%Y %H.%M.%S',                # '25/10/2009 14.30.59'
+    '%m/%d/%Y %H.%M.%S.%f',             # '25/10/2009 14.30.59.000200'
+    '%m/%d/%Y %H.%M',                   # '25/10/2009 14.30'
+]
+
+DECIMAL_SEPARATOR = ','
+THOUSAND_SEPARATOR = '.'
+NUMBER_GROUPING = 3
Index: venv/Lib/site-packages/django/conf/locale/ig/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/ig/formats.py b/venv/Lib/site-packages/django/conf/locale/ig/formats.py
new file mode 100644
--- /dev/null	(date 1617030482529)
+++ b/venv/Lib/site-packages/django/conf/locale/ig/formats.py	(date 1617030482529)
@@ -0,0 +1,32 @@
+# This file is distributed under the same license as the Django package.
+#
+# The *_FORMAT strings use the Django date format syntax,
+# see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date
+DATE_FORMAT = 'j F Y'
+TIME_FORMAT = 'P'
+DATETIME_FORMAT = 'j F Y P'
+YEAR_MONTH_FORMAT = 'F Y'
+MONTH_DAY_FORMAT = 'j F'
+SHORT_DATE_FORMAT = 'd.m.Y'
+SHORT_DATETIME_FORMAT = 'd.m.Y H:i'
+FIRST_DAY_OF_WEEK = 1  # Monday
+
+# The *_INPUT_FORMATS strings use the Python strftime format syntax,
+# see https://docs.python.org/library/datetime.html#strftime-strptime-behavior
+DATE_INPUT_FORMATS = [
+    '%d.%m.%Y',  # '25.10.2006'
+    '%d.%m.%y',  # '25.10.06'
+]
+DATETIME_INPUT_FORMATS = [
+    '%d.%m.%Y %H:%M:%S',     # '25.10.2006 14:30:59'
+    '%d.%m.%Y %H:%M:%S.%f',  # '25.10.2006 14:30:59.000200'
+    '%d.%m.%Y %H:%M',        # '25.10.2006 14:30'
+    '%d.%m.%Y',              # '25.10.2006'
+    '%d.%m.%y %H:%M:%S',     # '25.10.06 14:30:59'
+    '%d.%m.%y %H:%M:%S.%f',  # '25.10.06 14:30:59.000200'
+    '%d.%m.%y %H:%M',        # '25.10.06 14:30'
+    '%d.%m.%y',              # '25.10.06'
+]
+DECIMAL_SEPARATOR = '.'
+THOUSAND_SEPARATOR = ','
+NUMBER_GROUPING = 3
Index: venv/Lib/site-packages/django/conf/locale/is/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/is/formats.py b/venv/Lib/site-packages/django/conf/locale/is/formats.py
new file mode 100644
--- /dev/null	(date 1617030482532)
+++ b/venv/Lib/site-packages/django/conf/locale/is/formats.py	(date 1617030482532)
@@ -0,0 +1,21 @@
+# This file is distributed under the same license as the Django package.
+#
+# The *_FORMAT strings use the Django date format syntax,
+# see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date
+DATE_FORMAT = 'j. F Y'
+TIME_FORMAT = 'H:i'
+# DATETIME_FORMAT =
+YEAR_MONTH_FORMAT = 'F Y'
+MONTH_DAY_FORMAT = 'j. F'
+SHORT_DATE_FORMAT = 'j.n.Y'
+# SHORT_DATETIME_FORMAT =
+# FIRST_DAY_OF_WEEK =
+
+# The *_INPUT_FORMATS strings use the Python strftime format syntax,
+# see https://docs.python.org/library/datetime.html#strftime-strptime-behavior
+# DATE_INPUT_FORMATS =
+# TIME_INPUT_FORMATS =
+# DATETIME_INPUT_FORMATS =
+DECIMAL_SEPARATOR = ','
+THOUSAND_SEPARATOR = '.'
+NUMBER_GROUPING = 3
Index: venv/Lib/site-packages/django/conf/locale/it/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/it/formats.py b/venv/Lib/site-packages/django/conf/locale/it/formats.py
new file mode 100644
--- /dev/null	(date 1617030482533)
+++ b/venv/Lib/site-packages/django/conf/locale/it/formats.py	(date 1617030482533)
@@ -0,0 +1,40 @@
+# This file is distributed under the same license as the Django package.
+#
+# The *_FORMAT strings use the Django date format syntax,
+# see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date
+DATE_FORMAT = 'd F Y'  # 25 Ottobre 2006
+TIME_FORMAT = 'H:i'  # 14:30
+DATETIME_FORMAT = 'l d F Y H:i'  # Mercoledì 25 Ottobre 2006 14:30
+YEAR_MONTH_FORMAT = 'F Y'  # Ottobre 2006
+MONTH_DAY_FORMAT = 'j F'  # 25 Ottobre
+SHORT_DATE_FORMAT = 'd/m/Y'  # 25/12/2009
+SHORT_DATETIME_FORMAT = 'd/m/Y H:i'  # 25/10/2009 14:30
+FIRST_DAY_OF_WEEK = 1  # Lunedì
+
+# The *_INPUT_FORMATS strings use the Python strftime format syntax,
+# see https://docs.python.org/library/datetime.html#strftime-strptime-behavior
+DATE_INPUT_FORMATS = [
+    '%d/%m/%Y', '%Y/%m/%d',  # '25/10/2006', '2008/10/25'
+    '%d-%m-%Y', '%Y-%m-%d',  # '25-10-2006', '2008-10-25'
+    '%d-%m-%y', '%d/%m/%y',  # '25-10-06', '25/10/06'
+]
+DATETIME_INPUT_FORMATS = [
+    '%d/%m/%Y %H:%M:%S',     # '25/10/2006 14:30:59'
+    '%d/%m/%Y %H:%M:%S.%f',  # '25/10/2006 14:30:59.000200'
+    '%d/%m/%Y %H:%M',        # '25/10/2006 14:30'
+    '%d/%m/%y %H:%M:%S',     # '25/10/06 14:30:59'
+    '%d/%m/%y %H:%M:%S.%f',  # '25/10/06 14:30:59.000200'
+    '%d/%m/%y %H:%M',        # '25/10/06 14:30'
+    '%Y-%m-%d %H:%M:%S',     # '2006-10-25 14:30:59'
+    '%Y-%m-%d %H:%M:%S.%f',  # '2006-10-25 14:30:59.000200'
+    '%Y-%m-%d %H:%M',        # '2006-10-25 14:30'
+    '%d-%m-%Y %H:%M:%S',     # '25-10-2006 14:30:59'
+    '%d-%m-%Y %H:%M:%S.%f',  # '25-10-2006 14:30:59.000200'
+    '%d-%m-%Y %H:%M',        # '25-10-2006 14:30'
+    '%d-%m-%y %H:%M:%S',     # '25-10-06 14:30:59'
+    '%d-%m-%y %H:%M:%S.%f',  # '25-10-06 14:30:59.000200'
+    '%d-%m-%y %H:%M',        # '25-10-06 14:30'
+]
+DECIMAL_SEPARATOR = ','
+THOUSAND_SEPARATOR = '.'
+NUMBER_GROUPING = 3
Index: venv/Lib/site-packages/django/conf/locale/ja/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/ja/formats.py b/venv/Lib/site-packages/django/conf/locale/ja/formats.py
new file mode 100644
--- /dev/null	(date 1617030482535)
+++ b/venv/Lib/site-packages/django/conf/locale/ja/formats.py	(date 1617030482535)
@@ -0,0 +1,21 @@
+# This file is distributed under the same license as the Django package.
+#
+# The *_FORMAT strings use the Django date format syntax,
+# see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date
+DATE_FORMAT = 'Y年n月j日'
+TIME_FORMAT = 'G:i'
+DATETIME_FORMAT = 'Y年n月j日G:i'
+YEAR_MONTH_FORMAT = 'Y年n月'
+MONTH_DAY_FORMAT = 'n月j日'
+SHORT_DATE_FORMAT = 'Y/m/d'
+SHORT_DATETIME_FORMAT = 'Y/m/d G:i'
+# FIRST_DAY_OF_WEEK =
+
+# The *_INPUT_FORMATS strings use the Python strftime format syntax,
+# see https://docs.python.org/library/datetime.html#strftime-strptime-behavior
+# DATE_INPUT_FORMATS =
+# TIME_INPUT_FORMATS =
+# DATETIME_INPUT_FORMATS =
+DECIMAL_SEPARATOR = '.'
+THOUSAND_SEPARATOR = ','
+# NUMBER_GROUPING =
Index: venv/Lib/site-packages/django/conf/locale/ka/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/ka/formats.py b/venv/Lib/site-packages/django/conf/locale/ka/formats.py
new file mode 100644
--- /dev/null	(date 1617030482537)
+++ b/venv/Lib/site-packages/django/conf/locale/ka/formats.py	(date 1617030482537)
@@ -0,0 +1,42 @@
+# This file is distributed under the same license as the Django package.
+#
+# The *_FORMAT strings use the Django date format syntax,
+# see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date
+DATE_FORMAT = 'l, j F, Y'
+TIME_FORMAT = 'h:i a'
+DATETIME_FORMAT = 'j F, Y h:i a'
+YEAR_MONTH_FORMAT = 'F, Y'
+MONTH_DAY_FORMAT = 'j F'
+SHORT_DATE_FORMAT = 'j.M.Y'
+SHORT_DATETIME_FORMAT = 'j.M.Y H:i'
+FIRST_DAY_OF_WEEK = 1  # (Monday)
+
+# The *_INPUT_FORMATS strings use the Python strftime format syntax,
+# see https://docs.python.org/library/datetime.html#strftime-strptime-behavior
+# Kept ISO formats as they are in first position
+DATE_INPUT_FORMATS = [
+    '%Y-%m-%d', '%m/%d/%Y', '%m/%d/%y',     # '2006-10-25', '10/25/2006', '10/25/06'
+    '%d.%m.%Y', '%d.%m.%y',                 # '25.10.2006', '25.10.06'
+    # '%d %b %Y', '%d %b, %Y', '%d %b. %Y',   # '25 Oct 2006', '25 Oct, 2006', '25 Oct. 2006'
+    # '%d %B %Y', '%d %B, %Y',                # '25 October 2006', '25 October, 2006'
+]
+DATETIME_INPUT_FORMATS = [
+    '%Y-%m-%d %H:%M:%S',     # '2006-10-25 14:30:59'
+    '%Y-%m-%d %H:%M:%S.%f',  # '2006-10-25 14:30:59.000200'
+    '%Y-%m-%d %H:%M',        # '2006-10-25 14:30'
+    '%d.%m.%Y %H:%M:%S',     # '25.10.2006 14:30:59'
+    '%d.%m.%Y %H:%M:%S.%f',  # '25.10.2006 14:30:59.000200'
+    '%d.%m.%Y %H:%M',        # '25.10.2006 14:30'
+    '%d.%m.%y %H:%M:%S',     # '25.10.06 14:30:59'
+    '%d.%m.%y %H:%M:%S.%f',  # '25.10.06 14:30:59.000200'
+    '%d.%m.%y %H:%M',        # '25.10.06 14:30'
+    '%m/%d/%Y %H:%M:%S',     # '10/25/2006 14:30:59'
+    '%m/%d/%Y %H:%M:%S.%f',  # '10/25/2006 14:30:59.000200'
+    '%m/%d/%Y %H:%M',        # '10/25/2006 14:30'
+    '%m/%d/%y %H:%M:%S',     # '10/25/06 14:30:59'
+    '%m/%d/%y %H:%M:%S.%f',  # '10/25/06 14:30:59.000200'
+    '%m/%d/%y %H:%M',        # '10/25/06 14:30'
+]
+DECIMAL_SEPARATOR = '.'
+THOUSAND_SEPARATOR = " "
+NUMBER_GROUPING = 3
Index: venv/Lib/site-packages/django/conf/locale/km/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/km/formats.py b/venv/Lib/site-packages/django/conf/locale/km/formats.py
new file mode 100644
--- /dev/null	(date 1617030482540)
+++ b/venv/Lib/site-packages/django/conf/locale/km/formats.py	(date 1617030482540)
@@ -0,0 +1,21 @@
+# This file is distributed under the same license as the Django package.
+#
+# The *_FORMAT strings use the Django date format syntax,
+# see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date
+DATE_FORMAT = 'j ខែ F ឆ្នាំ Y'
+TIME_FORMAT = 'G:i'
+DATETIME_FORMAT = 'j ខែ F ឆ្នាំ Y, G:i'
+# YEAR_MONTH_FORMAT =
+MONTH_DAY_FORMAT = 'j F'
+SHORT_DATE_FORMAT = 'j M Y'
+SHORT_DATETIME_FORMAT = 'j M Y, G:i'
+# FIRST_DAY_OF_WEEK =
+
+# The *_INPUT_FORMATS strings use the Python strftime format syntax,
+# see https://docs.python.org/library/datetime.html#strftime-strptime-behavior
+# DATE_INPUT_FORMATS =
+# TIME_INPUT_FORMATS =
+# DATETIME_INPUT_FORMATS =
+DECIMAL_SEPARATOR = ','
+THOUSAND_SEPARATOR = '.'
+# NUMBER_GROUPING =
Index: venv/Lib/site-packages/django/conf/locale/kn/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/kn/formats.py b/venv/Lib/site-packages/django/conf/locale/kn/formats.py
new file mode 100644
--- /dev/null	(date 1617030482542)
+++ b/venv/Lib/site-packages/django/conf/locale/kn/formats.py	(date 1617030482542)
@@ -0,0 +1,21 @@
+# This file is distributed under the same license as the Django package.
+#
+# The *_FORMAT strings use the Django date format syntax,
+# see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date
+DATE_FORMAT = 'j F Y'
+TIME_FORMAT = 'h:i A'
+# DATETIME_FORMAT =
+# YEAR_MONTH_FORMAT =
+MONTH_DAY_FORMAT = 'j F'
+SHORT_DATE_FORMAT = 'j M Y'
+# SHORT_DATETIME_FORMAT =
+# FIRST_DAY_OF_WEEK =
+
+# The *_INPUT_FORMATS strings use the Python strftime format syntax,
+# see https://docs.python.org/library/datetime.html#strftime-strptime-behavior
+# DATE_INPUT_FORMATS =
+# TIME_INPUT_FORMATS =
+# DATETIME_INPUT_FORMATS =
+# DECIMAL_SEPARATOR =
+# THOUSAND_SEPARATOR =
+# NUMBER_GROUPING =
Index: venv/Lib/site-packages/django/conf/locale/ko/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/ko/formats.py b/venv/Lib/site-packages/django/conf/locale/ko/formats.py
new file mode 100644
--- /dev/null	(date 1617030482544)
+++ b/venv/Lib/site-packages/django/conf/locale/ko/formats.py	(date 1617030482544)
@@ -0,0 +1,49 @@
+# This file is distributed under the same license as the Django package.
+#
+# The *_FORMAT strings use the Django date format syntax,
+# see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date
+DATE_FORMAT = 'Y년 n월 j일'
+TIME_FORMAT = 'A g:i'
+DATETIME_FORMAT = 'Y년 n월 j일 g:i A'
+YEAR_MONTH_FORMAT = 'Y년 n월'
+MONTH_DAY_FORMAT = 'n월 j일'
+SHORT_DATE_FORMAT = 'Y-n-j.'
+SHORT_DATETIME_FORMAT = 'Y-n-j H:i'
+# FIRST_DAY_OF_WEEK =
+
+# The *_INPUT_FORMATS strings use the Python strftime format syntax,
+# see https://docs.python.org/library/datetime.html#strftime-strptime-behavior
+# Kept ISO formats as they are in first position
+DATE_INPUT_FORMATS = [
+    '%Y-%m-%d', '%m/%d/%Y', '%m/%d/%y',  # '2006-10-25', '10/25/2006', '10/25/06'
+    # '%b %d %Y', '%b %d, %Y',            # 'Oct 25 2006', 'Oct 25, 2006'
+    # '%d %b %Y', '%d %b, %Y',            # '25 Oct 2006', '25 Oct, 2006'
+    # '%B %d %Y', '%B %d, %Y',            # 'October 25 2006', 'October 25, 2006'
+    # '%d %B %Y', '%d %B, %Y',            # '25 October 2006', '25 October, 2006'
+    '%Y년 %m월 %d일',                   # '2006년 10월 25일', with localized suffix.
+]
+TIME_INPUT_FORMATS = [
+    '%H:%M:%S',     # '14:30:59'
+    '%H:%M:%S.%f',  # '14:30:59.000200'
+    '%H:%M',        # '14:30'
+    '%H시 %M분 %S초',   # '14시 30분 59초'
+    '%H시 %M분',        # '14시 30분'
+]
+DATETIME_INPUT_FORMATS = [
+    '%Y-%m-%d %H:%M:%S',     # '2006-10-25 14:30:59'
+    '%Y-%m-%d %H:%M:%S.%f',  # '2006-10-25 14:30:59.000200'
+    '%Y-%m-%d %H:%M',        # '2006-10-25 14:30'
+    '%m/%d/%Y %H:%M:%S',     # '10/25/2006 14:30:59'
+    '%m/%d/%Y %H:%M:%S.%f',  # '10/25/2006 14:30:59.000200'
+    '%m/%d/%Y %H:%M',        # '10/25/2006 14:30'
+    '%m/%d/%y %H:%M:%S',     # '10/25/06 14:30:59'
+    '%m/%d/%y %H:%M:%S.%f',  # '10/25/06 14:30:59.000200'
+    '%m/%d/%y %H:%M',        # '10/25/06 14:30'
+
+    '%Y년 %m월 %d일 %H시 %M분 %S초',  # '2006년 10월 25일 14시 30분 59초'
+    '%Y년 %m월 %d일 %H시 %M분',       # '2006년 10월 25일 14시 30분'
+]
+
+DECIMAL_SEPARATOR = '.'
+THOUSAND_SEPARATOR = ','
+NUMBER_GROUPING = 3
Index: venv/Lib/site-packages/django/conf/locale/ky/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/ky/formats.py b/venv/Lib/site-packages/django/conf/locale/ky/formats.py
new file mode 100644
--- /dev/null	(date 1617030482545)
+++ b/venv/Lib/site-packages/django/conf/locale/ky/formats.py	(date 1617030482545)
@@ -0,0 +1,32 @@
+# This file is distributed under the same license as the Django package.
+#
+# The *_FORMAT strings use the Django date format syntax,
+# see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date
+DATE_FORMAT = 'j E Y ж.'
+TIME_FORMAT = 'G:i'
+DATETIME_FORMAT = 'j E Y ж. G:i'
+YEAR_MONTH_FORMAT = 'F Y ж.'
+MONTH_DAY_FORMAT = 'j F'
+SHORT_DATE_FORMAT = 'd.m.Y'
+SHORT_DATETIME_FORMAT = 'd.m.Y H:i'
+FIRST_DAY_OF_WEEK = 1  # Дүйшөмбү, Monday
+
+# The *_INPUT_FORMATS strings use the Python strftime format syntax,
+# see https://docs.python.org/library/datetime.html#strftime-strptime-behavior
+DATE_INPUT_FORMATS = [
+    '%d.%m.%Y',  # '25.10.2006'
+    '%d.%m.%y',  # '25.10.06'
+]
+DATETIME_INPUT_FORMATS = [
+    '%d.%m.%Y %H:%M:%S',     # '25.10.2006 14:30:59'
+    '%d.%m.%Y %H:%M:%S.%f',  # '25.10.2006 14:30:59.000200'
+    '%d.%m.%Y %H:%M',        # '25.10.2006 14:30'
+    '%d.%m.%Y',              # '25.10.2006'
+    '%d.%m.%y %H:%M:%S',     # '25.10.06 14:30:59'
+    '%d.%m.%y %H:%M:%S.%f',  # '25.10.06 14:30:59.000200'
+    '%d.%m.%y %H:%M',        # '25.10.06 14:30'
+    '%d.%m.%y',              # '25.10.06'
+]
+DECIMAL_SEPARATOR = '.'
+THOUSAND_SEPARATOR = '\xa0'  # non-breaking space
+NUMBER_GROUPING = 3
Index: venv/Lib/site-packages/django/conf/locale/lt/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/lt/formats.py b/venv/Lib/site-packages/django/conf/locale/lt/formats.py
new file mode 100644
--- /dev/null	(date 1617030482551)
+++ b/venv/Lib/site-packages/django/conf/locale/lt/formats.py	(date 1617030482551)
@@ -0,0 +1,43 @@
+# This file is distributed under the same license as the Django package.
+#
+# The *_FORMAT strings use the Django date format syntax,
+# see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date
+DATE_FORMAT = r'Y \m. E j \d.'
+TIME_FORMAT = 'H:i'
+DATETIME_FORMAT = r'Y \m. E j \d., H:i'
+YEAR_MONTH_FORMAT = r'Y \m. F'
+MONTH_DAY_FORMAT = r'E j \d.'
+SHORT_DATE_FORMAT = 'Y-m-d'
+SHORT_DATETIME_FORMAT = 'Y-m-d H:i'
+FIRST_DAY_OF_WEEK = 1  # Monday
+
+# The *_INPUT_FORMATS strings use the Python strftime format syntax,
+# see https://docs.python.org/library/datetime.html#strftime-strptime-behavior
+DATE_INPUT_FORMATS = [
+    '%Y-%m-%d', '%d.%m.%Y', '%d.%m.%y',  # '2006-10-25', '25.10.2006', '25.10.06'
+]
+TIME_INPUT_FORMATS = [
+    '%H:%M:%S',     # '14:30:59'
+    '%H:%M:%S.%f',  # '14:30:59.000200'
+    '%H:%M',        # '14:30'
+    '%H.%M.%S',     # '14.30.59'
+    '%H.%M.%S.%f',  # '14.30.59.000200'
+    '%H.%M',        # '14.30'
+]
+DATETIME_INPUT_FORMATS = [
+    '%Y-%m-%d %H:%M:%S',     # '2006-10-25 14:30:59'
+    '%Y-%m-%d %H:%M:%S.%f',  # '2006-10-25 14:30:59.000200'
+    '%Y-%m-%d %H:%M',        # '2006-10-25 14:30'
+    '%d.%m.%Y %H:%M:%S',     # '25.10.2006 14:30:59'
+    '%d.%m.%Y %H:%M:%S.%f',  # '25.10.2006 14:30:59.000200'
+    '%d.%m.%Y %H:%M',        # '25.10.2006 14:30'
+    '%d.%m.%y %H:%M:%S',     # '25.10.06 14:30:59'
+    '%d.%m.%y %H:%M:%S.%f',  # '25.10.06 14:30:59.000200'
+    '%d.%m.%y %H:%M',        # '25.10.06 14:30'
+    '%d.%m.%y %H.%M.%S',     # '25.10.06 14.30.59'
+    '%d.%m.%y %H.%M.%S.%f',  # '25.10.06 14.30.59.000200'
+    '%d.%m.%y %H.%M',        # '25.10.06 14.30'
+]
+DECIMAL_SEPARATOR = ','
+THOUSAND_SEPARATOR = '.'
+NUMBER_GROUPING = 3
Index: venv/Lib/site-packages/django/conf/locale/lv/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/lv/formats.py b/venv/Lib/site-packages/django/conf/locale/lv/formats.py
new file mode 100644
--- /dev/null	(date 1617030482553)
+++ b/venv/Lib/site-packages/django/conf/locale/lv/formats.py	(date 1617030482553)
@@ -0,0 +1,44 @@
+# This file is distributed under the same license as the Django package.
+#
+# The *_FORMAT strings use the Django date format syntax,
+# see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date
+DATE_FORMAT = r'Y. \g\a\d\a j. F'
+TIME_FORMAT = 'H:i'
+DATETIME_FORMAT = r'Y. \g\a\d\a j. F, H:i'
+YEAR_MONTH_FORMAT = r'Y. \g. F'
+MONTH_DAY_FORMAT = 'j. F'
+SHORT_DATE_FORMAT = r'j.m.Y'
+SHORT_DATETIME_FORMAT = 'j.m.Y H:i'
+FIRST_DAY_OF_WEEK = 1  # Monday
+
+# The *_INPUT_FORMATS strings use the Python strftime format syntax,
+# see https://docs.python.org/library/datetime.html#strftime-strptime-behavior
+# Kept ISO formats as they are in first position
+DATE_INPUT_FORMATS = [
+    '%Y-%m-%d', '%d.%m.%Y', '%d.%m.%y',  # '2006-10-25', '25.10.2006', '25.10.06'
+]
+TIME_INPUT_FORMATS = [
+    '%H:%M:%S',     # '14:30:59'
+    '%H:%M:%S.%f',  # '14:30:59.000200'
+    '%H:%M',        # '14:30'
+    '%H.%M.%S',     # '14.30.59'
+    '%H.%M.%S.%f',  # '14.30.59.000200'
+    '%H.%M',        # '14.30'
+]
+DATETIME_INPUT_FORMATS = [
+    '%Y-%m-%d %H:%M:%S',     # '2006-10-25 14:30:59'
+    '%Y-%m-%d %H:%M:%S.%f',  # '2006-10-25 14:30:59.000200'
+    '%Y-%m-%d %H:%M',        # '2006-10-25 14:30'
+    '%d.%m.%Y %H:%M:%S',     # '25.10.2006 14:30:59'
+    '%d.%m.%Y %H:%M:%S.%f',  # '25.10.2006 14:30:59.000200'
+    '%d.%m.%Y %H:%M',        # '25.10.2006 14:30'
+    '%d.%m.%y %H:%M:%S',     # '25.10.06 14:30:59'
+    '%d.%m.%y %H:%M:%S.%f',  # '25.10.06 14:30:59.000200'
+    '%d.%m.%y %H:%M',        # '25.10.06 14:30'
+    '%d.%m.%y %H.%M.%S',     # '25.10.06 14.30.59'
+    '%d.%m.%y %H.%M.%S.%f',  # '25.10.06 14.30.59.000200'
+    '%d.%m.%y %H.%M',        # '25.10.06 14.30'
+]
+DECIMAL_SEPARATOR = ','
+THOUSAND_SEPARATOR = ' '  # Non-breaking space
+NUMBER_GROUPING = 3
Index: venv/Lib/site-packages/django/conf/locale/mk/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/mk/formats.py b/venv/Lib/site-packages/django/conf/locale/mk/formats.py
new file mode 100644
--- /dev/null	(date 1617030482554)
+++ b/venv/Lib/site-packages/django/conf/locale/mk/formats.py	(date 1617030482554)
@@ -0,0 +1,38 @@
+# This file is distributed under the same license as the Django package.
+#
+# The *_FORMAT strings use the Django date format syntax,
+# see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date
+DATE_FORMAT = 'd F Y'
+TIME_FORMAT = 'H:i'
+DATETIME_FORMAT = 'j. F Y H:i'
+YEAR_MONTH_FORMAT = 'F Y'
+MONTH_DAY_FORMAT = 'j. F'
+SHORT_DATE_FORMAT = 'j.m.Y'
+SHORT_DATETIME_FORMAT = 'j.m.Y H:i'
+FIRST_DAY_OF_WEEK = 1
+
+# The *_INPUT_FORMATS strings use the Python strftime format syntax,
+# see https://docs.python.org/library/datetime.html#strftime-strptime-behavior
+DATE_INPUT_FORMATS = [
+    '%d.%m.%Y', '%d.%m.%y',       # '25.10.2006', '25.10.06'
+    '%d. %m. %Y', '%d. %m. %y',   # '25. 10. 2006', '25. 10. 06'
+]
+
+DATETIME_INPUT_FORMATS = [
+    '%d.%m.%Y %H:%M:%S',       # '25.10.2006 14:30:59'
+    '%d.%m.%Y %H:%M:%S.%f',    # '25.10.2006 14:30:59.000200'
+    '%d.%m.%Y %H:%M',          # '25.10.2006 14:30'
+    '%d.%m.%y %H:%M:%S',       # '25.10.06 14:30:59'
+    '%d.%m.%y %H:%M:%S.%f',    # '25.10.06 14:30:59.000200'
+    '%d.%m.%y %H:%M',          # '25.10.06 14:30'
+    '%d. %m. %Y %H:%M:%S',     # '25. 10. 2006 14:30:59'
+    '%d. %m. %Y %H:%M:%S.%f',  # '25. 10. 2006 14:30:59.000200'
+    '%d. %m. %Y %H:%M',        # '25. 10. 2006 14:30'
+    '%d. %m. %y %H:%M:%S',     # '25. 10. 06 14:30:59'
+    '%d. %m. %y %H:%M:%S.%f',  # '25. 10. 06 14:30:59.000200'
+    '%d. %m. %y %H:%M',        # '25. 10. 06 14:30'
+]
+
+DECIMAL_SEPARATOR = ','
+THOUSAND_SEPARATOR = '.'
+NUMBER_GROUPING = 3
Index: venv/Lib/site-packages/django/conf/locale/ml/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/ml/formats.py b/venv/Lib/site-packages/django/conf/locale/ml/formats.py
new file mode 100644
--- /dev/null	(date 1617030482556)
+++ b/venv/Lib/site-packages/django/conf/locale/ml/formats.py	(date 1617030482556)
@@ -0,0 +1,37 @@
+# This file is distributed under the same license as the Django package.
+#
+# The *_FORMAT strings use the Django date format syntax,
+# see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date
+DATE_FORMAT = 'N j, Y'
+TIME_FORMAT = 'P'
+DATETIME_FORMAT = 'N j, Y, P'
+YEAR_MONTH_FORMAT = 'F Y'
+MONTH_DAY_FORMAT = 'F j'
+SHORT_DATE_FORMAT = 'm/d/Y'
+SHORT_DATETIME_FORMAT = 'm/d/Y P'
+FIRST_DAY_OF_WEEK = 0  # Sunday
+
+# The *_INPUT_FORMATS strings use the Python strftime format syntax,
+# see https://docs.python.org/library/datetime.html#strftime-strptime-behavior
+# Kept ISO formats as they are in first position
+DATE_INPUT_FORMATS = [
+    '%Y-%m-%d', '%m/%d/%Y', '%m/%d/%y',  # '2006-10-25', '10/25/2006', '10/25/06'
+    # '%b %d %Y', '%b %d, %Y',            # 'Oct 25 2006', 'Oct 25, 2006'
+    # '%d %b %Y', '%d %b, %Y',            # '25 Oct 2006', '25 Oct, 2006'
+    # '%B %d %Y', '%B %d, %Y',            # 'October 25 2006', 'October 25, 2006'
+    # '%d %B %Y', '%d %B, %Y',            # '25 October 2006', '25 October, 2006'
+]
+DATETIME_INPUT_FORMATS = [
+    '%Y-%m-%d %H:%M:%S',     # '2006-10-25 14:30:59'
+    '%Y-%m-%d %H:%M:%S.%f',  # '2006-10-25 14:30:59.000200'
+    '%Y-%m-%d %H:%M',        # '2006-10-25 14:30'
+    '%m/%d/%Y %H:%M:%S',     # '10/25/2006 14:30:59'
+    '%m/%d/%Y %H:%M:%S.%f',  # '10/25/2006 14:30:59.000200'
+    '%m/%d/%Y %H:%M',        # '10/25/2006 14:30'
+    '%m/%d/%y %H:%M:%S',     # '10/25/06 14:30:59'
+    '%m/%d/%y %H:%M:%S.%f',  # '10/25/06 14:30:59.000200'
+    '%m/%d/%y %H:%M',        # '10/25/06 14:30'
+]
+DECIMAL_SEPARATOR = '.'
+THOUSAND_SEPARATOR = ','
+NUMBER_GROUPING = 3
Index: venv/Lib/site-packages/django/conf/locale/mn/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/mn/formats.py b/venv/Lib/site-packages/django/conf/locale/mn/formats.py
new file mode 100644
--- /dev/null	(date 1617030482558)
+++ b/venv/Lib/site-packages/django/conf/locale/mn/formats.py	(date 1617030482558)
@@ -0,0 +1,21 @@
+# This file is distributed under the same license as the Django package.
+#
+# The *_FORMAT strings use the Django date format syntax,
+# see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date
+DATE_FORMAT = 'd F Y'
+TIME_FORMAT = 'g:i A'
+# DATETIME_FORMAT =
+# YEAR_MONTH_FORMAT =
+# MONTH_DAY_FORMAT =
+SHORT_DATE_FORMAT = 'j M Y'
+# SHORT_DATETIME_FORMAT =
+# FIRST_DAY_OF_WEEK =
+
+# The *_INPUT_FORMATS strings use the Python strftime format syntax,
+# see https://docs.python.org/library/datetime.html#strftime-strptime-behavior
+# DATE_INPUT_FORMATS =
+# TIME_INPUT_FORMATS =
+# DATETIME_INPUT_FORMATS =
+# DECIMAL_SEPARATOR =
+# THOUSAND_SEPARATOR =
+# NUMBER_GROUPING =
Index: venv/Lib/site-packages/django/conf/locale/nb/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/nb/formats.py b/venv/Lib/site-packages/django/conf/locale/nb/formats.py
new file mode 100644
--- /dev/null	(date 1617030482562)
+++ b/venv/Lib/site-packages/django/conf/locale/nb/formats.py	(date 1617030482562)
@@ -0,0 +1,36 @@
+# This file is distributed under the same license as the Django package.
+#
+# The *_FORMAT strings use the Django date format syntax,
+# see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date
+DATE_FORMAT = 'j. F Y'
+TIME_FORMAT = 'H:i'
+DATETIME_FORMAT = 'j. F Y H:i'
+YEAR_MONTH_FORMAT = 'F Y'
+MONTH_DAY_FORMAT = 'j. F'
+SHORT_DATE_FORMAT = 'd.m.Y'
+SHORT_DATETIME_FORMAT = 'd.m.Y H:i'
+FIRST_DAY_OF_WEEK = 1  # Monday
+
+# The *_INPUT_FORMATS strings use the Python strftime format syntax,
+# see https://docs.python.org/library/datetime.html#strftime-strptime-behavior
+# Kept ISO formats as they are in first position
+DATE_INPUT_FORMATS = [
+    '%Y-%m-%d', '%d.%m.%Y', '%d.%m.%y',  # '2006-10-25', '25.10.2006', '25.10.06'
+    # '%d. %b %Y', '%d %b %Y',            # '25. okt 2006', '25 okt 2006'
+    # '%d. %b. %Y', '%d %b. %Y',          # '25. okt. 2006', '25 okt. 2006'
+    # '%d. %B %Y', '%d %B %Y',            # '25. oktober 2006', '25 oktober 2006'
+]
+DATETIME_INPUT_FORMATS = [
+    '%Y-%m-%d %H:%M:%S',     # '2006-10-25 14:30:59'
+    '%Y-%m-%d %H:%M:%S.%f',  # '2006-10-25 14:30:59.000200'
+    '%Y-%m-%d %H:%M',        # '2006-10-25 14:30'
+    '%d.%m.%Y %H:%M:%S',     # '25.10.2006 14:30:59'
+    '%d.%m.%Y %H:%M:%S.%f',  # '25.10.2006 14:30:59.000200'
+    '%d.%m.%Y %H:%M',        # '25.10.2006 14:30'
+    '%d.%m.%y %H:%M:%S',     # '25.10.06 14:30:59'
+    '%d.%m.%y %H:%M:%S.%f',  # '25.10.06 14:30:59.000200'
+    '%d.%m.%y %H:%M',        # '25.10.06 14:30'
+]
+DECIMAL_SEPARATOR = ','
+THOUSAND_SEPARATOR = '\xa0'  # non-breaking space
+NUMBER_GROUPING = 3
Index: venv/Lib/site-packages/pip/_vendor/appdirs.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/pip/_vendor/appdirs.py b/venv/Lib/site-packages/pip/_vendor/appdirs.py
new file mode 100644
--- /dev/null	(date 1617030442509)
+++ b/venv/Lib/site-packages/pip/_vendor/appdirs.py	(date 1617030442509)
@@ -0,0 +1,633 @@
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+# Copyright (c) 2005-2010 ActiveState Software Inc.
+# Copyright (c) 2013 Eddy Petrișor
+
+"""Utilities for determining application-specific dirs.
+
+See <http://github.com/ActiveState/appdirs> for details and usage.
+"""
+# Dev Notes:
+# - MSDN on where to store app data files:
+#   http://support.microsoft.com/default.aspx?scid=kb;en-us;310294#XSLTH3194121123120121120120
+# - Mac OS X: http://developer.apple.com/documentation/MacOSX/Conceptual/BPFileSystem/index.html
+# - XDG spec for Un*x: http://standards.freedesktop.org/basedir-spec/basedir-spec-latest.html
+
+__version__ = "1.4.4"
+__version_info__ = tuple(int(segment) for segment in __version__.split("."))
+
+
+import sys
+import os
+
+PY3 = sys.version_info[0] == 3
+
+if PY3:
+    unicode = str
+
+if sys.platform.startswith('java'):
+    import platform
+    os_name = platform.java_ver()[3][0]
+    if os_name.startswith('Windows'): # "Windows XP", "Windows 7", etc.
+        system = 'win32'
+    elif os_name.startswith('Mac'): # "Mac OS X", etc.
+        system = 'darwin'
+    else: # "Linux", "SunOS", "FreeBSD", etc.
+        # Setting this to "linux2" is not ideal, but only Windows or Mac
+        # are actually checked for and the rest of the module expects
+        # *sys.platform* style strings.
+        system = 'linux2'
+elif sys.platform == 'cli' and os.name == 'nt':
+    # Detect Windows in IronPython to match pip._internal.utils.compat.WINDOWS
+    # Discussion: <https://github.com/pypa/pip/pull/7501>
+    system = 'win32'
+else:
+    system = sys.platform
+
+
+
+def user_data_dir(appname=None, appauthor=None, version=None, roaming=False):
+    r"""Return full path to the user-specific data dir for this application.
+
+        "appname" is the name of application.
+            If None, just the system directory is returned.
+        "appauthor" (only used on Windows) is the name of the
+            appauthor or distributing body for this application. Typically
+            it is the owning company name. This falls back to appname. You may
+            pass False to disable it.
+        "version" is an optional version path element to append to the
+            path. You might want to use this if you want multiple versions
+            of your app to be able to run independently. If used, this
+            would typically be "<major>.<minor>".
+            Only applied when appname is present.
+        "roaming" (boolean, default False) can be set True to use the Windows
+            roaming appdata directory. That means that for users on a Windows
+            network setup for roaming profiles, this user data will be
+            sync'd on login. See
+            <http://technet.microsoft.com/en-us/library/cc766489(WS.10).aspx>
+            for a discussion of issues.
+
+    Typical user data directories are:
+        Mac OS X:               ~/Library/Application Support/<AppName>  # or ~/.config/<AppName>, if the other does not exist
+        Unix:                   ~/.local/share/<AppName>    # or in $XDG_DATA_HOME, if defined
+        Win XP (not roaming):   C:\Documents and Settings\<username>\Application Data\<AppAuthor>\<AppName>
+        Win XP (roaming):       C:\Documents and Settings\<username>\Local Settings\Application Data\<AppAuthor>\<AppName>
+        Win 7  (not roaming):   C:\Users\<username>\AppData\Local\<AppAuthor>\<AppName>
+        Win 7  (roaming):       C:\Users\<username>\AppData\Roaming\<AppAuthor>\<AppName>
+
+    For Unix, we follow the XDG spec and support $XDG_DATA_HOME.
+    That means, by default "~/.local/share/<AppName>".
+    """
+    if system == "win32":
+        if appauthor is None:
+            appauthor = appname
+        const = roaming and "CSIDL_APPDATA" or "CSIDL_LOCAL_APPDATA"
+        path = os.path.normpath(_get_win_folder(const))
+        if appname:
+            if appauthor is not False:
+                path = os.path.join(path, appauthor, appname)
+            else:
+                path = os.path.join(path, appname)
+    elif system == 'darwin':
+        path = os.path.expanduser('~/Library/Application Support/')
+        if appname:
+            path = os.path.join(path, appname)
+    else:
+        path = os.getenv('XDG_DATA_HOME', os.path.expanduser("~/.local/share"))
+        if appname:
+            path = os.path.join(path, appname)
+    if appname and version:
+        path = os.path.join(path, version)
+    return path
+
+
+def site_data_dir(appname=None, appauthor=None, version=None, multipath=False):
+    r"""Return full path to the user-shared data dir for this application.
+
+        "appname" is the name of application.
+            If None, just the system directory is returned.
+        "appauthor" (only used on Windows) is the name of the
+            appauthor or distributing body for this application. Typically
+            it is the owning company name. This falls back to appname. You may
+            pass False to disable it.
+        "version" is an optional version path element to append to the
+            path. You might want to use this if you want multiple versions
+            of your app to be able to run independently. If used, this
+            would typically be "<major>.<minor>".
+            Only applied when appname is present.
+        "multipath" is an optional parameter only applicable to *nix
+            which indicates that the entire list of data dirs should be
+            returned. By default, the first item from XDG_DATA_DIRS is
+            returned, or '/usr/local/share/<AppName>',
+            if XDG_DATA_DIRS is not set
+
+    Typical site data directories are:
+        Mac OS X:   /Library/Application Support/<AppName>
+        Unix:       /usr/local/share/<AppName> or /usr/share/<AppName>
+        Win XP:     C:\Documents and Settings\All Users\Application Data\<AppAuthor>\<AppName>
+        Vista:      (Fail! "C:\ProgramData" is a hidden *system* directory on Vista.)
+        Win 7:      C:\ProgramData\<AppAuthor>\<AppName>   # Hidden, but writeable on Win 7.
+
+    For Unix, this is using the $XDG_DATA_DIRS[0] default.
+
+    WARNING: Do not use this on Windows. See the Vista-Fail note above for why.
+    """
+    if system == "win32":
+        if appauthor is None:
+            appauthor = appname
+        path = os.path.normpath(_get_win_folder("CSIDL_COMMON_APPDATA"))
+        if appname:
+            if appauthor is not False:
+                path = os.path.join(path, appauthor, appname)
+            else:
+                path = os.path.join(path, appname)
+    elif system == 'darwin':
+        path = os.path.expanduser('/Library/Application Support')
+        if appname:
+            path = os.path.join(path, appname)
+    else:
+        # XDG default for $XDG_DATA_DIRS
+        # only first, if multipath is False
+        path = os.getenv('XDG_DATA_DIRS',
+                         os.pathsep.join(['/usr/local/share', '/usr/share']))
+        pathlist = [os.path.expanduser(x.rstrip(os.sep)) for x in path.split(os.pathsep)]
+        if appname:
+            if version:
+                appname = os.path.join(appname, version)
+            pathlist = [os.path.join(x, appname) for x in pathlist]
+
+        if multipath:
+            path = os.pathsep.join(pathlist)
+        else:
+            path = pathlist[0]
+        return path
+
+    if appname and version:
+        path = os.path.join(path, version)
+    return path
+
+
+def user_config_dir(appname=None, appauthor=None, version=None, roaming=False):
+    r"""Return full path to the user-specific config dir for this application.
+
+        "appname" is the name of application.
+            If None, just the system directory is returned.
+        "appauthor" (only used on Windows) is the name of the
+            appauthor or distributing body for this application. Typically
+            it is the owning company name. This falls back to appname. You may
+            pass False to disable it.
+        "version" is an optional version path element to append to the
+            path. You might want to use this if you want multiple versions
+            of your app to be able to run independently. If used, this
+            would typically be "<major>.<minor>".
+            Only applied when appname is present.
+        "roaming" (boolean, default False) can be set True to use the Windows
+            roaming appdata directory. That means that for users on a Windows
+            network setup for roaming profiles, this user data will be
+            sync'd on login. See
+            <http://technet.microsoft.com/en-us/library/cc766489(WS.10).aspx>
+            for a discussion of issues.
+
+    Typical user config directories are:
+        Mac OS X:               same as user_data_dir
+        Unix:                   ~/.config/<AppName>     # or in $XDG_CONFIG_HOME, if defined
+        Win *:                  same as user_data_dir
+
+    For Unix, we follow the XDG spec and support $XDG_CONFIG_HOME.
+    That means, by default "~/.config/<AppName>".
+    """
+    if system in ["win32", "darwin"]:
+        path = user_data_dir(appname, appauthor, None, roaming)
+    else:
+        path = os.getenv('XDG_CONFIG_HOME', os.path.expanduser("~/.config"))
+        if appname:
+            path = os.path.join(path, appname)
+    if appname and version:
+        path = os.path.join(path, version)
+    return path
+
+
+# for the discussion regarding site_config_dir locations
+# see <https://github.com/pypa/pip/issues/1733>
+def site_config_dir(appname=None, appauthor=None, version=None, multipath=False):
+    r"""Return full path to the user-shared data dir for this application.
+
+        "appname" is the name of application.
+            If None, just the system directory is returned.
+        "appauthor" (only used on Windows) is the name of the
+            appauthor or distributing body for this application. Typically
+            it is the owning company name. This falls back to appname. You may
+            pass False to disable it.
+        "version" is an optional version path element to append to the
+            path. You might want to use this if you want multiple versions
+            of your app to be able to run independently. If used, this
+            would typically be "<major>.<minor>".
+            Only applied when appname is present.
+        "multipath" is an optional parameter only applicable to *nix
+            which indicates that the entire list of config dirs should be
+            returned. By default, the first item from XDG_CONFIG_DIRS is
+            returned, or '/etc/xdg/<AppName>', if XDG_CONFIG_DIRS is not set
+
+    Typical site config directories are:
+        Mac OS X:   same as site_data_dir
+        Unix:       /etc/xdg/<AppName> or $XDG_CONFIG_DIRS[i]/<AppName> for each value in
+                    $XDG_CONFIG_DIRS
+        Win *:      same as site_data_dir
+        Vista:      (Fail! "C:\ProgramData" is a hidden *system* directory on Vista.)
+
+    For Unix, this is using the $XDG_CONFIG_DIRS[0] default, if multipath=False
+
+    WARNING: Do not use this on Windows. See the Vista-Fail note above for why.
+    """
+    if system in ["win32", "darwin"]:
+        path = site_data_dir(appname, appauthor)
+        if appname and version:
+            path = os.path.join(path, version)
+    else:
+        # XDG default for $XDG_CONFIG_DIRS (missing or empty)
+        # see <https://github.com/pypa/pip/pull/7501#discussion_r360624829>
+        # only first, if multipath is False
+        path = os.getenv('XDG_CONFIG_DIRS') or '/etc/xdg'
+        pathlist = [os.path.expanduser(x.rstrip(os.sep)) for x in path.split(os.pathsep) if x]
+        if appname:
+            if version:
+                appname = os.path.join(appname, version)
+            pathlist = [os.path.join(x, appname) for x in pathlist]
+
+        if multipath:
+            path = os.pathsep.join(pathlist)
+        else:
+            path = pathlist[0]
+    return path
+
+
+def user_cache_dir(appname=None, appauthor=None, version=None, opinion=True):
+    r"""Return full path to the user-specific cache dir for this application.
+
+        "appname" is the name of application.
+            If None, just the system directory is returned.
+        "appauthor" (only used on Windows) is the name of the
+            appauthor or distributing body for this application. Typically
+            it is the owning company name. This falls back to appname. You may
+            pass False to disable it.
+        "version" is an optional version path element to append to the
+            path. You might want to use this if you want multiple versions
+            of your app to be able to run independently. If used, this
+            would typically be "<major>.<minor>".
+            Only applied when appname is present.
+        "opinion" (boolean) can be False to disable the appending of
+            "Cache" to the base app data dir for Windows. See
+            discussion below.
+
+    Typical user cache directories are:
+        Mac OS X:   ~/Library/Caches/<AppName>
+        Unix:       ~/.cache/<AppName> (XDG default)
+        Win XP:     C:\Documents and Settings\<username>\Local Settings\Application Data\<AppAuthor>\<AppName>\Cache
+        Vista:      C:\Users\<username>\AppData\Local\<AppAuthor>\<AppName>\Cache
+
+    On Windows the only suggestion in the MSDN docs is that local settings go in
+    the `CSIDL_LOCAL_APPDATA` directory. This is identical to the non-roaming
+    app data dir (the default returned by `user_data_dir` above). Apps typically
+    put cache data somewhere *under* the given dir here. Some examples:
+        ...\Mozilla\Firefox\Profiles\<ProfileName>\Cache
+        ...\Acme\SuperApp\Cache\1.0
+    OPINION: This function appends "Cache" to the `CSIDL_LOCAL_APPDATA` value.
+    This can be disabled with the `opinion=False` option.
+    """
+    if system == "win32":
+        if appauthor is None:
+            appauthor = appname
+        path = os.path.normpath(_get_win_folder("CSIDL_LOCAL_APPDATA"))
+        # When using Python 2, return paths as bytes on Windows like we do on
+        # other operating systems. See helper function docs for more details.
+        if not PY3 and isinstance(path, unicode):
+            path = _win_path_to_bytes(path)
+        if appname:
+            if appauthor is not False:
+                path = os.path.join(path, appauthor, appname)
+            else:
+                path = os.path.join(path, appname)
+            if opinion:
+                path = os.path.join(path, "Cache")
+    elif system == 'darwin':
+        path = os.path.expanduser('~/Library/Caches')
+        if appname:
+            path = os.path.join(path, appname)
+    else:
+        path = os.getenv('XDG_CACHE_HOME', os.path.expanduser('~/.cache'))
+        if appname:
+            path = os.path.join(path, appname)
+    if appname and version:
+        path = os.path.join(path, version)
+    return path
+
+
+def user_state_dir(appname=None, appauthor=None, version=None, roaming=False):
+    r"""Return full path to the user-specific state dir for this application.
+
+        "appname" is the name of application.
+            If None, just the system directory is returned.
+        "appauthor" (only used on Windows) is the name of the
+            appauthor or distributing body for this application. Typically
+            it is the owning company name. This falls back to appname. You may
+            pass False to disable it.
+        "version" is an optional version path element to append to the
+            path. You might want to use this if you want multiple versions
+            of your app to be able to run independently. If used, this
+            would typically be "<major>.<minor>".
+            Only applied when appname is present.
+        "roaming" (boolean, default False) can be set True to use the Windows
+            roaming appdata directory. That means that for users on a Windows
+            network setup for roaming profiles, this user data will be
+            sync'd on login. See
+            <http://technet.microsoft.com/en-us/library/cc766489(WS.10).aspx>
+            for a discussion of issues.
+
+    Typical user state directories are:
+        Mac OS X:  same as user_data_dir
+        Unix:      ~/.local/state/<AppName>   # or in $XDG_STATE_HOME, if defined
+        Win *:     same as user_data_dir
+
+    For Unix, we follow this Debian proposal <https://wiki.debian.org/XDGBaseDirectorySpecification#state>
+    to extend the XDG spec and support $XDG_STATE_HOME.
+
+    That means, by default "~/.local/state/<AppName>".
+    """
+    if system in ["win32", "darwin"]:
+        path = user_data_dir(appname, appauthor, None, roaming)
+    else:
+        path = os.getenv('XDG_STATE_HOME', os.path.expanduser("~/.local/state"))
+        if appname:
+            path = os.path.join(path, appname)
+    if appname and version:
+        path = os.path.join(path, version)
+    return path
+
+
+def user_log_dir(appname=None, appauthor=None, version=None, opinion=True):
+    r"""Return full path to the user-specific log dir for this application.
+
+        "appname" is the name of application.
+            If None, just the system directory is returned.
+        "appauthor" (only used on Windows) is the name of the
+            appauthor or distributing body for this application. Typically
+            it is the owning company name. This falls back to appname. You may
+            pass False to disable it.
+        "version" is an optional version path element to append to the
+            path. You might want to use this if you want multiple versions
+            of your app to be able to run independently. If used, this
+            would typically be "<major>.<minor>".
+            Only applied when appname is present.
+        "opinion" (boolean) can be False to disable the appending of
+            "Logs" to the base app data dir for Windows, and "log" to the
+            base cache dir for Unix. See discussion below.
+
+    Typical user log directories are:
+        Mac OS X:   ~/Library/Logs/<AppName>
+        Unix:       ~/.cache/<AppName>/log  # or under $XDG_CACHE_HOME if defined
+        Win XP:     C:\Documents and Settings\<username>\Local Settings\Application Data\<AppAuthor>\<AppName>\Logs
+        Vista:      C:\Users\<username>\AppData\Local\<AppAuthor>\<AppName>\Logs
+
+    On Windows the only suggestion in the MSDN docs is that local settings
+    go in the `CSIDL_LOCAL_APPDATA` directory. (Note: I'm interested in
+    examples of what some windows apps use for a logs dir.)
+
+    OPINION: This function appends "Logs" to the `CSIDL_LOCAL_APPDATA`
+    value for Windows and appends "log" to the user cache dir for Unix.
+    This can be disabled with the `opinion=False` option.
+    """
+    if system == "darwin":
+        path = os.path.join(
+            os.path.expanduser('~/Library/Logs'),
+            appname)
+    elif system == "win32":
+        path = user_data_dir(appname, appauthor, version)
+        version = False
+        if opinion:
+            path = os.path.join(path, "Logs")
+    else:
+        path = user_cache_dir(appname, appauthor, version)
+        version = False
+        if opinion:
+            path = os.path.join(path, "log")
+    if appname and version:
+        path = os.path.join(path, version)
+    return path
+
+
+class AppDirs(object):
+    """Convenience wrapper for getting application dirs."""
+    def __init__(self, appname=None, appauthor=None, version=None,
+            roaming=False, multipath=False):
+        self.appname = appname
+        self.appauthor = appauthor
+        self.version = version
+        self.roaming = roaming
+        self.multipath = multipath
+
+    @property
+    def user_data_dir(self):
+        return user_data_dir(self.appname, self.appauthor,
+                             version=self.version, roaming=self.roaming)
+
+    @property
+    def site_data_dir(self):
+        return site_data_dir(self.appname, self.appauthor,
+                             version=self.version, multipath=self.multipath)
+
+    @property
+    def user_config_dir(self):
+        return user_config_dir(self.appname, self.appauthor,
+                               version=self.version, roaming=self.roaming)
+
+    @property
+    def site_config_dir(self):
+        return site_config_dir(self.appname, self.appauthor,
+                             version=self.version, multipath=self.multipath)
+
+    @property
+    def user_cache_dir(self):
+        return user_cache_dir(self.appname, self.appauthor,
+                              version=self.version)
+
+    @property
+    def user_state_dir(self):
+        return user_state_dir(self.appname, self.appauthor,
+                              version=self.version)
+
+    @property
+    def user_log_dir(self):
+        return user_log_dir(self.appname, self.appauthor,
+                            version=self.version)
+
+
+#---- internal support stuff
+
+def _get_win_folder_from_registry(csidl_name):
+    """This is a fallback technique at best. I'm not sure if using the
+    registry for this guarantees us the correct answer for all CSIDL_*
+    names.
+    """
+    if PY3:
+      import winreg as _winreg
+    else:
+      import _winreg
+
+    shell_folder_name = {
+        "CSIDL_APPDATA": "AppData",
+        "CSIDL_COMMON_APPDATA": "Common AppData",
+        "CSIDL_LOCAL_APPDATA": "Local AppData",
+    }[csidl_name]
+
+    key = _winreg.OpenKey(
+        _winreg.HKEY_CURRENT_USER,
+        r"Software\Microsoft\Windows\CurrentVersion\Explorer\Shell Folders"
+    )
+    dir, type = _winreg.QueryValueEx(key, shell_folder_name)
+    return dir
+
+
+def _get_win_folder_with_pywin32(csidl_name):
+    from win32com.shell import shellcon, shell
+    dir = shell.SHGetFolderPath(0, getattr(shellcon, csidl_name), 0, 0)
+    # Try to make this a unicode path because SHGetFolderPath does
+    # not return unicode strings when there is unicode data in the
+    # path.
+    try:
+        dir = unicode(dir)
+
+        # Downgrade to short path name if have highbit chars. See
+        # <http://bugs.activestate.com/show_bug.cgi?id=85099>.
+        has_high_char = False
+        for c in dir:
+            if ord(c) > 255:
+                has_high_char = True
+                break
+        if has_high_char:
+            try:
+                import win32api
+                dir = win32api.GetShortPathName(dir)
+            except ImportError:
+                pass
+    except UnicodeError:
+        pass
+    return dir
+
+
+def _get_win_folder_with_ctypes(csidl_name):
+    import ctypes
+
+    csidl_const = {
+        "CSIDL_APPDATA": 26,
+        "CSIDL_COMMON_APPDATA": 35,
+        "CSIDL_LOCAL_APPDATA": 28,
+    }[csidl_name]
+
+    buf = ctypes.create_unicode_buffer(1024)
+    ctypes.windll.shell32.SHGetFolderPathW(None, csidl_const, None, 0, buf)
+
+    # Downgrade to short path name if have highbit chars. See
+    # <http://bugs.activestate.com/show_bug.cgi?id=85099>.
+    has_high_char = False
+    for c in buf:
+        if ord(c) > 255:
+            has_high_char = True
+            break
+    if has_high_char:
+        buf2 = ctypes.create_unicode_buffer(1024)
+        if ctypes.windll.kernel32.GetShortPathNameW(buf.value, buf2, 1024):
+            buf = buf2
+
+    return buf.value
+
+def _get_win_folder_with_jna(csidl_name):
+    import array
+    from com.sun import jna
+    from com.sun.jna.platform import win32
+
+    buf_size = win32.WinDef.MAX_PATH * 2
+    buf = array.zeros('c', buf_size)
+    shell = win32.Shell32.INSTANCE
+    shell.SHGetFolderPath(None, getattr(win32.ShlObj, csidl_name), None, win32.ShlObj.SHGFP_TYPE_CURRENT, buf)
+    dir = jna.Native.toString(buf.tostring()).rstrip("\0")
+
+    # Downgrade to short path name if have highbit chars. See
+    # <http://bugs.activestate.com/show_bug.cgi?id=85099>.
+    has_high_char = False
+    for c in dir:
+        if ord(c) > 255:
+            has_high_char = True
+            break
+    if has_high_char:
+        buf = array.zeros('c', buf_size)
+        kernel = win32.Kernel32.INSTANCE
+        if kernel.GetShortPathName(dir, buf, buf_size):
+            dir = jna.Native.toString(buf.tostring()).rstrip("\0")
+
+    return dir
+
+if system == "win32":
+    try:
+        from ctypes import windll
+        _get_win_folder = _get_win_folder_with_ctypes
+    except ImportError:
+        try:
+            import com.sun.jna
+            _get_win_folder = _get_win_folder_with_jna
+        except ImportError:
+            _get_win_folder = _get_win_folder_from_registry
+
+
+def _win_path_to_bytes(path):
+    """Encode Windows paths to bytes. Only used on Python 2.
+
+    Motivation is to be consistent with other operating systems where paths
+    are also returned as bytes. This avoids problems mixing bytes and Unicode
+    elsewhere in the codebase. For more details and discussion see
+    <https://github.com/pypa/pip/issues/3463>.
+
+    If encoding using ASCII and MBCS fails, return the original Unicode path.
+    """
+    for encoding in ('ASCII', 'MBCS'):
+        try:
+            return path.encode(encoding)
+        except (UnicodeEncodeError, LookupError):
+            pass
+    return path
+
+
+#---- self test code
+
+if __name__ == "__main__":
+    appname = "MyApp"
+    appauthor = "MyCompany"
+
+    props = ("user_data_dir",
+             "user_config_dir",
+             "user_cache_dir",
+             "user_state_dir",
+             "user_log_dir",
+             "site_data_dir",
+             "site_config_dir")
+
+    print("-- app dirs %s --" % __version__)
+
+    print("-- app dirs (with optional 'version')")
+    dirs = AppDirs(appname, appauthor, version="1.0")
+    for prop in props:
+        print("%s: %s" % (prop, getattr(dirs, prop)))
+
+    print("\n-- app dirs (without optional 'version')")
+    dirs = AppDirs(appname, appauthor)
+    for prop in props:
+        print("%s: %s" % (prop, getattr(dirs, prop)))
+
+    print("\n-- app dirs (without optional 'appauthor')")
+    dirs = AppDirs(appname)
+    for prop in props:
+        print("%s: %s" % (prop, getattr(dirs, prop)))
+
+    print("\n-- app dirs (with disabled 'appauthor')")
+    dirs = AppDirs(appname, appauthor=False)
+    for prop in props:
+        print("%s: %s" % (prop, getattr(dirs, prop)))
Index: venv/Lib/site-packages/django/conf/locale/nl/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/nl/formats.py b/venv/Lib/site-packages/django/conf/locale/nl/formats.py
new file mode 100644
--- /dev/null	(date 1617030482564)
+++ b/venv/Lib/site-packages/django/conf/locale/nl/formats.py	(date 1617030482564)
@@ -0,0 +1,66 @@
+# This file is distributed under the same license as the Django package.
+#
+# The *_FORMAT strings use the Django date format syntax,
+# see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date
+DATE_FORMAT = 'j F Y'                   # '20 januari 2009'
+TIME_FORMAT = 'H:i'                     # '15:23'
+DATETIME_FORMAT = 'j F Y H:i'           # '20 januari 2009 15:23'
+YEAR_MONTH_FORMAT = 'F Y'               # 'januari 2009'
+MONTH_DAY_FORMAT = 'j F'                # '20 januari'
+SHORT_DATE_FORMAT = 'j-n-Y'             # '20-1-2009'
+SHORT_DATETIME_FORMAT = 'j-n-Y H:i'     # '20-1-2009 15:23'
+FIRST_DAY_OF_WEEK = 1                   # Monday (in Dutch 'maandag')
+
+# The *_INPUT_FORMATS strings use the Python strftime format syntax,
+# see https://docs.python.org/library/datetime.html#strftime-strptime-behavior
+DATE_INPUT_FORMATS = [
+    '%d-%m-%Y', '%d-%m-%y',             # '20-01-2009', '20-01-09'
+    '%d/%m/%Y', '%d/%m/%y',             # '20/01/2009', '20/01/09'
+    '%Y/%m/%d',                         # '2009/01/20'
+    # '%d %b %Y', '%d %b %y',           # '20 jan 2009', '20 jan 09'
+    # '%d %B %Y', '%d %B %y',           # '20 januari 2009', '20 januari 09'
+]
+# Kept ISO formats as one is in first position
+TIME_INPUT_FORMATS = [
+    '%H:%M:%S',                         # '15:23:35'
+    '%H:%M:%S.%f',                      # '15:23:35.000200'
+    '%H.%M:%S',                         # '15.23:35'
+    '%H.%M:%S.%f',                      # '15.23:35.000200'
+    '%H.%M',                            # '15.23'
+    '%H:%M',                            # '15:23'
+]
+DATETIME_INPUT_FORMATS = [
+    # With time in %H:%M:%S :
+    '%d-%m-%Y %H:%M:%S', '%d-%m-%y %H:%M:%S', '%Y-%m-%d %H:%M:%S',
+    # '20-01-2009 15:23:35', '20-01-09 15:23:35', '2009-01-20 15:23:35'
+    '%d/%m/%Y %H:%M:%S', '%d/%m/%y %H:%M:%S', '%Y/%m/%d %H:%M:%S',
+    # '20/01/2009 15:23:35', '20/01/09 15:23:35', '2009/01/20 15:23:35'
+    # '%d %b %Y %H:%M:%S', '%d %b %y %H:%M:%S',   # '20 jan 2009 15:23:35', '20 jan 09 15:23:35'
+    # '%d %B %Y %H:%M:%S', '%d %B %y %H:%M:%S',   # '20 januari 2009 15:23:35', '20 januari 2009 15:23:35'
+    # With time in %H:%M:%S.%f :
+    '%d-%m-%Y %H:%M:%S.%f', '%d-%m-%y %H:%M:%S.%f', '%Y-%m-%d %H:%M:%S.%f',
+    # '20-01-2009 15:23:35.000200', '20-01-09 15:23:35.000200', '2009-01-20 15:23:35.000200'
+    '%d/%m/%Y %H:%M:%S.%f', '%d/%m/%y %H:%M:%S.%f', '%Y/%m/%d %H:%M:%S.%f',
+    # '20/01/2009 15:23:35.000200', '20/01/09 15:23:35.000200', '2009/01/20 15:23:35.000200'
+    # With time in %H.%M:%S :
+    '%d-%m-%Y %H.%M:%S', '%d-%m-%y %H.%M:%S',   # '20-01-2009 15.23:35', '20-01-09 15.23:35'
+    '%d/%m/%Y %H.%M:%S', '%d/%m/%y %H.%M:%S',   # '20/01/2009 15.23:35', '20/01/09 15.23:35'
+    # '%d %b %Y %H.%M:%S', '%d %b %y %H.%M:%S',   # '20 jan 2009 15.23:35', '20 jan 09 15.23:35'
+    # '%d %B %Y %H.%M:%S', '%d %B %y %H.%M:%S',   # '20 januari 2009 15.23:35', '20 januari 2009 15.23:35'
+    # With time in %H.%M:%S.%f :
+    '%d-%m-%Y %H.%M:%S.%f', '%d-%m-%y %H.%M:%S.%f',   # '20-01-2009 15.23:35.000200', '20-01-09 15.23:35.000200'
+    '%d/%m/%Y %H.%M:%S.%f', '%d/%m/%y %H.%M:%S.%f',   # '20/01/2009 15.23:35.000200', '20/01/09 15.23:35.000200'
+    # With time in %H:%M :
+    '%d-%m-%Y %H:%M', '%d-%m-%y %H:%M', '%Y-%m-%d %H:%M',   # '20-01-2009 15:23', '20-01-09 15:23', '2009-01-20 15:23'
+    '%d/%m/%Y %H:%M', '%d/%m/%y %H:%M', '%Y/%m/%d %H:%M',   # '20/01/2009 15:23', '20/01/09 15:23', '2009/01/20 15:23'
+    # '%d %b %Y %H:%M', '%d %b %y %H:%M',         # '20 jan 2009 15:23', '20 jan 09 15:23'
+    # '%d %B %Y %H:%M', '%d %B %y %H:%M',         # '20 januari 2009 15:23', '20 januari 2009 15:23'
+    # With time in %H.%M :
+    '%d-%m-%Y %H.%M', '%d-%m-%y %H.%M',         # '20-01-2009 15.23', '20-01-09 15.23'
+    '%d/%m/%Y %H.%M', '%d/%m/%y %H.%M',         # '20/01/2009 15.23', '20/01/09 15.23'
+    # '%d %b %Y %H.%M', '%d %b %y %H.%M',         # '20 jan 2009 15.23', '20 jan 09 15.23'
+    # '%d %B %Y %H.%M', '%d %B %y %H.%M',         # '20 januari 2009 15.23', '20 januari 2009 15.23'
+]
+DECIMAL_SEPARATOR = ','
+THOUSAND_SEPARATOR = '.'
+NUMBER_GROUPING = 3
Index: venv/Lib/site-packages/django/conf/locale/nn/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/nn/formats.py b/venv/Lib/site-packages/django/conf/locale/nn/formats.py
new file mode 100644
--- /dev/null	(date 1617030482566)
+++ b/venv/Lib/site-packages/django/conf/locale/nn/formats.py	(date 1617030482566)
@@ -0,0 +1,36 @@
+# This file is distributed under the same license as the Django package.
+#
+# The *_FORMAT strings use the Django date format syntax,
+# see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date
+DATE_FORMAT = 'j. F Y'
+TIME_FORMAT = 'H:i'
+DATETIME_FORMAT = 'j. F Y H:i'
+YEAR_MONTH_FORMAT = 'F Y'
+MONTH_DAY_FORMAT = 'j. F'
+SHORT_DATE_FORMAT = 'd.m.Y'
+SHORT_DATETIME_FORMAT = 'd.m.Y H:i'
+FIRST_DAY_OF_WEEK = 1  # Monday
+
+# The *_INPUT_FORMATS strings use the Python strftime format syntax,
+# see https://docs.python.org/library/datetime.html#strftime-strptime-behavior
+# Kept ISO formats as they are in first position
+DATE_INPUT_FORMATS = [
+    '%Y-%m-%d', '%d.%m.%Y', '%d.%m.%y',  # '2006-10-25', '25.10.2006', '25.10.06'
+    # '%d. %b %Y', '%d %b %Y',            # '25. okt 2006', '25 okt 2006'
+    # '%d. %b. %Y', '%d %b. %Y',          # '25. okt. 2006', '25 okt. 2006'
+    # '%d. %B %Y', '%d %B %Y',            # '25. oktober 2006', '25 oktober 2006'
+]
+DATETIME_INPUT_FORMATS = [
+    '%Y-%m-%d %H:%M:%S',     # '2006-10-25 14:30:59'
+    '%Y-%m-%d %H:%M:%S.%f',  # '2006-10-25 14:30:59.000200'
+    '%Y-%m-%d %H:%M',        # '2006-10-25 14:30'
+    '%d.%m.%Y %H:%M:%S',     # '25.10.2006 14:30:59'
+    '%d.%m.%Y %H:%M:%S.%f',  # '25.10.2006 14:30:59.000200'
+    '%d.%m.%Y %H:%M',        # '25.10.2006 14:30'
+    '%d.%m.%y %H:%M:%S',     # '25.10.06 14:30:59'
+    '%d.%m.%y %H:%M:%S.%f',  # '25.10.06 14:30:59.000200'
+    '%d.%m.%y %H:%M',        # '25.10.06 14:30'
+]
+DECIMAL_SEPARATOR = ','
+THOUSAND_SEPARATOR = '\xa0'  # non-breaking space
+NUMBER_GROUPING = 3
Index: venv/Lib/site-packages/django/contrib/auth/handlers/modwsgi.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/auth/handlers/modwsgi.py b/venv/Lib/site-packages/django/contrib/auth/handlers/modwsgi.py
new file mode 100644
--- /dev/null	(date 1617030484054)
+++ b/venv/Lib/site-packages/django/contrib/auth/handlers/modwsgi.py	(date 1617030484054)
@@ -0,0 +1,43 @@
+from django import db
+from django.contrib import auth
+
+UserModel = auth.get_user_model()
+
+
+def check_password(environ, username, password):
+    """
+    Authenticate against Django's auth database.
+
+    mod_wsgi docs specify None, True, False as return value depending
+    on whether the user exists and authenticates.
+    """
+    # db connection state is managed similarly to the wsgi handler
+    # as mod_wsgi may call these functions outside of a request/response cycle
+    db.reset_queries()
+    try:
+        try:
+            user = UserModel._default_manager.get_by_natural_key(username)
+        except UserModel.DoesNotExist:
+            return None
+        if not user.is_active:
+            return None
+        return user.check_password(password)
+    finally:
+        db.close_old_connections()
+
+
+def groups_for_user(environ, username):
+    """
+    Authorize a user based on groups
+    """
+    db.reset_queries()
+    try:
+        try:
+            user = UserModel._default_manager.get_by_natural_key(username)
+        except UserModel.DoesNotExist:
+            return []
+        if not user.is_active:
+            return []
+        return [group.name.encode() for group in user.groups.all()]
+    finally:
+        db.close_old_connections()
Index: venv/Lib/site-packages/django/conf/locale/pl/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/pl/formats.py b/venv/Lib/site-packages/django/conf/locale/pl/formats.py
new file mode 100644
--- /dev/null	(date 1617030482570)
+++ b/venv/Lib/site-packages/django/conf/locale/pl/formats.py	(date 1617030482570)
@@ -0,0 +1,28 @@
+# This file is distributed under the same license as the Django package.
+#
+# The *_FORMAT strings use the Django date format syntax,
+# see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date
+DATE_FORMAT = 'j E Y'
+TIME_FORMAT = 'H:i'
+DATETIME_FORMAT = 'j E Y H:i'
+YEAR_MONTH_FORMAT = 'F Y'
+MONTH_DAY_FORMAT = 'j E'
+SHORT_DATE_FORMAT = 'd-m-Y'
+SHORT_DATETIME_FORMAT = 'd-m-Y  H:i'
+FIRST_DAY_OF_WEEK = 1  # Monday
+
+# The *_INPUT_FORMATS strings use the Python strftime format syntax,
+# see https://docs.python.org/library/datetime.html#strftime-strptime-behavior
+DATE_INPUT_FORMATS = [
+    '%d.%m.%Y', '%d.%m.%y',     # '25.10.2006', '25.10.06'
+    '%y-%m-%d',                 # '06-10-25'
+    # '%d. %B %Y', '%d. %b. %Y',  # '25. October 2006', '25. Oct. 2006'
+]
+DATETIME_INPUT_FORMATS = [
+    '%d.%m.%Y %H:%M:%S',     # '25.10.2006 14:30:59'
+    '%d.%m.%Y %H:%M:%S.%f',  # '25.10.2006 14:30:59.000200'
+    '%d.%m.%Y %H:%M',        # '25.10.2006 14:30'
+]
+DECIMAL_SEPARATOR = ','
+THOUSAND_SEPARATOR = ' '
+NUMBER_GROUPING = 3
Index: venv/Lib/site-packages/django/contrib/auth/management/__init__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/auth/management/__init__.py b/venv/Lib/site-packages/django/contrib/auth/management/__init__.py
new file mode 100644
--- /dev/null	(date 1617030484147)
+++ b/venv/Lib/site-packages/django/contrib/auth/management/__init__.py	(date 1617030484147)
@@ -0,0 +1,145 @@
+"""
+Creates permissions for all installed apps that need permissions.
+"""
+import getpass
+import unicodedata
+
+from django.apps import apps as global_apps
+from django.contrib.auth import get_permission_codename
+from django.contrib.contenttypes.management import create_contenttypes
+from django.core import exceptions
+from django.db import DEFAULT_DB_ALIAS, router
+
+
+def _get_all_permissions(opts):
+    """
+    Return (codename, name) for all permissions in the given opts.
+    """
+    return [*_get_builtin_permissions(opts), *opts.permissions]
+
+
+def _get_builtin_permissions(opts):
+    """
+    Return (codename, name) for all autogenerated permissions.
+    By default, this is ('add', 'change', 'delete', 'view')
+    """
+    perms = []
+    for action in opts.default_permissions:
+        perms.append((
+            get_permission_codename(action, opts),
+            'Can %s %s' % (action, opts.verbose_name_raw)
+        ))
+    return perms
+
+
+def create_permissions(app_config, verbosity=2, interactive=True, using=DEFAULT_DB_ALIAS, apps=global_apps, **kwargs):
+    if not app_config.models_module:
+        return
+
+    # Ensure that contenttypes are created for this app. Needed if
+    # 'django.contrib.auth' is in INSTALLED_APPS before
+    # 'django.contrib.contenttypes'.
+    create_contenttypes(app_config, verbosity=verbosity, interactive=interactive, using=using, apps=apps, **kwargs)
+
+    app_label = app_config.label
+    try:
+        app_config = apps.get_app_config(app_label)
+        ContentType = apps.get_model('contenttypes', 'ContentType')
+        Permission = apps.get_model('auth', 'Permission')
+    except LookupError:
+        return
+
+    if not router.allow_migrate_model(using, Permission):
+        return
+
+    # This will hold the permissions we're looking for as
+    # (content_type, (codename, name))
+    searched_perms = []
+    # The codenames and ctypes that should exist.
+    ctypes = set()
+    for klass in app_config.get_models():
+        # Force looking up the content types in the current database
+        # before creating foreign keys to them.
+        ctype = ContentType.objects.db_manager(using).get_for_model(klass, for_concrete_model=False)
+
+        ctypes.add(ctype)
+        for perm in _get_all_permissions(klass._meta):
+            searched_perms.append((ctype, perm))
+
+    # Find all the Permissions that have a content_type for a model we're
+    # looking for.  We don't need to check for codenames since we already have
+    # a list of the ones we're going to create.
+    all_perms = set(Permission.objects.using(using).filter(
+        content_type__in=ctypes,
+    ).values_list(
+        "content_type", "codename"
+    ))
+
+    perms = [
+        Permission(codename=codename, name=name, content_type=ct)
+        for ct, (codename, name) in searched_perms
+        if (ct.pk, codename) not in all_perms
+    ]
+    Permission.objects.using(using).bulk_create(perms)
+    if verbosity >= 2:
+        for perm in perms:
+            print("Adding permission '%s'" % perm)
+
+
+def get_system_username():
+    """
+    Return the current system user's username, or an empty string if the
+    username could not be determined.
+    """
+    try:
+        result = getpass.getuser()
+    except (ImportError, KeyError):
+        # KeyError will be raised by os.getpwuid() (called by getuser())
+        # if there is no corresponding entry in the /etc/passwd file
+        # (a very restricted chroot environment, for example).
+        return ''
+    return result
+
+
+def get_default_username(check_db=True):
+    """
+    Try to determine the current system user's username to use as a default.
+
+    :param check_db: If ``True``, requires that the username does not match an
+        existing ``auth.User`` (otherwise returns an empty string).
+    :returns: The username, or an empty string if no username can be
+        determined.
+    """
+    # This file is used in apps.py, it should not trigger models import.
+    from django.contrib.auth import models as auth_app
+
+    # If the User model has been swapped out, we can't make any assumptions
+    # about the default user name.
+    if auth_app.User._meta.swapped:
+        return ''
+
+    default_username = get_system_username()
+    try:
+        default_username = (
+            unicodedata.normalize('NFKD', default_username)
+            .encode('ascii', 'ignore').decode('ascii')
+            .replace(' ', '').lower()
+        )
+    except UnicodeDecodeError:
+        return ''
+
+    # Run the username validator
+    try:
+        auth_app.User._meta.get_field('username').run_validators(default_username)
+    except exceptions.ValidationError:
+        return ''
+
+    # Don't return the default username if it is already taken.
+    if check_db and default_username:
+        try:
+            auth_app.User._default_manager.get(username=default_username)
+        except auth_app.User.DoesNotExist:
+            pass
+        else:
+            return ''
+    return default_username
Index: venv/Lib/site-packages/django/conf/locale/pt/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/pt/formats.py b/venv/Lib/site-packages/django/conf/locale/pt/formats.py
new file mode 100644
--- /dev/null	(date 1617030482572)
+++ b/venv/Lib/site-packages/django/conf/locale/pt/formats.py	(date 1617030482572)
@@ -0,0 +1,35 @@
+# This file is distributed under the same license as the Django package.
+#
+# The *_FORMAT strings use the Django date format syntax,
+# see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date
+DATE_FORMAT = r'j \d\e F \d\e Y'
+TIME_FORMAT = 'H:i'
+DATETIME_FORMAT = r'j \d\e F \d\e Y à\s H:i'
+YEAR_MONTH_FORMAT = r'F \d\e Y'
+MONTH_DAY_FORMAT = r'j \d\e F'
+SHORT_DATE_FORMAT = 'd/m/Y'
+SHORT_DATETIME_FORMAT = 'd/m/Y H:i'
+FIRST_DAY_OF_WEEK = 0  # Sunday
+
+# The *_INPUT_FORMATS strings use the Python strftime format syntax,
+# see https://docs.python.org/library/datetime.html#strftime-strptime-behavior
+# Kept ISO formats as they are in first position
+DATE_INPUT_FORMATS = [
+    '%Y-%m-%d', '%d/%m/%Y', '%d/%m/%y',   # '2006-10-25', '25/10/2006', '25/10/06'
+    # '%d de %b de %Y', '%d de %b, %Y',   # '25 de Out de 2006', '25 Out, 2006'
+    # '%d de %B de %Y', '%d de %B, %Y',   # '25 de Outubro de 2006', '25 de Outubro, 2006'
+]
+DATETIME_INPUT_FORMATS = [
+    '%Y-%m-%d %H:%M:%S',     # '2006-10-25 14:30:59'
+    '%Y-%m-%d %H:%M:%S.%f',  # '2006-10-25 14:30:59.000200'
+    '%Y-%m-%d %H:%M',        # '2006-10-25 14:30'
+    '%d/%m/%Y %H:%M:%S',     # '25/10/2006 14:30:59'
+    '%d/%m/%Y %H:%M:%S.%f',  # '25/10/2006 14:30:59.000200'
+    '%d/%m/%Y %H:%M',        # '25/10/2006 14:30'
+    '%d/%m/%y %H:%M:%S',     # '25/10/06 14:30:59'
+    '%d/%m/%y %H:%M:%S.%f',  # '25/10/06 14:30:59.000200'
+    '%d/%m/%y %H:%M',        # '25/10/06 14:30'
+]
+DECIMAL_SEPARATOR = ','
+THOUSAND_SEPARATOR = '.'
+NUMBER_GROUPING = 3
Index: venv/Lib/site-packages/django/contrib/auth/migrations/0001_initial.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/auth/migrations/0001_initial.py b/venv/Lib/site-packages/django/contrib/auth/migrations/0001_initial.py
new file mode 100644
--- /dev/null	(date 1617030484148)
+++ b/venv/Lib/site-packages/django/contrib/auth/migrations/0001_initial.py	(date 1617030484148)
@@ -0,0 +1,104 @@
+import django.contrib.auth.models
+from django.contrib.auth import validators
+from django.db import migrations, models
+from django.utils import timezone
+
+
+class Migration(migrations.Migration):
+
+    dependencies = [
+        ('contenttypes', '__first__'),
+    ]
+
+    operations = [
+        migrations.CreateModel(
+            name='Permission',
+            fields=[
+                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),
+                ('name', models.CharField(max_length=50, verbose_name='name')),
+                ('content_type', models.ForeignKey(
+                    to='contenttypes.ContentType',
+                    on_delete=models.CASCADE,
+                    to_field='id',
+                    verbose_name='content type',
+                )),
+                ('codename', models.CharField(max_length=100, verbose_name='codename')),
+            ],
+            options={
+                'ordering': ['content_type__app_label', 'content_type__model', 'codename'],
+                'unique_together': {('content_type', 'codename')},
+                'verbose_name': 'permission',
+                'verbose_name_plural': 'permissions',
+            },
+            managers=[
+                ('objects', django.contrib.auth.models.PermissionManager()),
+            ],
+        ),
+        migrations.CreateModel(
+            name='Group',
+            fields=[
+                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),
+                ('name', models.CharField(unique=True, max_length=80, verbose_name='name')),
+                ('permissions', models.ManyToManyField(to='auth.Permission', verbose_name='permissions', blank=True)),
+            ],
+            options={
+                'verbose_name': 'group',
+                'verbose_name_plural': 'groups',
+            },
+            managers=[
+                ('objects', django.contrib.auth.models.GroupManager()),
+            ],
+        ),
+        migrations.CreateModel(
+            name='User',
+            fields=[
+                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),
+                ('password', models.CharField(max_length=128, verbose_name='password')),
+                ('last_login', models.DateTimeField(default=timezone.now, verbose_name='last login')),
+                ('is_superuser', models.BooleanField(
+                    default=False,
+                    help_text='Designates that this user has all permissions without explicitly assigning them.',
+                    verbose_name='superuser status'
+                )),
+                ('username', models.CharField(
+                    help_text='Required. 30 characters or fewer. Letters, digits and @/./+/-/_ only.', unique=True,
+                    max_length=30, verbose_name='username',
+                    validators=[validators.UnicodeUsernameValidator()],
+                )),
+                ('first_name', models.CharField(max_length=30, verbose_name='first name', blank=True)),
+                ('last_name', models.CharField(max_length=30, verbose_name='last name', blank=True)),
+                ('email', models.EmailField(max_length=75, verbose_name='email address', blank=True)),
+                ('is_staff', models.BooleanField(
+                    default=False, help_text='Designates whether the user can log into this admin site.',
+                    verbose_name='staff status'
+                )),
+                ('is_active', models.BooleanField(
+                    default=True, verbose_name='active', help_text=(
+                        'Designates whether this user should be treated as active. Unselect this instead of deleting '
+                        'accounts.'
+                    )
+                )),
+                ('date_joined', models.DateTimeField(default=timezone.now, verbose_name='date joined')),
+                ('groups', models.ManyToManyField(
+                    to='auth.Group', verbose_name='groups', blank=True, related_name='user_set',
+                    related_query_name='user', help_text=(
+                        'The groups this user belongs to. A user will get all permissions granted to each of their '
+                        'groups.'
+                    )
+                )),
+                ('user_permissions', models.ManyToManyField(
+                    to='auth.Permission', verbose_name='user permissions', blank=True,
+                    help_text='Specific permissions for this user.', related_name='user_set',
+                    related_query_name='user')
+                 ),
+            ],
+            options={
+                'swappable': 'AUTH_USER_MODEL',
+                'verbose_name': 'user',
+                'verbose_name_plural': 'users',
+            },
+            managers=[
+                ('objects', django.contrib.auth.models.UserManager()),
+            ],
+        ),
+    ]
Index: venv/Lib/site-packages/django/contrib/auth/migrations/0002_alter_permission_name_max_length.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/auth/migrations/0002_alter_permission_name_max_length.py b/venv/Lib/site-packages/django/contrib/auth/migrations/0002_alter_permission_name_max_length.py
new file mode 100644
--- /dev/null	(date 1617030484148)
+++ b/venv/Lib/site-packages/django/contrib/auth/migrations/0002_alter_permission_name_max_length.py	(date 1617030484148)
@@ -0,0 +1,16 @@
+from django.db import migrations, models
+
+
+class Migration(migrations.Migration):
+
+    dependencies = [
+        ('auth', '0001_initial'),
+    ]
+
+    operations = [
+        migrations.AlterField(
+            model_name='permission',
+            name='name',
+            field=models.CharField(max_length=255, verbose_name='name'),
+        ),
+    ]
Index: venv/Lib/site-packages/django/contrib/auth/migrations/0003_alter_user_email_max_length.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/auth/migrations/0003_alter_user_email_max_length.py b/venv/Lib/site-packages/django/contrib/auth/migrations/0003_alter_user_email_max_length.py
new file mode 100644
--- /dev/null	(date 1617030484149)
+++ b/venv/Lib/site-packages/django/contrib/auth/migrations/0003_alter_user_email_max_length.py	(date 1617030484149)
@@ -0,0 +1,16 @@
+from django.db import migrations, models
+
+
+class Migration(migrations.Migration):
+
+    dependencies = [
+        ('auth', '0002_alter_permission_name_max_length'),
+    ]
+
+    operations = [
+        migrations.AlterField(
+            model_name='user',
+            name='email',
+            field=models.EmailField(max_length=254, verbose_name='email address', blank=True),
+        ),
+    ]
Index: venv/Lib/site-packages/django/conf/locale/ro/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/ro/formats.py b/venv/Lib/site-packages/django/conf/locale/ro/formats.py
new file mode 100644
--- /dev/null	(date 1617030482575)
+++ b/venv/Lib/site-packages/django/conf/locale/ro/formats.py	(date 1617030482575)
@@ -0,0 +1,35 @@
+# This file is distributed under the same license as the Django package.
+#
+# The *_FORMAT strings use the Django date format syntax,
+# see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date
+DATE_FORMAT = 'j F Y'
+TIME_FORMAT = 'H:i'
+DATETIME_FORMAT = 'j F Y, H:i'
+YEAR_MONTH_FORMAT = 'F Y'
+MONTH_DAY_FORMAT = 'j F'
+SHORT_DATE_FORMAT = 'd.m.Y'
+SHORT_DATETIME_FORMAT = 'd.m.Y, H:i'
+FIRST_DAY_OF_WEEK = 1
+
+# The *_INPUT_FORMATS strings use the Python strftime format syntax,
+# see https://docs.python.org/library/datetime.html#strftime-strptime-behavior
+DATE_INPUT_FORMATS = [
+    '%d.%m.%Y',
+    '%d.%b.%Y',
+    '%d %B %Y',
+    '%A, %d %B %Y',
+]
+TIME_INPUT_FORMATS = [
+    '%H:%M',
+    '%H:%M:%S',
+    '%H:%M:%S.%f',
+]
+DATETIME_INPUT_FORMATS = [
+    '%d.%m.%Y, %H:%M',
+    '%d.%m.%Y, %H:%M:%S',
+    '%d.%B.%Y, %H:%M',
+    '%d.%B.%Y, %H:%M:%S',
+]
+DECIMAL_SEPARATOR = ','
+THOUSAND_SEPARATOR = '.'
+NUMBER_GROUPING = 3
Index: venv/Lib/site-packages/django/contrib/auth/migrations/0004_alter_user_username_opts.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/auth/migrations/0004_alter_user_username_opts.py b/venv/Lib/site-packages/django/contrib/auth/migrations/0004_alter_user_username_opts.py
new file mode 100644
--- /dev/null	(date 1617030484149)
+++ b/venv/Lib/site-packages/django/contrib/auth/migrations/0004_alter_user_username_opts.py	(date 1617030484149)
@@ -0,0 +1,23 @@
+from django.contrib.auth import validators
+from django.db import migrations, models
+
+
+class Migration(migrations.Migration):
+
+    dependencies = [
+        ('auth', '0003_alter_user_email_max_length'),
+    ]
+
+    # No database changes; modifies validators and error_messages (#13147).
+    operations = [
+        migrations.AlterField(
+            model_name='user',
+            name='username',
+            field=models.CharField(
+                error_messages={'unique': 'A user with that username already exists.'}, max_length=30,
+                validators=[validators.UnicodeUsernameValidator()],
+                help_text='Required. 30 characters or fewer. Letters, digits and @/./+/-/_ only.',
+                unique=True, verbose_name='username'
+            ),
+        ),
+    ]
Index: venv/Lib/site-packages/django/contrib/auth/migrations/0005_alter_user_last_login_null.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/auth/migrations/0005_alter_user_last_login_null.py b/venv/Lib/site-packages/django/contrib/auth/migrations/0005_alter_user_last_login_null.py
new file mode 100644
--- /dev/null	(date 1617030484150)
+++ b/venv/Lib/site-packages/django/contrib/auth/migrations/0005_alter_user_last_login_null.py	(date 1617030484150)
@@ -0,0 +1,16 @@
+from django.db import migrations, models
+
+
+class Migration(migrations.Migration):
+
+    dependencies = [
+        ('auth', '0004_alter_user_username_opts'),
+    ]
+
+    operations = [
+        migrations.AlterField(
+            model_name='user',
+            name='last_login',
+            field=models.DateTimeField(null=True, verbose_name='last login', blank=True),
+        ),
+    ]
Index: venv/Lib/site-packages/django/contrib/auth/migrations/0006_require_contenttypes_0002.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/auth/migrations/0006_require_contenttypes_0002.py b/venv/Lib/site-packages/django/contrib/auth/migrations/0006_require_contenttypes_0002.py
new file mode 100644
--- /dev/null	(date 1617030484150)
+++ b/venv/Lib/site-packages/django/contrib/auth/migrations/0006_require_contenttypes_0002.py	(date 1617030484150)
@@ -0,0 +1,14 @@
+from django.db import migrations
+
+
+class Migration(migrations.Migration):
+
+    dependencies = [
+        ('auth', '0005_alter_user_last_login_null'),
+        ('contenttypes', '0002_remove_content_type_name'),
+    ]
+
+    operations = [
+        # Ensure the contenttypes migration is applied before sending
+        # post_migrate signals (which create ContentTypes).
+    ]
Index: venv/Lib/site-packages/django/contrib/auth/migrations/0007_alter_validators_add_error_messages.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/auth/migrations/0007_alter_validators_add_error_messages.py b/venv/Lib/site-packages/django/contrib/auth/migrations/0007_alter_validators_add_error_messages.py
new file mode 100644
--- /dev/null	(date 1617030484150)
+++ b/venv/Lib/site-packages/django/contrib/auth/migrations/0007_alter_validators_add_error_messages.py	(date 1617030484150)
@@ -0,0 +1,24 @@
+from django.contrib.auth import validators
+from django.db import migrations, models
+
+
+class Migration(migrations.Migration):
+
+    dependencies = [
+        ('auth', '0006_require_contenttypes_0002'),
+    ]
+
+    operations = [
+        migrations.AlterField(
+            model_name='user',
+            name='username',
+            field=models.CharField(
+                error_messages={'unique': 'A user with that username already exists.'},
+                help_text='Required. 30 characters or fewer. Letters, digits and @/./+/-/_ only.',
+                max_length=30,
+                unique=True,
+                validators=[validators.UnicodeUsernameValidator()],
+                verbose_name='username',
+            ),
+        ),
+    ]
Index: venv/Lib/site-packages/django/conf/locale/ru/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/ru/formats.py b/venv/Lib/site-packages/django/conf/locale/ru/formats.py
new file mode 100644
--- /dev/null	(date 1617030482577)
+++ b/venv/Lib/site-packages/django/conf/locale/ru/formats.py	(date 1617030482577)
@@ -0,0 +1,30 @@
+# This file is distributed under the same license as the Django package.
+#
+# The *_FORMAT strings use the Django date format syntax,
+# see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date
+DATE_FORMAT = 'j E Y г.'
+TIME_FORMAT = 'G:i'
+DATETIME_FORMAT = 'j E Y г. G:i'
+YEAR_MONTH_FORMAT = 'F Y г.'
+MONTH_DAY_FORMAT = 'j F'
+SHORT_DATE_FORMAT = 'd.m.Y'
+SHORT_DATETIME_FORMAT = 'd.m.Y H:i'
+FIRST_DAY_OF_WEEK = 1  # Monday
+
+# The *_INPUT_FORMATS strings use the Python strftime format syntax,
+# see https://docs.python.org/library/datetime.html#strftime-strptime-behavior
+DATE_INPUT_FORMATS = [
+    '%d.%m.%Y',  # '25.10.2006'
+    '%d.%m.%y',  # '25.10.06'
+]
+DATETIME_INPUT_FORMATS = [
+    '%d.%m.%Y %H:%M:%S',     # '25.10.2006 14:30:59'
+    '%d.%m.%Y %H:%M:%S.%f',  # '25.10.2006 14:30:59.000200'
+    '%d.%m.%Y %H:%M',        # '25.10.2006 14:30'
+    '%d.%m.%y %H:%M:%S',     # '25.10.06 14:30:59'
+    '%d.%m.%y %H:%M:%S.%f',  # '25.10.06 14:30:59.000200'
+    '%d.%m.%y %H:%M',        # '25.10.06 14:30'
+]
+DECIMAL_SEPARATOR = ','
+THOUSAND_SEPARATOR = '\xa0'  # non-breaking space
+NUMBER_GROUPING = 3
Index: venv/Lib/site-packages/django/contrib/auth/migrations/0008_alter_user_username_max_length.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/auth/migrations/0008_alter_user_username_max_length.py b/venv/Lib/site-packages/django/contrib/auth/migrations/0008_alter_user_username_max_length.py
new file mode 100644
--- /dev/null	(date 1617030484151)
+++ b/venv/Lib/site-packages/django/contrib/auth/migrations/0008_alter_user_username_max_length.py	(date 1617030484151)
@@ -0,0 +1,24 @@
+from django.contrib.auth import validators
+from django.db import migrations, models
+
+
+class Migration(migrations.Migration):
+
+    dependencies = [
+        ('auth', '0007_alter_validators_add_error_messages'),
+    ]
+
+    operations = [
+        migrations.AlterField(
+            model_name='user',
+            name='username',
+            field=models.CharField(
+                error_messages={'unique': 'A user with that username already exists.'},
+                help_text='Required. 150 characters or fewer. Letters, digits and @/./+/-/_ only.',
+                max_length=150,
+                unique=True,
+                validators=[validators.UnicodeUsernameValidator()],
+                verbose_name='username',
+            ),
+        ),
+    ]
Index: venv/Lib/site-packages/django/contrib/auth/migrations/0009_alter_user_last_name_max_length.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/auth/migrations/0009_alter_user_last_name_max_length.py b/venv/Lib/site-packages/django/contrib/auth/migrations/0009_alter_user_last_name_max_length.py
new file mode 100644
--- /dev/null	(date 1617030484151)
+++ b/venv/Lib/site-packages/django/contrib/auth/migrations/0009_alter_user_last_name_max_length.py	(date 1617030484151)
@@ -0,0 +1,16 @@
+from django.db import migrations, models
+
+
+class Migration(migrations.Migration):
+
+    dependencies = [
+        ('auth', '0008_alter_user_username_max_length'),
+    ]
+
+    operations = [
+        migrations.AlterField(
+            model_name='user',
+            name='last_name',
+            field=models.CharField(blank=True, max_length=150, verbose_name='last name'),
+        ),
+    ]
Index: venv/Lib/site-packages/django/contrib/auth/migrations/0010_alter_group_name_max_length.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/auth/migrations/0010_alter_group_name_max_length.py b/venv/Lib/site-packages/django/contrib/auth/migrations/0010_alter_group_name_max_length.py
new file mode 100644
--- /dev/null	(date 1617030484151)
+++ b/venv/Lib/site-packages/django/contrib/auth/migrations/0010_alter_group_name_max_length.py	(date 1617030484151)
@@ -0,0 +1,16 @@
+from django.db import migrations, models
+
+
+class Migration(migrations.Migration):
+
+    dependencies = [
+        ('auth', '0009_alter_user_last_name_max_length'),
+    ]
+
+    operations = [
+        migrations.AlterField(
+            model_name='group',
+            name='name',
+            field=models.CharField(max_length=150, unique=True, verbose_name='name'),
+        ),
+    ]
Index: venv/Lib/site-packages/django/contrib/auth/migrations/0011_update_proxy_permissions.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/auth/migrations/0011_update_proxy_permissions.py b/venv/Lib/site-packages/django/contrib/auth/migrations/0011_update_proxy_permissions.py
new file mode 100644
--- /dev/null	(date 1617030484152)
+++ b/venv/Lib/site-packages/django/contrib/auth/migrations/0011_update_proxy_permissions.py	(date 1617030484152)
@@ -0,0 +1,69 @@
+import sys
+
+from django.core.management.color import color_style
+from django.db import IntegrityError, migrations, transaction
+from django.db.models import Q
+
+WARNING = """
+    A problem arose migrating proxy model permissions for {old} to {new}.
+
+      Permission(s) for {new} already existed.
+      Codenames Q: {query}
+
+    Ensure to audit ALL permissions for {old} and {new}.
+"""
+
+
+def update_proxy_model_permissions(apps, schema_editor, reverse=False):
+    """
+    Update the content_type of proxy model permissions to use the ContentType
+    of the proxy model.
+    """
+    style = color_style()
+    Permission = apps.get_model('auth', 'Permission')
+    ContentType = apps.get_model('contenttypes', 'ContentType')
+    alias = schema_editor.connection.alias
+    for Model in apps.get_models():
+        opts = Model._meta
+        if not opts.proxy:
+            continue
+        proxy_default_permissions_codenames = [
+            '%s_%s' % (action, opts.model_name)
+            for action in opts.default_permissions
+        ]
+        permissions_query = Q(codename__in=proxy_default_permissions_codenames)
+        for codename, name in opts.permissions:
+            permissions_query = permissions_query | Q(codename=codename, name=name)
+        content_type_manager = ContentType.objects.db_manager(alias)
+        concrete_content_type = content_type_manager.get_for_model(Model, for_concrete_model=True)
+        proxy_content_type = content_type_manager.get_for_model(Model, for_concrete_model=False)
+        old_content_type = proxy_content_type if reverse else concrete_content_type
+        new_content_type = concrete_content_type if reverse else proxy_content_type
+        try:
+            with transaction.atomic(using=alias):
+                Permission.objects.using(alias).filter(
+                    permissions_query,
+                    content_type=old_content_type,
+                ).update(content_type=new_content_type)
+        except IntegrityError:
+            old = '{}_{}'.format(old_content_type.app_label, old_content_type.model)
+            new = '{}_{}'.format(new_content_type.app_label, new_content_type.model)
+            sys.stdout.write(style.WARNING(WARNING.format(old=old, new=new, query=permissions_query)))
+
+
+def revert_proxy_model_permissions(apps, schema_editor):
+    """
+    Update the content_type of proxy model permissions to use the ContentType
+    of the concrete model.
+    """
+    update_proxy_model_permissions(apps, schema_editor, reverse=True)
+
+
+class Migration(migrations.Migration):
+    dependencies = [
+        ('auth', '0010_alter_group_name_max_length'),
+        ('contenttypes', '0002_remove_content_type_name'),
+    ]
+    operations = [
+        migrations.RunPython(update_proxy_model_permissions, revert_proxy_model_permissions),
+    ]
Index: venv/Lib/site-packages/django/conf/locale/sk/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/sk/formats.py b/venv/Lib/site-packages/django/conf/locale/sk/formats.py
new file mode 100644
--- /dev/null	(date 1617030482578)
+++ b/venv/Lib/site-packages/django/conf/locale/sk/formats.py	(date 1617030482578)
@@ -0,0 +1,28 @@
+# This file is distributed under the same license as the Django package.
+#
+# The *_FORMAT strings use the Django date format syntax,
+# see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date
+DATE_FORMAT = 'j. F Y'
+TIME_FORMAT = 'G:i'
+DATETIME_FORMAT = 'j. F Y G:i'
+YEAR_MONTH_FORMAT = 'F Y'
+MONTH_DAY_FORMAT = 'j. F'
+SHORT_DATE_FORMAT = 'd.m.Y'
+SHORT_DATETIME_FORMAT = 'd.m.Y G:i'
+FIRST_DAY_OF_WEEK = 1  # Monday
+
+# The *_INPUT_FORMATS strings use the Python strftime format syntax,
+# see https://docs.python.org/library/datetime.html#strftime-strptime-behavior
+DATE_INPUT_FORMATS = [
+    '%d.%m.%Y', '%d.%m.%y',     # '25.10.2006', '25.10.06'
+    '%y-%m-%d',                 # '06-10-25'
+    # '%d. %B %Y', '%d. %b. %Y',  # '25. October 2006', '25. Oct. 2006'
+]
+DATETIME_INPUT_FORMATS = [
+    '%d.%m.%Y %H:%M:%S',     # '25.10.2006 14:30:59'
+    '%d.%m.%Y %H:%M:%S.%f',  # '25.10.2006 14:30:59.000200'
+    '%d.%m.%Y %H:%M',        # '25.10.2006 14:30'
+]
+DECIMAL_SEPARATOR = ','
+THOUSAND_SEPARATOR = '\xa0'  # non-breaking space
+NUMBER_GROUPING = 3
Index: venv/Lib/site-packages/django/contrib/auth/migrations/0012_alter_user_first_name_max_length.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/auth/migrations/0012_alter_user_first_name_max_length.py b/venv/Lib/site-packages/django/contrib/auth/migrations/0012_alter_user_first_name_max_length.py
new file mode 100644
--- /dev/null	(date 1617030484152)
+++ b/venv/Lib/site-packages/django/contrib/auth/migrations/0012_alter_user_first_name_max_length.py	(date 1617030484152)
@@ -0,0 +1,16 @@
+from django.db import migrations, models
+
+
+class Migration(migrations.Migration):
+
+    dependencies = [
+        ('auth', '0011_update_proxy_permissions'),
+    ]
+
+    operations = [
+        migrations.AlterField(
+            model_name='user',
+            name='first_name',
+            field=models.CharField(blank=True, max_length=150, verbose_name='first name'),
+        ),
+    ]
Index: venv/Lib/site-packages/django/conf/locale/sl/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/sl/formats.py b/venv/Lib/site-packages/django/conf/locale/sl/formats.py
new file mode 100644
--- /dev/null	(date 1617030482580)
+++ b/venv/Lib/site-packages/django/conf/locale/sl/formats.py	(date 1617030482580)
@@ -0,0 +1,42 @@
+# This file is distributed under the same license as the Django package.
+#
+# The *_FORMAT strings use the Django date format syntax,
+# see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date
+DATE_FORMAT = 'd. F Y'
+TIME_FORMAT = 'H:i'
+DATETIME_FORMAT = 'j. F Y. H:i'
+YEAR_MONTH_FORMAT = 'F Y'
+MONTH_DAY_FORMAT = 'j. F'
+SHORT_DATE_FORMAT = 'j. M. Y'
+SHORT_DATETIME_FORMAT = 'j.n.Y. H:i'
+FIRST_DAY_OF_WEEK = 0
+
+# The *_INPUT_FORMATS strings use the Python strftime format syntax,
+# see https://docs.python.org/library/datetime.html#strftime-strptime-behavior
+DATE_INPUT_FORMATS = [
+    '%d.%m.%Y', '%d.%m.%y',         # '25.10.2006', '25.10.06'
+    '%d-%m-%Y',                     # '25-10-2006'
+    '%d. %m. %Y', '%d. %m. %y',     # '25. 10. 2006', '25. 10. 06'
+]
+
+DATETIME_INPUT_FORMATS = [
+    '%d.%m.%Y %H:%M:%S',            # '25.10.2006 14:30:59'
+    '%d.%m.%Y %H:%M:%S.%f',         # '25.10.2006 14:30:59.000200'
+    '%d.%m.%Y %H:%M',               # '25.10.2006 14:30'
+    '%d.%m.%y %H:%M:%S',            # '25.10.06 14:30:59'
+    '%d.%m.%y %H:%M:%S.%f',         # '25.10.06 14:30:59.000200'
+    '%d.%m.%y %H:%M',                # '25.10.06 14:30'
+    '%d-%m-%Y %H:%M:%S',            # '25-10-2006 14:30:59'
+    '%d-%m-%Y %H:%M:%S.%f',         # '25-10-2006 14:30:59.000200'
+    '%d-%m-%Y %H:%M',               # '25-10-2006 14:30'
+    '%d. %m. %Y %H:%M:%S',          # '25. 10. 2006 14:30:59'
+    '%d. %m. %Y %H:%M:%S.%f',       # '25. 10. 2006 14:30:59.000200'
+    '%d. %m. %Y %H:%M',             # '25. 10. 2006 14:30'
+    '%d. %m. %y %H:%M:%S',          # '25. 10. 06 14:30:59'
+    '%d. %m. %y %H:%M:%S.%f',       # '25. 10. 06 14:30:59.000200'
+    '%d. %m. %y %H:%M',             # '25. 10. 06 14:30'
+]
+
+DECIMAL_SEPARATOR = ','
+THOUSAND_SEPARATOR = '.'
+NUMBER_GROUPING = 3
Index: venv/Lib/site-packages/django/conf/locale/sq/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/sq/formats.py b/venv/Lib/site-packages/django/conf/locale/sq/formats.py
new file mode 100644
--- /dev/null	(date 1617030482582)
+++ b/venv/Lib/site-packages/django/conf/locale/sq/formats.py	(date 1617030482582)
@@ -0,0 +1,21 @@
+# This file is distributed under the same license as the Django package.
+#
+# The *_FORMAT strings use the Django date format syntax,
+# see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date
+DATE_FORMAT = 'd F Y'
+TIME_FORMAT = 'g.i.A'
+# DATETIME_FORMAT =
+YEAR_MONTH_FORMAT = 'F Y'
+MONTH_DAY_FORMAT = 'j F'
+SHORT_DATE_FORMAT = 'Y-m-d'
+# SHORT_DATETIME_FORMAT =
+# FIRST_DAY_OF_WEEK =
+
+# The *_INPUT_FORMATS strings use the Python strftime format syntax,
+# see https://docs.python.org/library/datetime.html#strftime-strptime-behavior
+# DATE_INPUT_FORMATS =
+# TIME_INPUT_FORMATS =
+# DATETIME_INPUT_FORMATS =
+DECIMAL_SEPARATOR = ','
+THOUSAND_SEPARATOR = '.'
+# NUMBER_GROUPING =
Index: venv/Lib/site-packages/django/conf/locale/sr/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/sr/formats.py b/venv/Lib/site-packages/django/conf/locale/sr/formats.py
new file mode 100644
--- /dev/null	(date 1617030482583)
+++ b/venv/Lib/site-packages/django/conf/locale/sr/formats.py	(date 1617030482583)
@@ -0,0 +1,39 @@
+# This file is distributed under the same license as the Django package.
+#
+# The *_FORMAT strings use the Django date format syntax,
+# see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date
+DATE_FORMAT = 'j. F Y.'
+TIME_FORMAT = 'H:i'
+DATETIME_FORMAT = 'j. F Y. H:i'
+YEAR_MONTH_FORMAT = 'F Y.'
+MONTH_DAY_FORMAT = 'j. F'
+SHORT_DATE_FORMAT = 'j.m.Y.'
+SHORT_DATETIME_FORMAT = 'j.m.Y. H:i'
+FIRST_DAY_OF_WEEK = 1
+
+# The *_INPUT_FORMATS strings use the Python strftime format syntax,
+# see https://docs.python.org/library/datetime.html#strftime-strptime-behavior
+DATE_INPUT_FORMATS = [
+    '%d.%m.%Y.', '%d.%m.%y.',       # '25.10.2006.', '25.10.06.'
+    '%d. %m. %Y.', '%d. %m. %y.',   # '25. 10. 2006.', '25. 10. 06.'
+    # '%d. %b %y.', '%d. %B %y.',     # '25. Oct 06.', '25. October 06.'
+    # '%d. %b \'%y.', '%d. %B \'%y.', # '25. Oct '06.', '25. October '06.'
+    # '%d. %b %Y.', '%d. %B %Y.',     # '25. Oct 2006.', '25. October 2006.'
+]
+DATETIME_INPUT_FORMATS = [
+    '%d.%m.%Y. %H:%M:%S',       # '25.10.2006. 14:30:59'
+    '%d.%m.%Y. %H:%M:%S.%f',    # '25.10.2006. 14:30:59.000200'
+    '%d.%m.%Y. %H:%M',          # '25.10.2006. 14:30'
+    '%d.%m.%y. %H:%M:%S',       # '25.10.06. 14:30:59'
+    '%d.%m.%y. %H:%M:%S.%f',    # '25.10.06. 14:30:59.000200'
+    '%d.%m.%y. %H:%M',          # '25.10.06. 14:30'
+    '%d. %m. %Y. %H:%M:%S',     # '25. 10. 2006. 14:30:59'
+    '%d. %m. %Y. %H:%M:%S.%f',  # '25. 10. 2006. 14:30:59.000200'
+    '%d. %m. %Y. %H:%M',        # '25. 10. 2006. 14:30'
+    '%d. %m. %y. %H:%M:%S',     # '25. 10. 06. 14:30:59'
+    '%d. %m. %y. %H:%M:%S.%f',  # '25. 10. 06. 14:30:59.000200'
+    '%d. %m. %y. %H:%M',        # '25. 10. 06. 14:30'
+]
+DECIMAL_SEPARATOR = ','
+THOUSAND_SEPARATOR = '.'
+NUMBER_GROUPING = 3
Index: venv/Lib/site-packages/django/conf/locale/sv/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/sv/formats.py b/venv/Lib/site-packages/django/conf/locale/sv/formats.py
new file mode 100644
--- /dev/null	(date 1617030482587)
+++ b/venv/Lib/site-packages/django/conf/locale/sv/formats.py	(date 1617030482587)
@@ -0,0 +1,35 @@
+# This file is distributed under the same license as the Django package.
+#
+# The *_FORMAT strings use the Django date format syntax,
+# see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date
+DATE_FORMAT = 'j F Y'
+TIME_FORMAT = 'H:i'
+DATETIME_FORMAT = 'j F Y H:i'
+YEAR_MONTH_FORMAT = 'F Y'
+MONTH_DAY_FORMAT = 'j F'
+SHORT_DATE_FORMAT = 'Y-m-d'
+SHORT_DATETIME_FORMAT = 'Y-m-d H:i'
+FIRST_DAY_OF_WEEK = 1
+
+# The *_INPUT_FORMATS strings use the Python strftime format syntax,
+# see https://docs.python.org/library/datetime.html#strftime-strptime-behavior
+# Kept ISO formats as they are in first position
+DATE_INPUT_FORMATS = [
+    '%Y-%m-%d',              # '2006-10-25'
+    '%m/%d/%Y',              # '10/25/2006'
+    '%m/%d/%y',              # '10/25/06'
+]
+DATETIME_INPUT_FORMATS = [
+    '%Y-%m-%d %H:%M:%S',     # '2006-10-25 14:30:59'
+    '%Y-%m-%d %H:%M:%S.%f',  # '2006-10-25 14:30:59.000200'
+    '%Y-%m-%d %H:%M',        # '2006-10-25 14:30'
+    '%m/%d/%Y %H:%M:%S',     # '10/25/2006 14:30:59'
+    '%m/%d/%Y %H:%M:%S.%f',  # '10/25/2006 14:30:59.000200'
+    '%m/%d/%Y %H:%M',        # '10/25/2006 14:30'
+    '%m/%d/%y %H:%M:%S',     # '10/25/06 14:30:59'
+    '%m/%d/%y %H:%M:%S.%f',  # '10/25/06 14:30:59.000200'
+    '%m/%d/%y %H:%M',        # '10/25/06 14:30'
+]
+DECIMAL_SEPARATOR = ','
+THOUSAND_SEPARATOR = '\xa0'  # non-breaking space
+NUMBER_GROUPING = 3
Index: venv/Lib/site-packages/django/conf/locale/ta/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/ta/formats.py b/venv/Lib/site-packages/django/conf/locale/ta/formats.py
new file mode 100644
--- /dev/null	(date 1617030482590)
+++ b/venv/Lib/site-packages/django/conf/locale/ta/formats.py	(date 1617030482590)
@@ -0,0 +1,21 @@
+# This file is distributed under the same license as the Django package.
+#
+# The *_FORMAT strings use the Django date format syntax,
+# see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date
+DATE_FORMAT = 'j F, Y'
+TIME_FORMAT = 'g:i A'
+# DATETIME_FORMAT =
+# YEAR_MONTH_FORMAT =
+MONTH_DAY_FORMAT = 'j F'
+SHORT_DATE_FORMAT = 'j M, Y'
+# SHORT_DATETIME_FORMAT =
+# FIRST_DAY_OF_WEEK =
+
+# The *_INPUT_FORMATS strings use the Python strftime format syntax,
+# see https://docs.python.org/library/datetime.html#strftime-strptime-behavior
+# DATE_INPUT_FORMATS =
+# TIME_INPUT_FORMATS =
+# DATETIME_INPUT_FORMATS =
+# DECIMAL_SEPARATOR =
+# THOUSAND_SEPARATOR =
+# NUMBER_GROUPING =
Index: venv/Lib/site-packages/django/contrib/admin/views/autocomplete.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/admin/views/autocomplete.py b/venv/Lib/site-packages/django/contrib/admin/views/autocomplete.py
new file mode 100644
--- /dev/null	(date 1617030482876)
+++ b/venv/Lib/site-packages/django/contrib/admin/views/autocomplete.py	(date 1617030482876)
@@ -0,0 +1,51 @@
+from django.http import Http404, JsonResponse
+from django.views.generic.list import BaseListView
+
+
+class AutocompleteJsonView(BaseListView):
+    """Handle AutocompleteWidget's AJAX requests for data."""
+    paginate_by = 20
+    model_admin = None
+
+    def get(self, request, *args, **kwargs):
+        """
+        Return a JsonResponse with search results of the form:
+        {
+            results: [{id: "123" text: "foo"}],
+            pagination: {more: true}
+        }
+        """
+        if not self.model_admin.get_search_fields(request):
+            raise Http404(
+                '%s must have search_fields for the autocomplete_view.' %
+                type(self.model_admin).__name__
+            )
+        if not self.has_perm(request):
+            return JsonResponse({'error': '403 Forbidden'}, status=403)
+
+        self.term = request.GET.get('term', '')
+        self.object_list = self.get_queryset()
+        context = self.get_context_data()
+        return JsonResponse({
+            'results': [
+                {'id': str(obj.pk), 'text': str(obj)}
+                for obj in context['object_list']
+            ],
+            'pagination': {'more': context['page_obj'].has_next()},
+        })
+
+    def get_paginator(self, *args, **kwargs):
+        """Use the ModelAdmin's paginator."""
+        return self.model_admin.get_paginator(self.request, *args, **kwargs)
+
+    def get_queryset(self):
+        """Return queryset based on ModelAdmin.get_search_results()."""
+        qs = self.model_admin.get_queryset(self.request)
+        qs, search_use_distinct = self.model_admin.get_search_results(self.request, qs, self.term)
+        if search_use_distinct:
+            qs = qs.distinct()
+        return qs
+
+    def has_perm(self, request, obj=None):
+        """Check if user has permission to access the related model."""
+        return self.model_admin.has_view_permission(request, obj=obj)
Index: venv/Lib/site-packages/django/contrib/admin/views/decorators.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/admin/views/decorators.py b/venv/Lib/site-packages/django/contrib/admin/views/decorators.py
new file mode 100644
--- /dev/null	(date 1617030482876)
+++ b/venv/Lib/site-packages/django/contrib/admin/views/decorators.py	(date 1617030482876)
@@ -0,0 +1,18 @@
+from django.contrib.auth import REDIRECT_FIELD_NAME
+from django.contrib.auth.decorators import user_passes_test
+
+
+def staff_member_required(view_func=None, redirect_field_name=REDIRECT_FIELD_NAME,
+                          login_url='admin:login'):
+    """
+    Decorator for views that checks that the user is logged in and is a staff
+    member, redirecting to the login page if necessary.
+    """
+    actual_decorator = user_passes_test(
+        lambda u: u.is_active and u.is_staff,
+        login_url=login_url,
+        redirect_field_name=redirect_field_name
+    )
+    if view_func:
+        return actual_decorator(view_func)
+    return actual_decorator
Index: venv/Lib/site-packages/django/contrib/admin/views/main.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/admin/views/main.py b/venv/Lib/site-packages/django/contrib/admin/views/main.py
new file mode 100644
--- /dev/null	(date 1617030482877)
+++ b/venv/Lib/site-packages/django/contrib/admin/views/main.py	(date 1617030482877)
@@ -0,0 +1,526 @@
+from datetime import datetime, timedelta
+
+from django import forms
+from django.conf import settings
+from django.contrib import messages
+from django.contrib.admin import FieldListFilter
+from django.contrib.admin.exceptions import (
+    DisallowedModelAdminLookup, DisallowedModelAdminToField,
+)
+from django.contrib.admin.options import (
+    IS_POPUP_VAR, TO_FIELD_VAR, IncorrectLookupParameters,
+)
+from django.contrib.admin.utils import (
+    get_fields_from_path, lookup_needs_distinct, prepare_lookup_value, quote,
+)
+from django.core.exceptions import (
+    FieldDoesNotExist, ImproperlyConfigured, SuspiciousOperation,
+)
+from django.core.paginator import InvalidPage
+from django.db.models import F, Field, ManyToOneRel, OrderBy
+from django.db.models.expressions import Combinable
+from django.urls import reverse
+from django.utils.http import urlencode
+from django.utils.timezone import make_aware
+from django.utils.translation import gettext
+
+# Changelist settings
+ALL_VAR = 'all'
+ORDER_VAR = 'o'
+ORDER_TYPE_VAR = 'ot'
+PAGE_VAR = 'p'
+SEARCH_VAR = 'q'
+ERROR_FLAG = 'e'
+
+IGNORED_PARAMS = (
+    ALL_VAR, ORDER_VAR, ORDER_TYPE_VAR, SEARCH_VAR, IS_POPUP_VAR, TO_FIELD_VAR)
+
+
+class ChangeListSearchForm(forms.Form):
+    def __init__(self, *args, **kwargs):
+        super().__init__(*args, **kwargs)
+        # Populate "fields" dynamically because SEARCH_VAR is a variable:
+        self.fields = {
+            SEARCH_VAR: forms.CharField(required=False, strip=False),
+        }
+
+
+class ChangeList:
+    search_form_class = ChangeListSearchForm
+
+    def __init__(self, request, model, list_display, list_display_links,
+                 list_filter, date_hierarchy, search_fields, list_select_related,
+                 list_per_page, list_max_show_all, list_editable, model_admin, sortable_by):
+        self.model = model
+        self.opts = model._meta
+        self.lookup_opts = self.opts
+        self.root_queryset = model_admin.get_queryset(request)
+        self.list_display = list_display
+        self.list_display_links = list_display_links
+        self.list_filter = list_filter
+        self.has_filters = None
+        self.has_active_filters = None
+        self.clear_all_filters_qs = None
+        self.date_hierarchy = date_hierarchy
+        self.search_fields = search_fields
+        self.list_select_related = list_select_related
+        self.list_per_page = list_per_page
+        self.list_max_show_all = list_max_show_all
+        self.model_admin = model_admin
+        self.preserved_filters = model_admin.get_preserved_filters(request)
+        self.sortable_by = sortable_by
+
+        # Get search parameters from the query string.
+        _search_form = self.search_form_class(request.GET)
+        if not _search_form.is_valid():
+            for error in _search_form.errors.values():
+                messages.error(request, ', '.join(error))
+        self.query = _search_form.cleaned_data.get(SEARCH_VAR) or ''
+        try:
+            self.page_num = int(request.GET.get(PAGE_VAR, 0))
+        except ValueError:
+            self.page_num = 0
+        self.show_all = ALL_VAR in request.GET
+        self.is_popup = IS_POPUP_VAR in request.GET
+        to_field = request.GET.get(TO_FIELD_VAR)
+        if to_field and not model_admin.to_field_allowed(request, to_field):
+            raise DisallowedModelAdminToField("The field %s cannot be referenced." % to_field)
+        self.to_field = to_field
+        self.params = dict(request.GET.items())
+        if PAGE_VAR in self.params:
+            del self.params[PAGE_VAR]
+        if ERROR_FLAG in self.params:
+            del self.params[ERROR_FLAG]
+
+        if self.is_popup:
+            self.list_editable = ()
+        else:
+            self.list_editable = list_editable
+        self.queryset = self.get_queryset(request)
+        self.get_results(request)
+        if self.is_popup:
+            title = gettext('Select %s')
+        elif self.model_admin.has_change_permission(request):
+            title = gettext('Select %s to change')
+        else:
+            title = gettext('Select %s to view')
+        self.title = title % self.opts.verbose_name
+        self.pk_attname = self.lookup_opts.pk.attname
+
+    def get_filters_params(self, params=None):
+        """
+        Return all params except IGNORED_PARAMS.
+        """
+        params = params or self.params
+        lookup_params = params.copy()  # a dictionary of the query string
+        # Remove all the parameters that are globally and systematically
+        # ignored.
+        for ignored in IGNORED_PARAMS:
+            if ignored in lookup_params:
+                del lookup_params[ignored]
+        return lookup_params
+
+    def get_filters(self, request):
+        lookup_params = self.get_filters_params()
+        use_distinct = False
+        has_active_filters = False
+
+        for key, value in lookup_params.items():
+            if not self.model_admin.lookup_allowed(key, value):
+                raise DisallowedModelAdminLookup("Filtering by %s not allowed" % key)
+
+        filter_specs = []
+        for list_filter in self.list_filter:
+            lookup_params_count = len(lookup_params)
+            if callable(list_filter):
+                # This is simply a custom list filter class.
+                spec = list_filter(request, lookup_params, self.model, self.model_admin)
+            else:
+                field_path = None
+                if isinstance(list_filter, (tuple, list)):
+                    # This is a custom FieldListFilter class for a given field.
+                    field, field_list_filter_class = list_filter
+                else:
+                    # This is simply a field name, so use the default
+                    # FieldListFilter class that has been registered for the
+                    # type of the given field.
+                    field, field_list_filter_class = list_filter, FieldListFilter.create
+                if not isinstance(field, Field):
+                    field_path = field
+                    field = get_fields_from_path(self.model, field_path)[-1]
+
+                spec = field_list_filter_class(
+                    field, request, lookup_params,
+                    self.model, self.model_admin, field_path=field_path,
+                )
+                # field_list_filter_class removes any lookup_params it
+                # processes. If that happened, check if distinct() is needed to
+                # remove duplicate results.
+                if lookup_params_count > len(lookup_params):
+                    use_distinct = use_distinct or lookup_needs_distinct(self.lookup_opts, field_path)
+            if spec and spec.has_output():
+                filter_specs.append(spec)
+                if lookup_params_count > len(lookup_params):
+                    has_active_filters = True
+
+        if self.date_hierarchy:
+            # Create bounded lookup parameters so that the query is more
+            # efficient.
+            year = lookup_params.pop('%s__year' % self.date_hierarchy, None)
+            if year is not None:
+                month = lookup_params.pop('%s__month' % self.date_hierarchy, None)
+                day = lookup_params.pop('%s__day' % self.date_hierarchy, None)
+                try:
+                    from_date = datetime(
+                        int(year),
+                        int(month if month is not None else 1),
+                        int(day if day is not None else 1),
+                    )
+                except ValueError as e:
+                    raise IncorrectLookupParameters(e) from e
+                if day:
+                    to_date = from_date + timedelta(days=1)
+                elif month:
+                    # In this branch, from_date will always be the first of a
+                    # month, so advancing 32 days gives the next month.
+                    to_date = (from_date + timedelta(days=32)).replace(day=1)
+                else:
+                    to_date = from_date.replace(year=from_date.year + 1)
+                if settings.USE_TZ:
+                    from_date = make_aware(from_date)
+                    to_date = make_aware(to_date)
+                lookup_params.update({
+                    '%s__gte' % self.date_hierarchy: from_date,
+                    '%s__lt' % self.date_hierarchy: to_date,
+                })
+
+        # At this point, all the parameters used by the various ListFilters
+        # have been removed from lookup_params, which now only contains other
+        # parameters passed via the query string. We now loop through the
+        # remaining parameters both to ensure that all the parameters are valid
+        # fields and to determine if at least one of them needs distinct(). If
+        # the lookup parameters aren't real fields, then bail out.
+        try:
+            for key, value in lookup_params.items():
+                lookup_params[key] = prepare_lookup_value(key, value)
+                use_distinct = use_distinct or lookup_needs_distinct(self.lookup_opts, key)
+            return (
+                filter_specs, bool(filter_specs), lookup_params, use_distinct,
+                has_active_filters,
+            )
+        except FieldDoesNotExist as e:
+            raise IncorrectLookupParameters(e) from e
+
+    def get_query_string(self, new_params=None, remove=None):
+        if new_params is None:
+            new_params = {}
+        if remove is None:
+            remove = []
+        p = self.params.copy()
+        for r in remove:
+            for k in list(p):
+                if k.startswith(r):
+                    del p[k]
+        for k, v in new_params.items():
+            if v is None:
+                if k in p:
+                    del p[k]
+            else:
+                p[k] = v
+        return '?%s' % urlencode(sorted(p.items()))
+
+    def get_results(self, request):
+        paginator = self.model_admin.get_paginator(request, self.queryset, self.list_per_page)
+        # Get the number of objects, with admin filters applied.
+        result_count = paginator.count
+
+        # Get the total number of objects, with no admin filters applied.
+        if self.model_admin.show_full_result_count:
+            full_result_count = self.root_queryset.count()
+        else:
+            full_result_count = None
+        can_show_all = result_count <= self.list_max_show_all
+        multi_page = result_count > self.list_per_page
+
+        # Get the list of objects to display on this page.
+        if (self.show_all and can_show_all) or not multi_page:
+            result_list = self.queryset._clone()
+        else:
+            try:
+                result_list = paginator.page(self.page_num + 1).object_list
+            except InvalidPage:
+                raise IncorrectLookupParameters
+
+        self.result_count = result_count
+        self.show_full_result_count = self.model_admin.show_full_result_count
+        # Admin actions are shown if there is at least one entry
+        # or if entries are not counted because show_full_result_count is disabled
+        self.show_admin_actions = not self.show_full_result_count or bool(full_result_count)
+        self.full_result_count = full_result_count
+        self.result_list = result_list
+        self.can_show_all = can_show_all
+        self.multi_page = multi_page
+        self.paginator = paginator
+
+    def _get_default_ordering(self):
+        ordering = []
+        if self.model_admin.ordering:
+            ordering = self.model_admin.ordering
+        elif self.lookup_opts.ordering:
+            ordering = self.lookup_opts.ordering
+        return ordering
+
+    def get_ordering_field(self, field_name):
+        """
+        Return the proper model field name corresponding to the given
+        field_name to use for ordering. field_name may either be the name of a
+        proper model field or the name of a method (on the admin or model) or a
+        callable with the 'admin_order_field' attribute. Return None if no
+        proper model field name can be matched.
+        """
+        try:
+            field = self.lookup_opts.get_field(field_name)
+            return field.name
+        except FieldDoesNotExist:
+            # See whether field_name is a name of a non-field
+            # that allows sorting.
+            if callable(field_name):
+                attr = field_name
+            elif hasattr(self.model_admin, field_name):
+                attr = getattr(self.model_admin, field_name)
+            else:
+                attr = getattr(self.model, field_name)
+            if isinstance(attr, property) and hasattr(attr, 'fget'):
+                attr = attr.fget
+            return getattr(attr, 'admin_order_field', None)
+
+    def get_ordering(self, request, queryset):
+        """
+        Return the list of ordering fields for the change list.
+        First check the get_ordering() method in model admin, then check
+        the object's default ordering. Then, any manually-specified ordering
+        from the query string overrides anything. Finally, a deterministic
+        order is guaranteed by calling _get_deterministic_ordering() with the
+        constructed ordering.
+        """
+        params = self.params
+        ordering = list(self.model_admin.get_ordering(request) or self._get_default_ordering())
+        if ORDER_VAR in params:
+            # Clear ordering and used params
+            ordering = []
+            order_params = params[ORDER_VAR].split('.')
+            for p in order_params:
+                try:
+                    none, pfx, idx = p.rpartition('-')
+                    field_name = self.list_display[int(idx)]
+                    order_field = self.get_ordering_field(field_name)
+                    if not order_field:
+                        continue  # No 'admin_order_field', skip it
+                    if isinstance(order_field, OrderBy):
+                        if pfx == '-':
+                            order_field = order_field.copy()
+                            order_field.reverse_ordering()
+                        ordering.append(order_field)
+                    elif hasattr(order_field, 'resolve_expression'):
+                        # order_field is an expression.
+                        ordering.append(order_field.desc() if pfx == '-' else order_field.asc())
+                    # reverse order if order_field has already "-" as prefix
+                    elif order_field.startswith('-') and pfx == '-':
+                        ordering.append(order_field[1:])
+                    else:
+                        ordering.append(pfx + order_field)
+                except (IndexError, ValueError):
+                    continue  # Invalid ordering specified, skip it.
+
+        # Add the given query's ordering fields, if any.
+        ordering.extend(queryset.query.order_by)
+
+        return self._get_deterministic_ordering(ordering)
+
+    def _get_deterministic_ordering(self, ordering):
+        """
+        Ensure a deterministic order across all database backends. Search for a
+        single field or unique together set of fields providing a total
+        ordering. If these are missing, augment the ordering with a descendant
+        primary key.
+        """
+        ordering = list(ordering)
+        ordering_fields = set()
+        total_ordering_fields = {'pk'} | {
+            field.attname for field in self.lookup_opts.fields
+            if field.unique and not field.null
+        }
+        for part in ordering:
+            # Search for single field providing a total ordering.
+            field_name = None
+            if isinstance(part, str):
+                field_name = part.lstrip('-')
+            elif isinstance(part, F):
+                field_name = part.name
+            elif isinstance(part, OrderBy) and isinstance(part.expression, F):
+                field_name = part.expression.name
+            if field_name:
+                # Normalize attname references by using get_field().
+                try:
+                    field = self.lookup_opts.get_field(field_name)
+                except FieldDoesNotExist:
+                    # Could be "?" for random ordering or a related field
+                    # lookup. Skip this part of introspection for now.
+                    continue
+                # Ordering by a related field name orders by the referenced
+                # model's ordering. Skip this part of introspection for now.
+                if field.remote_field and field_name == field.name:
+                    continue
+                if field.attname in total_ordering_fields:
+                    break
+                ordering_fields.add(field.attname)
+        else:
+            # No single total ordering field, try unique_together and total
+            # unique constraints.
+            constraint_field_names = (
+                *self.lookup_opts.unique_together,
+                *(
+                    constraint.fields
+                    for constraint in self.lookup_opts.total_unique_constraints
+                ),
+            )
+            for field_names in constraint_field_names:
+                # Normalize attname references by using get_field().
+                fields = [self.lookup_opts.get_field(field_name) for field_name in field_names]
+                # Composite unique constraints containing a nullable column
+                # cannot ensure total ordering.
+                if any(field.null for field in fields):
+                    continue
+                if ordering_fields.issuperset(field.attname for field in fields):
+                    break
+            else:
+                # If no set of unique fields is present in the ordering, rely
+                # on the primary key to provide total ordering.
+                ordering.append('-pk')
+        return ordering
+
+    def get_ordering_field_columns(self):
+        """
+        Return a dictionary of ordering field column numbers and asc/desc.
+        """
+        # We must cope with more than one column having the same underlying sort
+        # field, so we base things on column numbers.
+        ordering = self._get_default_ordering()
+        ordering_fields = {}
+        if ORDER_VAR not in self.params:
+            # for ordering specified on ModelAdmin or model Meta, we don't know
+            # the right column numbers absolutely, because there might be more
+            # than one column associated with that ordering, so we guess.
+            for field in ordering:
+                if isinstance(field, (Combinable, OrderBy)):
+                    if not isinstance(field, OrderBy):
+                        field = field.asc()
+                    if isinstance(field.expression, F):
+                        order_type = 'desc' if field.descending else 'asc'
+                        field = field.expression.name
+                    else:
+                        continue
+                elif field.startswith('-'):
+                    field = field[1:]
+                    order_type = 'desc'
+                else:
+                    order_type = 'asc'
+                for index, attr in enumerate(self.list_display):
+                    if self.get_ordering_field(attr) == field:
+                        ordering_fields[index] = order_type
+                        break
+        else:
+            for p in self.params[ORDER_VAR].split('.'):
+                none, pfx, idx = p.rpartition('-')
+                try:
+                    idx = int(idx)
+                except ValueError:
+                    continue  # skip it
+                ordering_fields[idx] = 'desc' if pfx == '-' else 'asc'
+        return ordering_fields
+
+    def get_queryset(self, request):
+        # First, we collect all the declared list filters.
+        (
+            self.filter_specs,
+            self.has_filters,
+            remaining_lookup_params,
+            filters_use_distinct,
+            self.has_active_filters,
+        ) = self.get_filters(request)
+        # Then, we let every list filter modify the queryset to its liking.
+        qs = self.root_queryset
+        for filter_spec in self.filter_specs:
+            new_qs = filter_spec.queryset(request, qs)
+            if new_qs is not None:
+                qs = new_qs
+
+        try:
+            # Finally, we apply the remaining lookup parameters from the query
+            # string (i.e. those that haven't already been processed by the
+            # filters).
+            qs = qs.filter(**remaining_lookup_params)
+        except (SuspiciousOperation, ImproperlyConfigured):
+            # Allow certain types of errors to be re-raised as-is so that the
+            # caller can treat them in a special way.
+            raise
+        except Exception as e:
+            # Every other error is caught with a naked except, because we don't
+            # have any other way of validating lookup parameters. They might be
+            # invalid if the keyword arguments are incorrect, or if the values
+            # are not in the correct type, so we might get FieldError,
+            # ValueError, ValidationError, or ?.
+            raise IncorrectLookupParameters(e)
+
+        if not qs.query.select_related:
+            qs = self.apply_select_related(qs)
+
+        # Set ordering.
+        ordering = self.get_ordering(request, qs)
+        qs = qs.order_by(*ordering)
+
+        # Apply search results
+        qs, search_use_distinct = self.model_admin.get_search_results(request, qs, self.query)
+
+        # Set query string for clearing all filters.
+        self.clear_all_filters_qs = self.get_query_string(
+            new_params=remaining_lookup_params,
+            remove=self.get_filters_params(),
+        )
+        # Remove duplicates from results, if necessary
+        if filters_use_distinct | search_use_distinct:
+            return qs.distinct()
+        else:
+            return qs
+
+    def apply_select_related(self, qs):
+        if self.list_select_related is True:
+            return qs.select_related()
+
+        if self.list_select_related is False:
+            if self.has_related_field_in_list_display():
+                return qs.select_related()
+
+        if self.list_select_related:
+            return qs.select_related(*self.list_select_related)
+        return qs
+
+    def has_related_field_in_list_display(self):
+        for field_name in self.list_display:
+            try:
+                field = self.lookup_opts.get_field(field_name)
+            except FieldDoesNotExist:
+                pass
+            else:
+                if isinstance(field.remote_field, ManyToOneRel):
+                    # <FK>_id field names don't require a join.
+                    if field_name != field.get_attname():
+                        return True
+        return False
+
+    def url_for_result(self, result):
+        pk = getattr(result, self.pk_attname)
+        return reverse('admin:%s_%s_change' % (self.opts.app_label,
+                                               self.opts.model_name),
+                       args=(quote(pk),),
+                       current_app=self.model_admin.admin_site.name)
Index: venv/Lib/site-packages/django/conf/locale/te/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/te/formats.py b/venv/Lib/site-packages/django/conf/locale/te/formats.py
new file mode 100644
--- /dev/null	(date 1617030482591)
+++ b/venv/Lib/site-packages/django/conf/locale/te/formats.py	(date 1617030482591)
@@ -0,0 +1,21 @@
+# This file is distributed under the same license as the Django package.
+#
+# The *_FORMAT strings use the Django date format syntax,
+# see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date
+DATE_FORMAT = 'j F Y'
+TIME_FORMAT = 'g:i A'
+# DATETIME_FORMAT =
+# YEAR_MONTH_FORMAT =
+MONTH_DAY_FORMAT = 'j F'
+SHORT_DATE_FORMAT = 'j M Y'
+# SHORT_DATETIME_FORMAT =
+# FIRST_DAY_OF_WEEK =
+
+# The *_INPUT_FORMATS strings use the Python strftime format syntax,
+# see https://docs.python.org/library/datetime.html#strftime-strptime-behavior
+# DATE_INPUT_FORMATS =
+# TIME_INPUT_FORMATS =
+# DATETIME_INPUT_FORMATS =
+# DECIMAL_SEPARATOR =
+# THOUSAND_SEPARATOR =
+# NUMBER_GROUPING =
Index: venv/Lib/site-packages/django/conf/locale/tg/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/tg/formats.py b/venv/Lib/site-packages/django/conf/locale/tg/formats.py
new file mode 100644
--- /dev/null	(date 1617030482593)
+++ b/venv/Lib/site-packages/django/conf/locale/tg/formats.py	(date 1617030482593)
@@ -0,0 +1,32 @@
+# This file is distributed under the same license as the Django package.
+#
+# The *_FORMAT strings use the Django date format syntax,
+# see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date
+DATE_FORMAT = 'j E Y г.'
+TIME_FORMAT = 'G:i'
+DATETIME_FORMAT = 'j E Y г. G:i'
+YEAR_MONTH_FORMAT = 'F Y г.'
+MONTH_DAY_FORMAT = 'j F'
+SHORT_DATE_FORMAT = 'd.m.Y'
+SHORT_DATETIME_FORMAT = 'd.m.Y H:i'
+FIRST_DAY_OF_WEEK = 1  # Monday
+
+# The *_INPUT_FORMATS strings use the Python strftime format syntax,
+# see https://docs.python.org/library/datetime.html#strftime-strptime-behavior
+DATE_INPUT_FORMATS = [
+    '%d.%m.%Y',  # '25.10.2006'
+    '%d.%m.%y',  # '25.10.06'
+]
+DATETIME_INPUT_FORMATS = [
+    '%d.%m.%Y %H:%M:%S',     # '25.10.2006 14:30:59'
+    '%d.%m.%Y %H:%M:%S.%f',  # '25.10.2006 14:30:59.000200'
+    '%d.%m.%Y %H:%M',        # '25.10.2006 14:30'
+    '%d.%m.%Y',              # '25.10.2006'
+    '%d.%m.%y %H:%M:%S',     # '25.10.06 14:30:59'
+    '%d.%m.%y %H:%M:%S.%f',  # '25.10.06 14:30:59.000200'
+    '%d.%m.%y %H:%M',        # '25.10.06 14:30'
+    '%d.%m.%y',              # '25.10.06'
+]
+DECIMAL_SEPARATOR = ','
+THOUSAND_SEPARATOR = '\xa0'  # non-breaking space
+NUMBER_GROUPING = 3
Index: venv/Lib/site-packages/django/conf/locale/th/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/th/formats.py b/venv/Lib/site-packages/django/conf/locale/th/formats.py
new file mode 100644
--- /dev/null	(date 1617030482594)
+++ b/venv/Lib/site-packages/django/conf/locale/th/formats.py	(date 1617030482594)
@@ -0,0 +1,33 @@
+# This file is distributed under the same license as the Django package.
+#
+# The *_FORMAT strings use the Django date format syntax,
+# see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date
+DATE_FORMAT = 'j F Y'
+TIME_FORMAT = 'G:i'
+DATETIME_FORMAT = 'j F Y, G:i'
+YEAR_MONTH_FORMAT = 'F Y'
+MONTH_DAY_FORMAT = 'j F'
+SHORT_DATE_FORMAT = 'j M Y'
+SHORT_DATETIME_FORMAT = 'j M Y, G:i'
+FIRST_DAY_OF_WEEK = 0  # Sunday
+
+# The *_INPUT_FORMATS strings use the Python strftime format syntax,
+# see https://docs.python.org/library/datetime.html#strftime-strptime-behavior
+DATE_INPUT_FORMATS = [
+    '%d/%m/%Y',  # 25/10/2006
+    '%d %b %Y',  # 25 ต.ค. 2006
+    '%d %B %Y',  # 25 ตุลาคม 2006
+]
+TIME_INPUT_FORMATS = [
+    '%H:%M:%S',  # 14:30:59
+    '%H:%M:%S.%f',  # 14:30:59.000200
+    '%H:%M',  # 14:30
+]
+DATETIME_INPUT_FORMATS = [
+    '%d/%m/%Y %H:%M:%S',  # 25/10/2006 14:30:59
+    '%d/%m/%Y %H:%M:%S.%f',  # 25/10/2006 14:30:59.000200
+    '%d/%m/%Y %H:%M',  # 25/10/2006 14:30
+]
+DECIMAL_SEPARATOR = '.'
+THOUSAND_SEPARATOR = ','
+NUMBER_GROUPING = 3
Index: venv/Lib/site-packages/django/conf/locale/tk/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/tk/formats.py b/venv/Lib/site-packages/django/conf/locale/tk/formats.py
new file mode 100644
--- /dev/null	(date 1617030482596)
+++ b/venv/Lib/site-packages/django/conf/locale/tk/formats.py	(date 1617030482596)
@@ -0,0 +1,32 @@
+# This file is distributed under the same license as the Django package.
+#
+# The *_FORMAT strings use the Django date format syntax,
+# see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date
+DATE_FORMAT = 'j E Y г.'
+TIME_FORMAT = 'G:i'
+DATETIME_FORMAT = 'j E Y г. G:i'
+YEAR_MONTH_FORMAT = 'F Y г.'
+MONTH_DAY_FORMAT = 'j F'
+SHORT_DATE_FORMAT = 'd.m.Y'
+SHORT_DATETIME_FORMAT = 'd.m.Y H:i'
+FIRST_DAY_OF_WEEK = 1  # Monday
+
+# The *_INPUT_FORMATS strings use the Python strftime format syntax,
+# see https://docs.python.org/library/datetime.html#strftime-strptime-behavior
+DATE_INPUT_FORMATS = [
+    '%d.%m.%Y',  # '25.10.2006'
+    '%d.%m.%y',  # '25.10.06'
+]
+DATETIME_INPUT_FORMATS = [
+    '%d.%m.%Y %H:%M:%S',     # '25.10.2006 14:30:59'
+    '%d.%m.%Y %H:%M:%S.%f',  # '25.10.2006 14:30:59.000200'
+    '%d.%m.%Y %H:%M',        # '25.10.2006 14:30'
+    '%d.%m.%Y',              # '25.10.2006'
+    '%d.%m.%y %H:%M:%S',     # '25.10.06 14:30:59'
+    '%d.%m.%y %H:%M:%S.%f',  # '25.10.06 14:30:59.000200'
+    '%d.%m.%y %H:%M',        # '25.10.06 14:30'
+    '%d.%m.%y',              # '25.10.06'
+]
+DECIMAL_SEPARATOR = ','
+THOUSAND_SEPARATOR = '\xa0'  # non-breaking space
+NUMBER_GROUPING = 3
Index: venv/Lib/site-packages/django/conf/locale/tr/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/tr/formats.py b/venv/Lib/site-packages/django/conf/locale/tr/formats.py
new file mode 100644
--- /dev/null	(date 1617030482598)
+++ b/venv/Lib/site-packages/django/conf/locale/tr/formats.py	(date 1617030482598)
@@ -0,0 +1,28 @@
+# This file is distributed under the same license as the Django package.
+#
+# The *_FORMAT strings use the Django date format syntax,
+# see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date
+DATE_FORMAT = 'd F Y'
+TIME_FORMAT = 'H:i'
+DATETIME_FORMAT = 'd F Y H:i'
+YEAR_MONTH_FORMAT = 'F Y'
+MONTH_DAY_FORMAT = 'd F'
+SHORT_DATE_FORMAT = 'd M Y'
+SHORT_DATETIME_FORMAT = 'd M Y H:i'
+FIRST_DAY_OF_WEEK = 1  # Pazartesi
+
+# The *_INPUT_FORMATS strings use the Python strftime format syntax,
+# see https://docs.python.org/library/datetime.html#strftime-strptime-behavior
+DATE_INPUT_FORMATS = [
+    '%d/%m/%Y', '%d/%m/%y',     # '25/10/2006', '25/10/06'
+    '%y-%m-%d',                 # '06-10-25'
+    # '%d %B %Y', '%d %b. %Y',  # '25 Ekim 2006', '25 Eki. 2006'
+]
+DATETIME_INPUT_FORMATS = [
+    '%d/%m/%Y %H:%M:%S',     # '25/10/2006 14:30:59'
+    '%d/%m/%Y %H:%M:%S.%f',  # '25/10/2006 14:30:59.000200'
+    '%d/%m/%Y %H:%M',        # '25/10/2006 14:30'
+]
+DECIMAL_SEPARATOR = ','
+THOUSAND_SEPARATOR = '.'
+NUMBER_GROUPING = 3
Index: venv/Lib/site-packages/django/conf/locale/uk/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/uk/formats.py b/venv/Lib/site-packages/django/conf/locale/uk/formats.py
new file mode 100644
--- /dev/null	(date 1617030482602)
+++ b/venv/Lib/site-packages/django/conf/locale/uk/formats.py	(date 1617030482602)
@@ -0,0 +1,35 @@
+# This file is distributed under the same license as the Django package.
+#
+# The *_FORMAT strings use the Django date format syntax,
+# see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date
+DATE_FORMAT = 'd E Y р.'
+TIME_FORMAT = 'H:i'
+DATETIME_FORMAT = 'd E Y р. H:i'
+YEAR_MONTH_FORMAT = 'F Y'
+MONTH_DAY_FORMAT = 'd F'
+SHORT_DATE_FORMAT = 'd.m.Y'
+SHORT_DATETIME_FORMAT = 'd.m.Y H:i'
+FIRST_DAY_OF_WEEK = 1  # Monday
+
+# The *_INPUT_FORMATS strings use the Python strftime format syntax,
+# see https://docs.python.org/library/datetime.html#strftime-strptime-behavior
+DATE_INPUT_FORMATS = [
+    '%d.%m.%Y',  # '25.10.2006'
+    '%d %B %Y',  # '25 October 2006'
+]
+TIME_INPUT_FORMATS = [
+    '%H:%M:%S',     # '14:30:59'
+    '%H:%M:%S.%f',  # '14:30:59.000200'
+    '%H:%M',        # '14:30'
+]
+DATETIME_INPUT_FORMATS = [
+    '%d.%m.%Y %H:%M:%S',     # '25.10.2006 14:30:59'
+    '%d.%m.%Y %H:%M:%S.%f',  # '25.10.2006 14:30:59.000200'
+    '%d.%m.%Y %H:%M',        # '25.10.2006 14:30'
+    '%d %B %Y %H:%M:%S',     # '25 October 2006 14:30:59'
+    '%d %B %Y %H:%M:%S.%f',  # '25 October 2006 14:30:59.000200'
+    '%d %B %Y %H:%M',        # '25 October 2006 14:30'
+]
+DECIMAL_SEPARATOR = ','
+THOUSAND_SEPARATOR = '\xa0'  # non-breaking space
+NUMBER_GROUPING = 3
Index: venv/Lib/site-packages/django/conf/locale/uz/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/uz/formats.py b/venv/Lib/site-packages/django/conf/locale/uz/formats.py
new file mode 100644
--- /dev/null	(date 1617030482604)
+++ b/venv/Lib/site-packages/django/conf/locale/uz/formats.py	(date 1617030482604)
@@ -0,0 +1,30 @@
+# This file is distributed under the same license as the Django package.
+#
+# The *_FORMAT strings use the Django date format syntax,
+# see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date
+DATE_FORMAT = r'j-E, Y-\y\i\l'
+TIME_FORMAT = 'G:i'
+DATETIME_FORMAT = r'j-E, Y-\y\i\l G:i'
+YEAR_MONTH_FORMAT = r'F Y-\y\i\l'
+MONTH_DAY_FORMAT = 'j-E'
+SHORT_DATE_FORMAT = 'd.m.Y'
+SHORT_DATETIME_FORMAT = 'd.m.Y H:i'
+FIRST_DAY_OF_WEEK = 1  # Monday
+
+# The *_INPUT_FORMATS strings use the Python strftime format syntax,
+# see https://docs.python.org/library/datetime.html#strftime-strptime-behavior
+DATE_INPUT_FORMATS = [
+    '%d.%m.%Y',       # '25.10.2006'
+    '%d-%B, %Y-yil',  # '25-Oktabr, 2006-yil'
+]
+DATETIME_INPUT_FORMATS = [
+    '%d.%m.%Y %H:%M:%S',     # '25.10.2006 14:30:59'
+    '%d.%m.%Y %H:%M:%S.%f',  # '25.10.2006 14:30:59.000200'
+    '%d.%m.%Y %H:%M',        # '25.10.2006 14:30'
+    '%d-%B, %Y-yil %H:%M:%S',     # '25-Oktabr, 2006-yil 14:30:59'
+    '%d-%B, %Y-yil %H:%M:%S.%f',  # '25-Oktabr, 2006-yil 14:30:59.000200'
+    '%d-%B, %Y-yil %H:%M',        # '25-Oktabr, 2006-yil 14:30'
+]
+DECIMAL_SEPARATOR = ','
+THOUSAND_SEPARATOR = '\xa0'  # non-breaking space
+NUMBER_GROUPING = 3
Index: venv/Lib/site-packages/django/conf/locale/vi/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/vi/formats.py b/venv/Lib/site-packages/django/conf/locale/vi/formats.py
new file mode 100644
--- /dev/null	(date 1617030482606)
+++ b/venv/Lib/site-packages/django/conf/locale/vi/formats.py	(date 1617030482606)
@@ -0,0 +1,21 @@
+# This file is distributed under the same license as the Django package.
+#
+# The *_FORMAT strings use the Django date format syntax,
+# see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date
+DATE_FORMAT = r'\N\gà\y d \t\há\n\g n \nă\m Y'
+TIME_FORMAT = 'H:i'
+DATETIME_FORMAT = r'H:i \N\gà\y d \t\há\n\g n \nă\m Y'
+YEAR_MONTH_FORMAT = 'F Y'
+MONTH_DAY_FORMAT = 'j F'
+SHORT_DATE_FORMAT = 'd-m-Y'
+SHORT_DATETIME_FORMAT = 'H:i d-m-Y'
+# FIRST_DAY_OF_WEEK =
+
+# The *_INPUT_FORMATS strings use the Python strftime format syntax,
+# see https://docs.python.org/library/datetime.html#strftime-strptime-behavior
+# DATE_INPUT_FORMATS =
+# TIME_INPUT_FORMATS =
+# DATETIME_INPUT_FORMATS =
+DECIMAL_SEPARATOR = ','
+THOUSAND_SEPARATOR = '.'
+# NUMBER_GROUPING =
Index: venv/Lib/site-packages/django/conf/locale/ar_DZ/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/ar_DZ/formats.py b/venv/Lib/site-packages/django/conf/locale/ar_DZ/formats.py
new file mode 100644
--- /dev/null	(date 1617030482463)
+++ b/venv/Lib/site-packages/django/conf/locale/ar_DZ/formats.py	(date 1617030482463)
@@ -0,0 +1,29 @@
+# This file is distributed under the same license as the Django package.
+#
+# The *_FORMAT strings use the Django date format syntax,
+# see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date
+DATE_FORMAT = 'j F Y'
+TIME_FORMAT = 'H:i'
+DATETIME_FORMAT = 'j F Y H:i'
+YEAR_MONTH_FORMAT = 'F Y'
+MONTH_DAY_FORMAT = 'j F'
+SHORT_DATE_FORMAT = 'j F Y'
+SHORT_DATETIME_FORMAT = 'j F Y H:i'
+FIRST_DAY_OF_WEEK = 0  # Sunday
+
+# The *_INPUT_FORMATS strings use the Python strftime format syntax,
+# see https://docs.python.org/library/datetime.html#strftime-strptime-behavior
+DATE_INPUT_FORMATS = [
+    '%Y/%m/%d',  # '2006/10/25'
+]
+TIME_INPUT_FORMATS = [
+    '%H:%M',     # '14:30
+    '%H:%M:%S',  # '14:30:59'
+]
+DATETIME_INPUT_FORMATS = [
+    '%Y/%m/%d %H:%M',     # '2006/10/25 14:30'
+    '%Y/%m/%d %H:%M:%S',  # '2006/10/25 14:30:59'
+]
+DECIMAL_SEPARATOR = ','
+THOUSAND_SEPARATOR = '.'
+NUMBER_GROUPING = 3
Index: venv/Lib/site-packages/django/conf/locale/de_CH/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/de_CH/formats.py b/venv/Lib/site-packages/django/conf/locale/de_CH/formats.py
new file mode 100644
--- /dev/null	(date 1617030482482)
+++ b/venv/Lib/site-packages/django/conf/locale/de_CH/formats.py	(date 1617030482482)
@@ -0,0 +1,33 @@
+# This file is distributed under the same license as the Django package.
+#
+# The *_FORMAT strings use the Django date format syntax,
+# see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date
+DATE_FORMAT = 'j. F Y'
+TIME_FORMAT = 'H:i'
+DATETIME_FORMAT = 'j. F Y H:i'
+YEAR_MONTH_FORMAT = 'F Y'
+MONTH_DAY_FORMAT = 'j. F'
+SHORT_DATE_FORMAT = 'd.m.Y'
+SHORT_DATETIME_FORMAT = 'd.m.Y H:i'
+FIRST_DAY_OF_WEEK = 1  # Monday
+
+# The *_INPUT_FORMATS strings use the Python strftime format syntax,
+# see https://docs.python.org/library/datetime.html#strftime-strptime-behavior
+DATE_INPUT_FORMATS = [
+    '%d.%m.%Y', '%d.%m.%y',     # '25.10.2006', '25.10.06'
+    # '%d. %B %Y', '%d. %b. %Y',  # '25. October 2006', '25. Oct. 2006'
+]
+DATETIME_INPUT_FORMATS = [
+    '%d.%m.%Y %H:%M:%S',    # '25.10.2006 14:30:59'
+    '%d.%m.%Y %H:%M:%S.%f',  # '25.10.2006 14:30:59.000200'
+    '%d.%m.%Y %H:%M',       # '25.10.2006 14:30'
+]
+
+# these are the separators for non-monetary numbers. For monetary numbers,
+# the DECIMAL_SEPARATOR is a . (decimal point) and the THOUSAND_SEPARATOR is a
+# ' (single quote).
+# For details, please refer to http://www.bk.admin.ch/dokumentation/sprachen/04915/05016/index.html?lang=de
+# (in German) and the documentation
+DECIMAL_SEPARATOR = ','
+THOUSAND_SEPARATOR = '\xa0'  # non-breaking space
+NUMBER_GROUPING = 3
Index: venv/Lib/site-packages/django/conf/locale/en_AU/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/en_AU/formats.py b/venv/Lib/site-packages/django/conf/locale/en_AU/formats.py
new file mode 100644
--- /dev/null	(date 1617030482487)
+++ b/venv/Lib/site-packages/django/conf/locale/en_AU/formats.py	(date 1617030482487)
@@ -0,0 +1,36 @@
+# This file is distributed under the same license as the Django package.
+#
+# The *_FORMAT strings use the Django date format syntax,
+# see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date
+DATE_FORMAT = 'j M Y'                   # '25 Oct 2006'
+TIME_FORMAT = 'P'                       # '2:30 p.m.'
+DATETIME_FORMAT = 'j M Y, P'            # '25 Oct 2006, 2:30 p.m.'
+YEAR_MONTH_FORMAT = 'F Y'               # 'October 2006'
+MONTH_DAY_FORMAT = 'j F'                # '25 October'
+SHORT_DATE_FORMAT = 'd/m/Y'             # '25/10/2006'
+SHORT_DATETIME_FORMAT = 'd/m/Y P'       # '25/10/2006 2:30 p.m.'
+FIRST_DAY_OF_WEEK = 0                   # Sunday
+
+# The *_INPUT_FORMATS strings use the Python strftime format syntax,
+# see https://docs.python.org/library/datetime.html#strftime-strptime-behavior
+DATE_INPUT_FORMATS = [
+    '%d/%m/%Y', '%d/%m/%y',             # '25/10/2006', '25/10/06'
+    # '%b %d %Y', '%b %d, %Y',          # 'Oct 25 2006', 'Oct 25, 2006'
+    # '%d %b %Y', '%d %b, %Y',          # '25 Oct 2006', '25 Oct, 2006'
+    # '%B %d %Y', '%B %d, %Y',          # 'October 25 2006', 'October 25, 2006'
+    # '%d %B %Y', '%d %B, %Y',          # '25 October 2006', '25 October, 2006'
+]
+DATETIME_INPUT_FORMATS = [
+    '%Y-%m-%d %H:%M:%S',                # '2006-10-25 14:30:59'
+    '%Y-%m-%d %H:%M:%S.%f',             # '2006-10-25 14:30:59.000200'
+    '%Y-%m-%d %H:%M',                   # '2006-10-25 14:30'
+    '%d/%m/%Y %H:%M:%S',                # '25/10/2006 14:30:59'
+    '%d/%m/%Y %H:%M:%S.%f',             # '25/10/2006 14:30:59.000200'
+    '%d/%m/%Y %H:%M',                   # '25/10/2006 14:30'
+    '%d/%m/%y %H:%M:%S',                # '25/10/06 14:30:59'
+    '%d/%m/%y %H:%M:%S.%f',             # '25/10/06 14:30:59.000200'
+    '%d/%m/%y %H:%M',                   # '25/10/06 14:30'
+]
+DECIMAL_SEPARATOR = '.'
+THOUSAND_SEPARATOR = ','
+NUMBER_GROUPING = 3
Index: venv/Lib/site-packages/django/conf/locale/en_GB/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/en_GB/formats.py b/venv/Lib/site-packages/django/conf/locale/en_GB/formats.py
new file mode 100644
--- /dev/null	(date 1617030482489)
+++ b/venv/Lib/site-packages/django/conf/locale/en_GB/formats.py	(date 1617030482489)
@@ -0,0 +1,36 @@
+# This file is distributed under the same license as the Django package.
+#
+# The *_FORMAT strings use the Django date format syntax,
+# see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date
+DATE_FORMAT = 'j M Y'                   # '25 Oct 2006'
+TIME_FORMAT = 'P'                       # '2:30 p.m.'
+DATETIME_FORMAT = 'j M Y, P'            # '25 Oct 2006, 2:30 p.m.'
+YEAR_MONTH_FORMAT = 'F Y'               # 'October 2006'
+MONTH_DAY_FORMAT = 'j F'                # '25 October'
+SHORT_DATE_FORMAT = 'd/m/Y'             # '25/10/2006'
+SHORT_DATETIME_FORMAT = 'd/m/Y P'       # '25/10/2006 2:30 p.m.'
+FIRST_DAY_OF_WEEK = 1                   # Monday
+
+# The *_INPUT_FORMATS strings use the Python strftime format syntax,
+# see https://docs.python.org/library/datetime.html#strftime-strptime-behavior
+DATE_INPUT_FORMATS = [
+    '%d/%m/%Y', '%d/%m/%y',             # '25/10/2006', '25/10/06'
+    # '%b %d %Y', '%b %d, %Y',          # 'Oct 25 2006', 'Oct 25, 2006'
+    # '%d %b %Y', '%d %b, %Y',          # '25 Oct 2006', '25 Oct, 2006'
+    # '%B %d %Y', '%B %d, %Y',          # 'October 25 2006', 'October 25, 2006'
+    # '%d %B %Y', '%d %B, %Y',          # '25 October 2006', '25 October, 2006'
+]
+DATETIME_INPUT_FORMATS = [
+    '%Y-%m-%d %H:%M:%S',                # '2006-10-25 14:30:59'
+    '%Y-%m-%d %H:%M:%S.%f',             # '2006-10-25 14:30:59.000200'
+    '%Y-%m-%d %H:%M',                   # '2006-10-25 14:30'
+    '%d/%m/%Y %H:%M:%S',                # '25/10/2006 14:30:59'
+    '%d/%m/%Y %H:%M:%S.%f',             # '25/10/2006 14:30:59.000200'
+    '%d/%m/%Y %H:%M',                   # '25/10/2006 14:30'
+    '%d/%m/%y %H:%M:%S',                # '25/10/06 14:30:59'
+    '%d/%m/%y %H:%M:%S.%f',             # '25/10/06 14:30:59.000200'
+    '%d/%m/%y %H:%M',                   # '25/10/06 14:30'
+]
+DECIMAL_SEPARATOR = '.'
+THOUSAND_SEPARATOR = ','
+NUMBER_GROUPING = 3
Index: venv/Lib/site-packages/pip/_vendor/distro.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/pip/_vendor/distro.py b/venv/Lib/site-packages/pip/_vendor/distro.py
new file mode 100644
--- /dev/null	(date 1617030442510)
+++ b/venv/Lib/site-packages/pip/_vendor/distro.py	(date 1617030442510)
@@ -0,0 +1,1230 @@
+# Copyright 2015,2016,2017 Nir Cohen
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+# http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+"""
+The ``distro`` package (``distro`` stands for Linux Distribution) provides
+information about the Linux distribution it runs on, such as a reliable
+machine-readable distro ID, or version information.
+
+It is the recommended replacement for Python's original
+:py:func:`platform.linux_distribution` function, but it provides much more
+functionality. An alternative implementation became necessary because Python
+3.5 deprecated this function, and Python 3.8 will remove it altogether.
+Its predecessor function :py:func:`platform.dist` was already
+deprecated since Python 2.6 and will also be removed in Python 3.8.
+Still, there are many cases in which access to OS distribution information
+is needed. See `Python issue 1322 <https://bugs.python.org/issue1322>`_ for
+more information.
+"""
+
+import os
+import re
+import sys
+import json
+import shlex
+import logging
+import argparse
+import subprocess
+
+
+_UNIXCONFDIR = os.environ.get('UNIXCONFDIR', '/etc')
+_OS_RELEASE_BASENAME = 'os-release'
+
+#: Translation table for normalizing the "ID" attribute defined in os-release
+#: files, for use by the :func:`distro.id` method.
+#:
+#: * Key: Value as defined in the os-release file, translated to lower case,
+#:   with blanks translated to underscores.
+#:
+#: * Value: Normalized value.
+NORMALIZED_OS_ID = {
+    'ol': 'oracle',  # Oracle Linux
+}
+
+#: Translation table for normalizing the "Distributor ID" attribute returned by
+#: the lsb_release command, for use by the :func:`distro.id` method.
+#:
+#: * Key: Value as returned by the lsb_release command, translated to lower
+#:   case, with blanks translated to underscores.
+#:
+#: * Value: Normalized value.
+NORMALIZED_LSB_ID = {
+    'enterpriseenterpriseas': 'oracle',  # Oracle Enterprise Linux 4
+    'enterpriseenterpriseserver': 'oracle',  # Oracle Linux 5
+    'redhatenterpriseworkstation': 'rhel',  # RHEL 6, 7 Workstation
+    'redhatenterpriseserver': 'rhel',  # RHEL 6, 7 Server
+    'redhatenterprisecomputenode': 'rhel',  # RHEL 6 ComputeNode
+}
+
+#: Translation table for normalizing the distro ID derived from the file name
+#: of distro release files, for use by the :func:`distro.id` method.
+#:
+#: * Key: Value as derived from the file name of a distro release file,
+#:   translated to lower case, with blanks translated to underscores.
+#:
+#: * Value: Normalized value.
+NORMALIZED_DISTRO_ID = {
+    'redhat': 'rhel',  # RHEL 6.x, 7.x
+}
+
+# Pattern for content of distro release file (reversed)
+_DISTRO_RELEASE_CONTENT_REVERSED_PATTERN = re.compile(
+    r'(?:[^)]*\)(.*)\()? *(?:STL )?([\d.+\-a-z]*\d) *(?:esaeler *)?(.+)')
+
+# Pattern for base file name of distro release file
+_DISTRO_RELEASE_BASENAME_PATTERN = re.compile(
+    r'(\w+)[-_](release|version)$')
+
+# Base file names to be ignored when searching for distro release file
+_DISTRO_RELEASE_IGNORE_BASENAMES = (
+    'debian_version',
+    'lsb-release',
+    'oem-release',
+    _OS_RELEASE_BASENAME,
+    'system-release',
+    'plesk-release',
+)
+
+
+def linux_distribution(full_distribution_name=True):
+    """
+    Return information about the current OS distribution as a tuple
+    ``(id_name, version, codename)`` with items as follows:
+
+    * ``id_name``:  If *full_distribution_name* is false, the result of
+      :func:`distro.id`. Otherwise, the result of :func:`distro.name`.
+
+    * ``version``:  The result of :func:`distro.version`.
+
+    * ``codename``:  The result of :func:`distro.codename`.
+
+    The interface of this function is compatible with the original
+    :py:func:`platform.linux_distribution` function, supporting a subset of
+    its parameters.
+
+    The data it returns may not exactly be the same, because it uses more data
+    sources than the original function, and that may lead to different data if
+    the OS distribution is not consistent across multiple data sources it
+    provides (there are indeed such distributions ...).
+
+    Another reason for differences is the fact that the :func:`distro.id`
+    method normalizes the distro ID string to a reliable machine-readable value
+    for a number of popular OS distributions.
+    """
+    return _distro.linux_distribution(full_distribution_name)
+
+
+def id():
+    """
+    Return the distro ID of the current distribution, as a
+    machine-readable string.
+
+    For a number of OS distributions, the returned distro ID value is
+    *reliable*, in the sense that it is documented and that it does not change
+    across releases of the distribution.
+
+    This package maintains the following reliable distro ID values:
+
+    ==============  =========================================
+    Distro ID       Distribution
+    ==============  =========================================
+    "ubuntu"        Ubuntu
+    "debian"        Debian
+    "rhel"          RedHat Enterprise Linux
+    "centos"        CentOS
+    "fedora"        Fedora
+    "sles"          SUSE Linux Enterprise Server
+    "opensuse"      openSUSE
+    "amazon"        Amazon Linux
+    "arch"          Arch Linux
+    "cloudlinux"    CloudLinux OS
+    "exherbo"       Exherbo Linux
+    "gentoo"        GenToo Linux
+    "ibm_powerkvm"  IBM PowerKVM
+    "kvmibm"        KVM for IBM z Systems
+    "linuxmint"     Linux Mint
+    "mageia"        Mageia
+    "mandriva"      Mandriva Linux
+    "parallels"     Parallels
+    "pidora"        Pidora
+    "raspbian"      Raspbian
+    "oracle"        Oracle Linux (and Oracle Enterprise Linux)
+    "scientific"    Scientific Linux
+    "slackware"     Slackware
+    "xenserver"     XenServer
+    "openbsd"       OpenBSD
+    "netbsd"        NetBSD
+    "freebsd"       FreeBSD
+    "midnightbsd"   MidnightBSD
+    ==============  =========================================
+
+    If you have a need to get distros for reliable IDs added into this set,
+    or if you find that the :func:`distro.id` function returns a different
+    distro ID for one of the listed distros, please create an issue in the
+    `distro issue tracker`_.
+
+    **Lookup hierarchy and transformations:**
+
+    First, the ID is obtained from the following sources, in the specified
+    order. The first available and non-empty value is used:
+
+    * the value of the "ID" attribute of the os-release file,
+
+    * the value of the "Distributor ID" attribute returned by the lsb_release
+      command,
+
+    * the first part of the file name of the distro release file,
+
+    The so determined ID value then passes the following transformations,
+    before it is returned by this method:
+
+    * it is translated to lower case,
+
+    * blanks (which should not be there anyway) are translated to underscores,
+
+    * a normalization of the ID is performed, based upon
+      `normalization tables`_. The purpose of this normalization is to ensure
+      that the ID is as reliable as possible, even across incompatible changes
+      in the OS distributions. A common reason for an incompatible change is
+      the addition of an os-release file, or the addition of the lsb_release
+      command, with ID values that differ from what was previously determined
+      from the distro release file name.
+    """
+    return _distro.id()
+
+
+def name(pretty=False):
+    """
+    Return the name of the current OS distribution, as a human-readable
+    string.
+
+    If *pretty* is false, the name is returned without version or codename.
+    (e.g. "CentOS Linux")
+
+    If *pretty* is true, the version and codename are appended.
+    (e.g. "CentOS Linux 7.1.1503 (Core)")
+
+    **Lookup hierarchy:**
+
+    The name is obtained from the following sources, in the specified order.
+    The first available and non-empty value is used:
+
+    * If *pretty* is false:
+
+      - the value of the "NAME" attribute of the os-release file,
+
+      - the value of the "Distributor ID" attribute returned by the lsb_release
+        command,
+
+      - the value of the "<name>" field of the distro release file.
+
+    * If *pretty* is true:
+
+      - the value of the "PRETTY_NAME" attribute of the os-release file,
+
+      - the value of the "Description" attribute returned by the lsb_release
+        command,
+
+      - the value of the "<name>" field of the distro release file, appended
+        with the value of the pretty version ("<version_id>" and "<codename>"
+        fields) of the distro release file, if available.
+    """
+    return _distro.name(pretty)
+
+
+def version(pretty=False, best=False):
+    """
+    Return the version of the current OS distribution, as a human-readable
+    string.
+
+    If *pretty* is false, the version is returned without codename (e.g.
+    "7.0").
+
+    If *pretty* is true, the codename in parenthesis is appended, if the
+    codename is non-empty (e.g. "7.0 (Maipo)").
+
+    Some distributions provide version numbers with different precisions in
+    the different sources of distribution information. Examining the different
+    sources in a fixed priority order does not always yield the most precise
+    version (e.g. for Debian 8.2, or CentOS 7.1).
+
+    The *best* parameter can be used to control the approach for the returned
+    version:
+
+    If *best* is false, the first non-empty version number in priority order of
+    the examined sources is returned.
+
+    If *best* is true, the most precise version number out of all examined
+    sources is returned.
+
+    **Lookup hierarchy:**
+
+    In all cases, the version number is obtained from the following sources.
+    If *best* is false, this order represents the priority order:
+
+    * the value of the "VERSION_ID" attribute of the os-release file,
+    * the value of the "Release" attribute returned by the lsb_release
+      command,
+    * the version number parsed from the "<version_id>" field of the first line
+      of the distro release file,
+    * the version number parsed from the "PRETTY_NAME" attribute of the
+      os-release file, if it follows the format of the distro release files.
+    * the version number parsed from the "Description" attribute returned by
+      the lsb_release command, if it follows the format of the distro release
+      files.
+    """
+    return _distro.version(pretty, best)
+
+
+def version_parts(best=False):
+    """
+    Return the version of the current OS distribution as a tuple
+    ``(major, minor, build_number)`` with items as follows:
+
+    * ``major``:  The result of :func:`distro.major_version`.
+
+    * ``minor``:  The result of :func:`distro.minor_version`.
+
+    * ``build_number``:  The result of :func:`distro.build_number`.
+
+    For a description of the *best* parameter, see the :func:`distro.version`
+    method.
+    """
+    return _distro.version_parts(best)
+
+
+def major_version(best=False):
+    """
+    Return the major version of the current OS distribution, as a string,
+    if provided.
+    Otherwise, the empty string is returned. The major version is the first
+    part of the dot-separated version string.
+
+    For a description of the *best* parameter, see the :func:`distro.version`
+    method.
+    """
+    return _distro.major_version(best)
+
+
+def minor_version(best=False):
+    """
+    Return the minor version of the current OS distribution, as a string,
+    if provided.
+    Otherwise, the empty string is returned. The minor version is the second
+    part of the dot-separated version string.
+
+    For a description of the *best* parameter, see the :func:`distro.version`
+    method.
+    """
+    return _distro.minor_version(best)
+
+
+def build_number(best=False):
+    """
+    Return the build number of the current OS distribution, as a string,
+    if provided.
+    Otherwise, the empty string is returned. The build number is the third part
+    of the dot-separated version string.
+
+    For a description of the *best* parameter, see the :func:`distro.version`
+    method.
+    """
+    return _distro.build_number(best)
+
+
+def like():
+    """
+    Return a space-separated list of distro IDs of distributions that are
+    closely related to the current OS distribution in regards to packaging
+    and programming interfaces, for example distributions the current
+    distribution is a derivative from.
+
+    **Lookup hierarchy:**
+
+    This information item is only provided by the os-release file.
+    For details, see the description of the "ID_LIKE" attribute in the
+    `os-release man page
+    <http://www.freedesktop.org/software/systemd/man/os-release.html>`_.
+    """
+    return _distro.like()
+
+
+def codename():
+    """
+    Return the codename for the release of the current OS distribution,
+    as a string.
+
+    If the distribution does not have a codename, an empty string is returned.
+
+    Note that the returned codename is not always really a codename. For
+    example, openSUSE returns "x86_64". This function does not handle such
+    cases in any special way and just returns the string it finds, if any.
+
+    **Lookup hierarchy:**
+
+    * the codename within the "VERSION" attribute of the os-release file, if
+      provided,
+
+    * the value of the "Codename" attribute returned by the lsb_release
+      command,
+
+    * the value of the "<codename>" field of the distro release file.
+    """
+    return _distro.codename()
+
+
+def info(pretty=False, best=False):
+    """
+    Return certain machine-readable information items about the current OS
+    distribution in a dictionary, as shown in the following example:
+
+    .. sourcecode:: python
+
+        {
+            'id': 'rhel',
+            'version': '7.0',
+            'version_parts': {
+                'major': '7',
+                'minor': '0',
+                'build_number': ''
+            },
+            'like': 'fedora',
+            'codename': 'Maipo'
+        }
+
+    The dictionary structure and keys are always the same, regardless of which
+    information items are available in the underlying data sources. The values
+    for the various keys are as follows:
+
+    * ``id``:  The result of :func:`distro.id`.
+
+    * ``version``:  The result of :func:`distro.version`.
+
+    * ``version_parts -> major``:  The result of :func:`distro.major_version`.
+
+    * ``version_parts -> minor``:  The result of :func:`distro.minor_version`.
+
+    * ``version_parts -> build_number``:  The result of
+      :func:`distro.build_number`.
+
+    * ``like``:  The result of :func:`distro.like`.
+
+    * ``codename``:  The result of :func:`distro.codename`.
+
+    For a description of the *pretty* and *best* parameters, see the
+    :func:`distro.version` method.
+    """
+    return _distro.info(pretty, best)
+
+
+def os_release_info():
+    """
+    Return a dictionary containing key-value pairs for the information items
+    from the os-release file data source of the current OS distribution.
+
+    See `os-release file`_ for details about these information items.
+    """
+    return _distro.os_release_info()
+
+
+def lsb_release_info():
+    """
+    Return a dictionary containing key-value pairs for the information items
+    from the lsb_release command data source of the current OS distribution.
+
+    See `lsb_release command output`_ for details about these information
+    items.
+    """
+    return _distro.lsb_release_info()
+
+
+def distro_release_info():
+    """
+    Return a dictionary containing key-value pairs for the information items
+    from the distro release file data source of the current OS distribution.
+
+    See `distro release file`_ for details about these information items.
+    """
+    return _distro.distro_release_info()
+
+
+def uname_info():
+    """
+    Return a dictionary containing key-value pairs for the information items
+    from the distro release file data source of the current OS distribution.
+    """
+    return _distro.uname_info()
+
+
+def os_release_attr(attribute):
+    """
+    Return a single named information item from the os-release file data source
+    of the current OS distribution.
+
+    Parameters:
+
+    * ``attribute`` (string): Key of the information item.
+
+    Returns:
+
+    * (string): Value of the information item, if the item exists.
+      The empty string, if the item does not exist.
+
+    See `os-release file`_ for details about these information items.
+    """
+    return _distro.os_release_attr(attribute)
+
+
+def lsb_release_attr(attribute):
+    """
+    Return a single named information item from the lsb_release command output
+    data source of the current OS distribution.
+
+    Parameters:
+
+    * ``attribute`` (string): Key of the information item.
+
+    Returns:
+
+    * (string): Value of the information item, if the item exists.
+      The empty string, if the item does not exist.
+
+    See `lsb_release command output`_ for details about these information
+    items.
+    """
+    return _distro.lsb_release_attr(attribute)
+
+
+def distro_release_attr(attribute):
+    """
+    Return a single named information item from the distro release file
+    data source of the current OS distribution.
+
+    Parameters:
+
+    * ``attribute`` (string): Key of the information item.
+
+    Returns:
+
+    * (string): Value of the information item, if the item exists.
+      The empty string, if the item does not exist.
+
+    See `distro release file`_ for details about these information items.
+    """
+    return _distro.distro_release_attr(attribute)
+
+
+def uname_attr(attribute):
+    """
+    Return a single named information item from the distro release file
+    data source of the current OS distribution.
+
+    Parameters:
+
+    * ``attribute`` (string): Key of the information item.
+
+    Returns:
+
+    * (string): Value of the information item, if the item exists.
+                The empty string, if the item does not exist.
+    """
+    return _distro.uname_attr(attribute)
+
+
+class cached_property(object):
+    """A version of @property which caches the value.  On access, it calls the
+    underlying function and sets the value in `__dict__` so future accesses
+    will not re-call the property.
+    """
+    def __init__(self, f):
+        self._fname = f.__name__
+        self._f = f
+
+    def __get__(self, obj, owner):
+        assert obj is not None, 'call {} on an instance'.format(self._fname)
+        ret = obj.__dict__[self._fname] = self._f(obj)
+        return ret
+
+
+class LinuxDistribution(object):
+    """
+    Provides information about a OS distribution.
+
+    This package creates a private module-global instance of this class with
+    default initialization arguments, that is used by the
+    `consolidated accessor functions`_ and `single source accessor functions`_.
+    By using default initialization arguments, that module-global instance
+    returns data about the current OS distribution (i.e. the distro this
+    package runs on).
+
+    Normally, it is not necessary to create additional instances of this class.
+    However, in situations where control is needed over the exact data sources
+    that are used, instances of this class can be created with a specific
+    distro release file, or a specific os-release file, or without invoking the
+    lsb_release command.
+    """
+
+    def __init__(self,
+                 include_lsb=True,
+                 os_release_file='',
+                 distro_release_file='',
+                 include_uname=True):
+        """
+        The initialization method of this class gathers information from the
+        available data sources, and stores that in private instance attributes.
+        Subsequent access to the information items uses these private instance
+        attributes, so that the data sources are read only once.
+
+        Parameters:
+
+        * ``include_lsb`` (bool): Controls whether the
+          `lsb_release command output`_ is included as a data source.
+
+          If the lsb_release command is not available in the program execution
+          path, the data source for the lsb_release command will be empty.
+
+        * ``os_release_file`` (string): The path name of the
+          `os-release file`_ that is to be used as a data source.
+
+          An empty string (the default) will cause the default path name to
+          be used (see `os-release file`_ for details).
+
+          If the specified or defaulted os-release file does not exist, the
+          data source for the os-release file will be empty.
+
+        * ``distro_release_file`` (string): The path name of the
+          `distro release file`_ that is to be used as a data source.
+
+          An empty string (the default) will cause a default search algorithm
+          to be used (see `distro release file`_ for details).
+
+          If the specified distro release file does not exist, or if no default
+          distro release file can be found, the data source for the distro
+          release file will be empty.
+
+        * ``include_uname`` (bool): Controls whether uname command output is
+          included as a data source. If the uname command is not available in
+          the program execution path the data source for the uname command will
+          be empty.
+
+        Public instance attributes:
+
+        * ``os_release_file`` (string): The path name of the
+          `os-release file`_ that is actually used as a data source. The
+          empty string if no distro release file is used as a data source.
+
+        * ``distro_release_file`` (string): The path name of the
+          `distro release file`_ that is actually used as a data source. The
+          empty string if no distro release file is used as a data source.
+
+        * ``include_lsb`` (bool): The result of the ``include_lsb`` parameter.
+          This controls whether the lsb information will be loaded.
+
+        * ``include_uname`` (bool): The result of the ``include_uname``
+          parameter. This controls whether the uname information will
+          be loaded.
+
+        Raises:
+
+        * :py:exc:`IOError`: Some I/O issue with an os-release file or distro
+          release file.
+
+        * :py:exc:`subprocess.CalledProcessError`: The lsb_release command had
+          some issue (other than not being available in the program execution
+          path).
+
+        * :py:exc:`UnicodeError`: A data source has unexpected characters or
+          uses an unexpected encoding.
+        """
+        self.os_release_file = os_release_file or \
+            os.path.join(_UNIXCONFDIR, _OS_RELEASE_BASENAME)
+        self.distro_release_file = distro_release_file or ''  # updated later
+        self.include_lsb = include_lsb
+        self.include_uname = include_uname
+
+    def __repr__(self):
+        """Return repr of all info
+        """
+        return \
+            "LinuxDistribution(" \
+            "os_release_file={self.os_release_file!r}, " \
+            "distro_release_file={self.distro_release_file!r}, " \
+            "include_lsb={self.include_lsb!r}, " \
+            "include_uname={self.include_uname!r}, " \
+            "_os_release_info={self._os_release_info!r}, " \
+            "_lsb_release_info={self._lsb_release_info!r}, " \
+            "_distro_release_info={self._distro_release_info!r}, " \
+            "_uname_info={self._uname_info!r})".format(
+                self=self)
+
+    def linux_distribution(self, full_distribution_name=True):
+        """
+        Return information about the OS distribution that is compatible
+        with Python's :func:`platform.linux_distribution`, supporting a subset
+        of its parameters.
+
+        For details, see :func:`distro.linux_distribution`.
+        """
+        return (
+            self.name() if full_distribution_name else self.id(),
+            self.version(),
+            self.codename()
+        )
+
+    def id(self):
+        """Return the distro ID of the OS distribution, as a string.
+
+        For details, see :func:`distro.id`.
+        """
+        def normalize(distro_id, table):
+            distro_id = distro_id.lower().replace(' ', '_')
+            return table.get(distro_id, distro_id)
+
+        distro_id = self.os_release_attr('id')
+        if distro_id:
+            return normalize(distro_id, NORMALIZED_OS_ID)
+
+        distro_id = self.lsb_release_attr('distributor_id')
+        if distro_id:
+            return normalize(distro_id, NORMALIZED_LSB_ID)
+
+        distro_id = self.distro_release_attr('id')
+        if distro_id:
+            return normalize(distro_id, NORMALIZED_DISTRO_ID)
+
+        distro_id = self.uname_attr('id')
+        if distro_id:
+            return normalize(distro_id, NORMALIZED_DISTRO_ID)
+
+        return ''
+
+    def name(self, pretty=False):
+        """
+        Return the name of the OS distribution, as a string.
+
+        For details, see :func:`distro.name`.
+        """
+        name = self.os_release_attr('name') \
+            or self.lsb_release_attr('distributor_id') \
+            or self.distro_release_attr('name') \
+            or self.uname_attr('name')
+        if pretty:
+            name = self.os_release_attr('pretty_name') \
+                or self.lsb_release_attr('description')
+            if not name:
+                name = self.distro_release_attr('name') \
+                       or self.uname_attr('name')
+                version = self.version(pretty=True)
+                if version:
+                    name = name + ' ' + version
+        return name or ''
+
+    def version(self, pretty=False, best=False):
+        """
+        Return the version of the OS distribution, as a string.
+
+        For details, see :func:`distro.version`.
+        """
+        versions = [
+            self.os_release_attr('version_id'),
+            self.lsb_release_attr('release'),
+            self.distro_release_attr('version_id'),
+            self._parse_distro_release_content(
+                self.os_release_attr('pretty_name')).get('version_id', ''),
+            self._parse_distro_release_content(
+                self.lsb_release_attr('description')).get('version_id', ''),
+            self.uname_attr('release')
+        ]
+        version = ''
+        if best:
+            # This algorithm uses the last version in priority order that has
+            # the best precision. If the versions are not in conflict, that
+            # does not matter; otherwise, using the last one instead of the
+            # first one might be considered a surprise.
+            for v in versions:
+                if v.count(".") > version.count(".") or version == '':
+                    version = v
+        else:
+            for v in versions:
+                if v != '':
+                    version = v
+                    break
+        if pretty and version and self.codename():
+            version = '{0} ({1})'.format(version, self.codename())
+        return version
+
+    def version_parts(self, best=False):
+        """
+        Return the version of the OS distribution, as a tuple of version
+        numbers.
+
+        For details, see :func:`distro.version_parts`.
+        """
+        version_str = self.version(best=best)
+        if version_str:
+            version_regex = re.compile(r'(\d+)\.?(\d+)?\.?(\d+)?')
+            matches = version_regex.match(version_str)
+            if matches:
+                major, minor, build_number = matches.groups()
+                return major, minor or '', build_number or ''
+        return '', '', ''
+
+    def major_version(self, best=False):
+        """
+        Return the major version number of the current distribution.
+
+        For details, see :func:`distro.major_version`.
+        """
+        return self.version_parts(best)[0]
+
+    def minor_version(self, best=False):
+        """
+        Return the minor version number of the current distribution.
+
+        For details, see :func:`distro.minor_version`.
+        """
+        return self.version_parts(best)[1]
+
+    def build_number(self, best=False):
+        """
+        Return the build number of the current distribution.
+
+        For details, see :func:`distro.build_number`.
+        """
+        return self.version_parts(best)[2]
+
+    def like(self):
+        """
+        Return the IDs of distributions that are like the OS distribution.
+
+        For details, see :func:`distro.like`.
+        """
+        return self.os_release_attr('id_like') or ''
+
+    def codename(self):
+        """
+        Return the codename of the OS distribution.
+
+        For details, see :func:`distro.codename`.
+        """
+        try:
+            # Handle os_release specially since distros might purposefully set
+            # this to empty string to have no codename
+            return self._os_release_info['codename']
+        except KeyError:
+            return self.lsb_release_attr('codename') \
+                or self.distro_release_attr('codename') \
+                or ''
+
+    def info(self, pretty=False, best=False):
+        """
+        Return certain machine-readable information about the OS
+        distribution.
+
+        For details, see :func:`distro.info`.
+        """
+        return dict(
+            id=self.id(),
+            version=self.version(pretty, best),
+            version_parts=dict(
+                major=self.major_version(best),
+                minor=self.minor_version(best),
+                build_number=self.build_number(best)
+            ),
+            like=self.like(),
+            codename=self.codename(),
+        )
+
+    def os_release_info(self):
+        """
+        Return a dictionary containing key-value pairs for the information
+        items from the os-release file data source of the OS distribution.
+
+        For details, see :func:`distro.os_release_info`.
+        """
+        return self._os_release_info
+
+    def lsb_release_info(self):
+        """
+        Return a dictionary containing key-value pairs for the information
+        items from the lsb_release command data source of the OS
+        distribution.
+
+        For details, see :func:`distro.lsb_release_info`.
+        """
+        return self._lsb_release_info
+
+    def distro_release_info(self):
+        """
+        Return a dictionary containing key-value pairs for the information
+        items from the distro release file data source of the OS
+        distribution.
+
+        For details, see :func:`distro.distro_release_info`.
+        """
+        return self._distro_release_info
+
+    def uname_info(self):
+        """
+        Return a dictionary containing key-value pairs for the information
+        items from the uname command data source of the OS distribution.
+
+        For details, see :func:`distro.uname_info`.
+        """
+        return self._uname_info
+
+    def os_release_attr(self, attribute):
+        """
+        Return a single named information item from the os-release file data
+        source of the OS distribution.
+
+        For details, see :func:`distro.os_release_attr`.
+        """
+        return self._os_release_info.get(attribute, '')
+
+    def lsb_release_attr(self, attribute):
+        """
+        Return a single named information item from the lsb_release command
+        output data source of the OS distribution.
+
+        For details, see :func:`distro.lsb_release_attr`.
+        """
+        return self._lsb_release_info.get(attribute, '')
+
+    def distro_release_attr(self, attribute):
+        """
+        Return a single named information item from the distro release file
+        data source of the OS distribution.
+
+        For details, see :func:`distro.distro_release_attr`.
+        """
+        return self._distro_release_info.get(attribute, '')
+
+    def uname_attr(self, attribute):
+        """
+        Return a single named information item from the uname command
+        output data source of the OS distribution.
+
+        For details, see :func:`distro.uname_release_attr`.
+        """
+        return self._uname_info.get(attribute, '')
+
+    @cached_property
+    def _os_release_info(self):
+        """
+        Get the information items from the specified os-release file.
+
+        Returns:
+            A dictionary containing all information items.
+        """
+        if os.path.isfile(self.os_release_file):
+            with open(self.os_release_file) as release_file:
+                return self._parse_os_release_content(release_file)
+        return {}
+
+    @staticmethod
+    def _parse_os_release_content(lines):
+        """
+        Parse the lines of an os-release file.
+
+        Parameters:
+
+        * lines: Iterable through the lines in the os-release file.
+                 Each line must be a unicode string or a UTF-8 encoded byte
+                 string.
+
+        Returns:
+            A dictionary containing all information items.
+        """
+        props = {}
+        lexer = shlex.shlex(lines, posix=True)
+        lexer.whitespace_split = True
+
+        # The shlex module defines its `wordchars` variable using literals,
+        # making it dependent on the encoding of the Python source file.
+        # In Python 2.6 and 2.7, the shlex source file is encoded in
+        # 'iso-8859-1', and the `wordchars` variable is defined as a byte
+        # string. This causes a UnicodeDecodeError to be raised when the
+        # parsed content is a unicode object. The following fix resolves that
+        # (... but it should be fixed in shlex...):
+        if sys.version_info[0] == 2 and isinstance(lexer.wordchars, bytes):
+            lexer.wordchars = lexer.wordchars.decode('iso-8859-1')
+
+        tokens = list(lexer)
+        for token in tokens:
+            # At this point, all shell-like parsing has been done (i.e.
+            # comments processed, quotes and backslash escape sequences
+            # processed, multi-line values assembled, trailing newlines
+            # stripped, etc.), so the tokens are now either:
+            # * variable assignments: var=value
+            # * commands or their arguments (not allowed in os-release)
+            if '=' in token:
+                k, v = token.split('=', 1)
+                props[k.lower()] = v
+            else:
+                # Ignore any tokens that are not variable assignments
+                pass
+
+        if 'version_codename' in props:
+            # os-release added a version_codename field.  Use that in
+            # preference to anything else Note that some distros purposefully
+            # do not have code names.  They should be setting
+            # version_codename=""
+            props['codename'] = props['version_codename']
+        elif 'ubuntu_codename' in props:
+            # Same as above but a non-standard field name used on older Ubuntus
+            props['codename'] = props['ubuntu_codename']
+        elif 'version' in props:
+            # If there is no version_codename, parse it from the version
+            codename = re.search(r'(\(\D+\))|,(\s+)?\D+', props['version'])
+            if codename:
+                codename = codename.group()
+                codename = codename.strip('()')
+                codename = codename.strip(',')
+                codename = codename.strip()
+                # codename appears within paranthese.
+                props['codename'] = codename
+
+        return props
+
+    @cached_property
+    def _lsb_release_info(self):
+        """
+        Get the information items from the lsb_release command output.
+
+        Returns:
+            A dictionary containing all information items.
+        """
+        if not self.include_lsb:
+            return {}
+        with open(os.devnull, 'w') as devnull:
+            try:
+                cmd = ('lsb_release', '-a')
+                stdout = subprocess.check_output(cmd, stderr=devnull)
+            except OSError:  # Command not found
+                return {}
+        content = self._to_str(stdout).splitlines()
+        return self._parse_lsb_release_content(content)
+
+    @staticmethod
+    def _parse_lsb_release_content(lines):
+        """
+        Parse the output of the lsb_release command.
+
+        Parameters:
+
+        * lines: Iterable through the lines of the lsb_release output.
+                 Each line must be a unicode string or a UTF-8 encoded byte
+                 string.
+
+        Returns:
+            A dictionary containing all information items.
+        """
+        props = {}
+        for line in lines:
+            kv = line.strip('\n').split(':', 1)
+            if len(kv) != 2:
+                # Ignore lines without colon.
+                continue
+            k, v = kv
+            props.update({k.replace(' ', '_').lower(): v.strip()})
+        return props
+
+    @cached_property
+    def _uname_info(self):
+        with open(os.devnull, 'w') as devnull:
+            try:
+                cmd = ('uname', '-rs')
+                stdout = subprocess.check_output(cmd, stderr=devnull)
+            except OSError:
+                return {}
+        content = self._to_str(stdout).splitlines()
+        return self._parse_uname_content(content)
+
+    @staticmethod
+    def _parse_uname_content(lines):
+        props = {}
+        match = re.search(r'^([^\s]+)\s+([\d\.]+)', lines[0].strip())
+        if match:
+            name, version = match.groups()
+
+            # This is to prevent the Linux kernel version from
+            # appearing as the 'best' version on otherwise
+            # identifiable distributions.
+            if name == 'Linux':
+                return {}
+            props['id'] = name.lower()
+            props['name'] = name
+            props['release'] = version
+        return props
+
+    @staticmethod
+    def _to_str(text):
+        encoding = sys.getfilesystemencoding()
+        encoding = 'utf-8' if encoding == 'ascii' else encoding
+
+        if sys.version_info[0] >= 3:
+            if isinstance(text, bytes):
+                return text.decode(encoding)
+        else:
+            if isinstance(text, unicode):  # noqa
+                return text.encode(encoding)
+
+        return text
+
+    @cached_property
+    def _distro_release_info(self):
+        """
+        Get the information items from the specified distro release file.
+
+        Returns:
+            A dictionary containing all information items.
+        """
+        if self.distro_release_file:
+            # If it was specified, we use it and parse what we can, even if
+            # its file name or content does not match the expected pattern.
+            distro_info = self._parse_distro_release_file(
+                self.distro_release_file)
+            basename = os.path.basename(self.distro_release_file)
+            # The file name pattern for user-specified distro release files
+            # is somewhat more tolerant (compared to when searching for the
+            # file), because we want to use what was specified as best as
+            # possible.
+            match = _DISTRO_RELEASE_BASENAME_PATTERN.match(basename)
+            if 'name' in distro_info \
+               and 'cloudlinux' in distro_info['name'].lower():
+                distro_info['id'] = 'cloudlinux'
+            elif match:
+                distro_info['id'] = match.group(1)
+            return distro_info
+        else:
+            try:
+                basenames = os.listdir(_UNIXCONFDIR)
+                # We sort for repeatability in cases where there are multiple
+                # distro specific files; e.g. CentOS, Oracle, Enterprise all
+                # containing `redhat-release` on top of their own.
+                basenames.sort()
+            except OSError:
+                # This may occur when /etc is not readable but we can't be
+                # sure about the *-release files. Check common entries of
+                # /etc for information. If they turn out to not be there the
+                # error is handled in `_parse_distro_release_file()`.
+                basenames = ['SuSE-release',
+                             'arch-release',
+                             'base-release',
+                             'centos-release',
+                             'fedora-release',
+                             'gentoo-release',
+                             'mageia-release',
+                             'mandrake-release',
+                             'mandriva-release',
+                             'mandrivalinux-release',
+                             'manjaro-release',
+                             'oracle-release',
+                             'redhat-release',
+                             'sl-release',
+                             'slackware-version']
+            for basename in basenames:
+                if basename in _DISTRO_RELEASE_IGNORE_BASENAMES:
+                    continue
+                match = _DISTRO_RELEASE_BASENAME_PATTERN.match(basename)
+                if match:
+                    filepath = os.path.join(_UNIXCONFDIR, basename)
+                    distro_info = self._parse_distro_release_file(filepath)
+                    if 'name' in distro_info:
+                        # The name is always present if the pattern matches
+                        self.distro_release_file = filepath
+                        distro_info['id'] = match.group(1)
+                        if 'cloudlinux' in distro_info['name'].lower():
+                            distro_info['id'] = 'cloudlinux'
+                        return distro_info
+            return {}
+
+    def _parse_distro_release_file(self, filepath):
+        """
+        Parse a distro release file.
+
+        Parameters:
+
+        * filepath: Path name of the distro release file.
+
+        Returns:
+            A dictionary containing all information items.
+        """
+        try:
+            with open(filepath) as fp:
+                # Only parse the first line. For instance, on SLES there
+                # are multiple lines. We don't want them...
+                return self._parse_distro_release_content(fp.readline())
+        except (OSError, IOError):
+            # Ignore not being able to read a specific, seemingly version
+            # related file.
+            # See https://github.com/nir0s/distro/issues/162
+            return {}
+
+    @staticmethod
+    def _parse_distro_release_content(line):
+        """
+        Parse a line from a distro release file.
+
+        Parameters:
+        * line: Line from the distro release file. Must be a unicode string
+                or a UTF-8 encoded byte string.
+
+        Returns:
+            A dictionary containing all information items.
+        """
+        matches = _DISTRO_RELEASE_CONTENT_REVERSED_PATTERN.match(
+            line.strip()[::-1])
+        distro_info = {}
+        if matches:
+            # regexp ensures non-None
+            distro_info['name'] = matches.group(3)[::-1]
+            if matches.group(2):
+                distro_info['version_id'] = matches.group(2)[::-1]
+            if matches.group(1):
+                distro_info['codename'] = matches.group(1)[::-1]
+        elif line:
+            distro_info['name'] = line.strip()
+        return distro_info
+
+
+_distro = LinuxDistribution()
+
+
+def main():
+    logger = logging.getLogger(__name__)
+    logger.setLevel(logging.DEBUG)
+    logger.addHandler(logging.StreamHandler(sys.stdout))
+
+    parser = argparse.ArgumentParser(description="OS distro info tool")
+    parser.add_argument(
+        '--json',
+        '-j',
+        help="Output in machine readable format",
+        action="store_true")
+    args = parser.parse_args()
+
+    if args.json:
+        logger.info(json.dumps(info(), indent=4, sort_keys=True))
+    else:
+        logger.info('Name: %s', name(pretty=True))
+        distribution_version = version(pretty=True)
+        logger.info('Version: %s', distribution_version)
+        distribution_codename = codename()
+        logger.info('Codename: %s', distribution_codename)
+
+
+if __name__ == '__main__':
+    main()
Index: venv/Lib/site-packages/django/conf/locale/es_AR/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/es_AR/formats.py b/venv/Lib/site-packages/django/conf/locale/es_AR/formats.py
new file mode 100644
--- /dev/null	(date 1617030482494)
+++ b/venv/Lib/site-packages/django/conf/locale/es_AR/formats.py	(date 1617030482494)
@@ -0,0 +1,30 @@
+# This file is distributed under the same license as the Django package.
+#
+# The *_FORMAT strings use the Django date format syntax,
+# see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date
+DATE_FORMAT = r'j N Y'
+TIME_FORMAT = r'H:i'
+DATETIME_FORMAT = r'j N Y H:i'
+YEAR_MONTH_FORMAT = r'F Y'
+MONTH_DAY_FORMAT = r'j \d\e F'
+SHORT_DATE_FORMAT = r'd/m/Y'
+SHORT_DATETIME_FORMAT = r'd/m/Y H:i'
+FIRST_DAY_OF_WEEK = 0  # 0: Sunday, 1: Monday
+
+# The *_INPUT_FORMATS strings use the Python strftime format syntax,
+# see https://docs.python.org/library/datetime.html#strftime-strptime-behavior
+DATE_INPUT_FORMATS = [
+    '%d/%m/%Y',  # '31/12/2009'
+    '%d/%m/%y',  # '31/12/09'
+]
+DATETIME_INPUT_FORMATS = [
+    '%d/%m/%Y %H:%M:%S',
+    '%d/%m/%Y %H:%M:%S.%f',
+    '%d/%m/%Y %H:%M',
+    '%d/%m/%y %H:%M:%S',
+    '%d/%m/%y %H:%M:%S.%f',
+    '%d/%m/%y %H:%M',
+]
+DECIMAL_SEPARATOR = ','
+THOUSAND_SEPARATOR = '.'
+NUMBER_GROUPING = 3
Index: venv/Lib/site-packages/django/conf/locale/es_CO/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/es_CO/formats.py b/venv/Lib/site-packages/django/conf/locale/es_CO/formats.py
new file mode 100644
--- /dev/null	(date 1617030482496)
+++ b/venv/Lib/site-packages/django/conf/locale/es_CO/formats.py	(date 1617030482496)
@@ -0,0 +1,26 @@
+# This file is distributed under the same license as the Django package.
+#
+DATE_FORMAT = r'j \d\e F \d\e Y'
+TIME_FORMAT = 'H:i'
+DATETIME_FORMAT = r'j \d\e F \d\e Y \a \l\a\s H:i'
+YEAR_MONTH_FORMAT = r'F \d\e Y'
+MONTH_DAY_FORMAT = r'j \d\e F'
+SHORT_DATE_FORMAT = 'd/m/Y'
+SHORT_DATETIME_FORMAT = 'd/m/Y H:i'
+FIRST_DAY_OF_WEEK = 1
+DATE_INPUT_FORMATS = [
+    '%d/%m/%Y', '%d/%m/%y',  # '25/10/2006', '25/10/06'
+    '%Y%m%d',                # '20061025'
+
+]
+DATETIME_INPUT_FORMATS = [
+    '%d/%m/%Y %H:%M:%S',
+    '%d/%m/%Y %H:%M:%S.%f',
+    '%d/%m/%Y %H:%M',
+    '%d/%m/%y %H:%M:%S',
+    '%d/%m/%y %H:%M:%S.%f',
+    '%d/%m/%y %H:%M',
+]
+DECIMAL_SEPARATOR = ','
+THOUSAND_SEPARATOR = '.'
+NUMBER_GROUPING = 3
Index: venv/Lib/site-packages/django/conf/locale/es_MX/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/es_MX/formats.py b/venv/Lib/site-packages/django/conf/locale/es_MX/formats.py
new file mode 100644
--- /dev/null	(date 1617030482497)
+++ b/venv/Lib/site-packages/django/conf/locale/es_MX/formats.py	(date 1617030482497)
@@ -0,0 +1,25 @@
+# This file is distributed under the same license as the Django package.
+#
+DATE_FORMAT = r'j \d\e F \d\e Y'
+TIME_FORMAT = 'H:i'
+DATETIME_FORMAT = r'j \d\e F \d\e Y \a \l\a\s H:i'
+YEAR_MONTH_FORMAT = r'F \d\e Y'
+MONTH_DAY_FORMAT = r'j \d\e F'
+SHORT_DATE_FORMAT = 'd/m/Y'
+SHORT_DATETIME_FORMAT = 'd/m/Y H:i'
+FIRST_DAY_OF_WEEK = 1  # Monday: ISO 8601
+DATE_INPUT_FORMATS = [
+    '%d/%m/%Y', '%d/%m/%y',             # '25/10/2006', '25/10/06'
+    '%Y%m%d',                           # '20061025'
+]
+DATETIME_INPUT_FORMATS = [
+    '%d/%m/%Y %H:%M:%S',
+    '%d/%m/%Y %H:%M:%S.%f',
+    '%d/%m/%Y %H:%M',
+    '%d/%m/%y %H:%M:%S',
+    '%d/%m/%y %H:%M:%S.%f',
+    '%d/%m/%y %H:%M',
+]
+DECIMAL_SEPARATOR = '.'   # ',' is also official (less common): NOM-008-SCFI-2002
+THOUSAND_SEPARATOR = ','
+NUMBER_GROUPING = 3
Index: venv/Lib/site-packages/django/conf/locale/es_NI/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/es_NI/formats.py b/venv/Lib/site-packages/django/conf/locale/es_NI/formats.py
new file mode 100644
--- /dev/null	(date 1617030482499)
+++ b/venv/Lib/site-packages/django/conf/locale/es_NI/formats.py	(date 1617030482499)
@@ -0,0 +1,26 @@
+# This file is distributed under the same license as the Django package.
+#
+DATE_FORMAT = r'j \d\e F \d\e Y'
+TIME_FORMAT = 'H:i'
+DATETIME_FORMAT = r'j \d\e F \d\e Y \a \l\a\s H:i'
+YEAR_MONTH_FORMAT = r'F \d\e Y'
+MONTH_DAY_FORMAT = r'j \d\e F'
+SHORT_DATE_FORMAT = 'd/m/Y'
+SHORT_DATETIME_FORMAT = 'd/m/Y H:i'
+FIRST_DAY_OF_WEEK = 1  # Monday: ISO 8601
+DATE_INPUT_FORMATS = [
+    '%d/%m/%Y', '%d/%m/%y',            # '25/10/2006', '25/10/06'
+    '%Y%m%d',                          # '20061025'
+
+]
+DATETIME_INPUT_FORMATS = [
+    '%d/%m/%Y %H:%M:%S',
+    '%d/%m/%Y %H:%M:%S.%f',
+    '%d/%m/%Y %H:%M',
+    '%d/%m/%y %H:%M:%S',
+    '%d/%m/%y %H:%M:%S.%f',
+    '%d/%m/%y %H:%M',
+]
+DECIMAL_SEPARATOR = '.'
+THOUSAND_SEPARATOR = ','
+NUMBER_GROUPING = 3
Index: venv/Lib/site-packages/django/conf/locale/es_PR/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/es_PR/formats.py b/venv/Lib/site-packages/django/conf/locale/es_PR/formats.py
new file mode 100644
--- /dev/null	(date 1617030482500)
+++ b/venv/Lib/site-packages/django/conf/locale/es_PR/formats.py	(date 1617030482500)
@@ -0,0 +1,27 @@
+# This file is distributed under the same license as the Django package.
+#
+DATE_FORMAT = r'j \d\e F \d\e Y'
+TIME_FORMAT = 'H:i'
+DATETIME_FORMAT = r'j \d\e F \d\e Y \a \l\a\s H:i'
+YEAR_MONTH_FORMAT = r'F \d\e Y'
+MONTH_DAY_FORMAT = r'j \d\e F'
+SHORT_DATE_FORMAT = 'd/m/Y'
+SHORT_DATETIME_FORMAT = 'd/m/Y H:i'
+FIRST_DAY_OF_WEEK = 0  # Sunday
+
+DATE_INPUT_FORMATS = [
+    # '31/12/2009', '31/12/09'
+    '%d/%m/%Y', '%d/%m/%y'
+]
+DATETIME_INPUT_FORMATS = [
+    '%d/%m/%Y %H:%M:%S',
+    '%d/%m/%Y %H:%M:%S.%f',
+    '%d/%m/%Y %H:%M',
+    '%d/%m/%y %H:%M:%S',
+    '%d/%m/%y %H:%M:%S.%f',
+    '%d/%m/%y %H:%M',
+]
+
+DECIMAL_SEPARATOR = '.'
+THOUSAND_SEPARATOR = ','
+NUMBER_GROUPING = 3
Index: venv/Lib/site-packages/django/conf/locale/pt_BR/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/pt_BR/formats.py b/venv/Lib/site-packages/django/conf/locale/pt_BR/formats.py
new file mode 100644
--- /dev/null	(date 1617030482573)
+++ b/venv/Lib/site-packages/django/conf/locale/pt_BR/formats.py	(date 1617030482573)
@@ -0,0 +1,31 @@
+# This file is distributed under the same license as the Django package.
+#
+# The *_FORMAT strings use the Django date format syntax,
+# see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date
+DATE_FORMAT = r'j \d\e F \d\e Y'
+TIME_FORMAT = 'H:i'
+DATETIME_FORMAT = r'j \d\e F \d\e Y à\s H:i'
+YEAR_MONTH_FORMAT = r'F \d\e Y'
+MONTH_DAY_FORMAT = r'j \d\e F'
+SHORT_DATE_FORMAT = 'd/m/Y'
+SHORT_DATETIME_FORMAT = 'd/m/Y H:i'
+FIRST_DAY_OF_WEEK = 0  # Sunday
+
+# The *_INPUT_FORMATS strings use the Python strftime format syntax,
+# see https://docs.python.org/library/datetime.html#strftime-strptime-behavior
+DATE_INPUT_FORMATS = [
+    '%d/%m/%Y', '%d/%m/%y',  # '25/10/2006', '25/10/06'
+    # '%d de %b de %Y', '%d de %b, %Y',   # '25 de Out de 2006', '25 Out, 2006'
+    # '%d de %B de %Y', '%d de %B, %Y',   # '25 de Outubro de 2006', '25 de Outubro, 2006'
+]
+DATETIME_INPUT_FORMATS = [
+    '%d/%m/%Y %H:%M:%S',     # '25/10/2006 14:30:59'
+    '%d/%m/%Y %H:%M:%S.%f',  # '25/10/2006 14:30:59.000200'
+    '%d/%m/%Y %H:%M',        # '25/10/2006 14:30'
+    '%d/%m/%y %H:%M:%S',     # '25/10/06 14:30:59'
+    '%d/%m/%y %H:%M:%S.%f',  # '25/10/06 14:30:59.000200'
+    '%d/%m/%y %H:%M',        # '25/10/06 14:30'
+]
+DECIMAL_SEPARATOR = ','
+THOUSAND_SEPARATOR = '.'
+NUMBER_GROUPING = 3
Index: venv/Lib/site-packages/django/conf/locale/sr_Latn/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/sr_Latn/formats.py b/venv/Lib/site-packages/django/conf/locale/sr_Latn/formats.py
new file mode 100644
--- /dev/null	(date 1617030482585)
+++ b/venv/Lib/site-packages/django/conf/locale/sr_Latn/formats.py	(date 1617030482585)
@@ -0,0 +1,39 @@
+# This file is distributed under the same license as the Django package.
+#
+# The *_FORMAT strings use the Django date format syntax,
+# see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date
+DATE_FORMAT = 'j. F Y.'
+TIME_FORMAT = 'H:i'
+DATETIME_FORMAT = 'j. F Y. H:i'
+YEAR_MONTH_FORMAT = 'F Y.'
+MONTH_DAY_FORMAT = 'j. F'
+SHORT_DATE_FORMAT = 'j.m.Y.'
+SHORT_DATETIME_FORMAT = 'j.m.Y. H:i'
+FIRST_DAY_OF_WEEK = 1
+
+# The *_INPUT_FORMATS strings use the Python strftime format syntax,
+# see https://docs.python.org/library/datetime.html#strftime-strptime-behavior
+DATE_INPUT_FORMATS = [
+    '%d.%m.%Y.', '%d.%m.%y.',       # '25.10.2006.', '25.10.06.'
+    '%d. %m. %Y.', '%d. %m. %y.',   # '25. 10. 2006.', '25. 10. 06.'
+    # '%d. %b %y.', '%d. %B %y.',     # '25. Oct 06.', '25. October 06.'
+    # '%d. %b \'%y.', '%d. %B \'%y.', # '25. Oct '06.', '25. October '06.'
+    # '%d. %b %Y.', '%d. %B %Y.',     # '25. Oct 2006.', '25. October 2006.'
+]
+DATETIME_INPUT_FORMATS = [
+    '%d.%m.%Y. %H:%M:%S',       # '25.10.2006. 14:30:59'
+    '%d.%m.%Y. %H:%M:%S.%f',    # '25.10.2006. 14:30:59.000200'
+    '%d.%m.%Y. %H:%M',          # '25.10.2006. 14:30'
+    '%d.%m.%y. %H:%M:%S',       # '25.10.06. 14:30:59'
+    '%d.%m.%y. %H:%M:%S.%f',    # '25.10.06. 14:30:59.000200'
+    '%d.%m.%y. %H:%M',          # '25.10.06. 14:30'
+    '%d. %m. %Y. %H:%M:%S',     # '25. 10. 2006. 14:30:59'
+    '%d. %m. %Y. %H:%M:%S.%f',  # '25. 10. 2006. 14:30:59.000200'
+    '%d. %m. %Y. %H:%M',        # '25. 10. 2006. 14:30'
+    '%d. %m. %y. %H:%M:%S',     # '25. 10. 06. 14:30:59'
+    '%d. %m. %y. %H:%M:%S.%f',  # '25. 10. 06. 14:30:59.000200'
+    '%d. %m. %y. %H:%M',        # '25. 10. 06. 14:30'
+]
+DECIMAL_SEPARATOR = ','
+THOUSAND_SEPARATOR = '.'
+NUMBER_GROUPING = 3
Index: venv/Lib/site-packages/django/conf/locale/zh_Hans/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/zh_Hans/formats.py b/venv/Lib/site-packages/django/conf/locale/zh_Hans/formats.py
new file mode 100644
--- /dev/null	(date 1617030482608)
+++ b/venv/Lib/site-packages/django/conf/locale/zh_Hans/formats.py	(date 1617030482608)
@@ -0,0 +1,42 @@
+# This file is distributed under the same license as the Django package.
+#
+# The *_FORMAT strings use the Django date format syntax,
+# see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date
+DATE_FORMAT = 'Y年n月j日'                # 2016年9月5日
+TIME_FORMAT = 'H:i'                     # 20:45
+DATETIME_FORMAT = 'Y年n月j日 H:i'        # 2016年9月5日 20:45
+YEAR_MONTH_FORMAT = 'Y年n月'             # 2016年9月
+MONTH_DAY_FORMAT = 'm月j日'              # 9月5日
+SHORT_DATE_FORMAT = 'Y年n月j日'          # 2016年9月5日
+SHORT_DATETIME_FORMAT = 'Y年n月j日 H:i'  # 2016年9月5日 20:45
+FIRST_DAY_OF_WEEK = 1                   # 星期一 (Monday)
+
+# The *_INPUT_FORMATS strings use the Python strftime format syntax,
+# see https://docs.python.org/library/datetime.html#strftime-strptime-behavior
+DATE_INPUT_FORMATS = [
+    '%Y/%m/%d',     # '2016/09/05'
+    '%Y-%m-%d',     # '2016-09-05'
+    '%Y年%n月%j日',  # '2016年9月5日'
+]
+
+TIME_INPUT_FORMATS = [
+    '%H:%M',        # '20:45'
+    '%H:%M:%S',     # '20:45:29'
+    '%H:%M:%S.%f',  # '20:45:29.000200'
+]
+
+DATETIME_INPUT_FORMATS = [
+    '%Y/%m/%d %H:%M',           # '2016/09/05 20:45'
+    '%Y-%m-%d %H:%M',           # '2016-09-05 20:45'
+    '%Y年%n月%j日 %H:%M',        # '2016年9月5日 14:45'
+    '%Y/%m/%d %H:%M:%S',        # '2016/09/05 20:45:29'
+    '%Y-%m-%d %H:%M:%S',        # '2016-09-05 20:45:29'
+    '%Y年%n月%j日 %H:%M:%S',     # '2016年9月5日 20:45:29'
+    '%Y/%m/%d %H:%M:%S.%f',     # '2016/09/05 20:45:29.000200'
+    '%Y-%m-%d %H:%M:%S.%f',     # '2016-09-05 20:45:29.000200'
+    '%Y年%n月%j日 %H:%n:%S.%f',  # '2016年9月5日 20:45:29.000200'
+]
+
+DECIMAL_SEPARATOR = '.'
+THOUSAND_SEPARATOR = ''
+NUMBER_GROUPING = 4
Index: venv/Lib/site-packages/django/conf/locale/zh_Hant/formats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/locale/zh_Hant/formats.py b/venv/Lib/site-packages/django/conf/locale/zh_Hant/formats.py
new file mode 100644
--- /dev/null	(date 1617030482610)
+++ b/venv/Lib/site-packages/django/conf/locale/zh_Hant/formats.py	(date 1617030482610)
@@ -0,0 +1,42 @@
+# This file is distributed under the same license as the Django package.
+#
+# The *_FORMAT strings use the Django date format syntax,
+# see https://docs.djangoproject.com/en/dev/ref/templates/builtins/#date
+DATE_FORMAT = 'Y年n月j日'                # 2016年9月5日
+TIME_FORMAT = 'H:i'                     # 20:45
+DATETIME_FORMAT = 'Y年n月j日 H:i'        # 2016年9月5日 20:45
+YEAR_MONTH_FORMAT = 'Y年n月'             # 2016年9月
+MONTH_DAY_FORMAT = 'm月j日'              # 9月5日
+SHORT_DATE_FORMAT = 'Y年n月j日'          # 2016年9月5日
+SHORT_DATETIME_FORMAT = 'Y年n月j日 H:i'  # 2016年9月5日 20:45
+FIRST_DAY_OF_WEEK = 1                   # 星期一 (Monday)
+
+# The *_INPUT_FORMATS strings use the Python strftime format syntax,
+# see https://docs.python.org/library/datetime.html#strftime-strptime-behavior
+DATE_INPUT_FORMATS = [
+    '%Y/%m/%d',     # '2016/09/05'
+    '%Y-%m-%d',     # '2016-09-05'
+    '%Y年%n月%j日',  # '2016年9月5日'
+]
+
+TIME_INPUT_FORMATS = [
+    '%H:%M',        # '20:45'
+    '%H:%M:%S',     # '20:45:29'
+    '%H:%M:%S.%f',  # '20:45:29.000200'
+]
+
+DATETIME_INPUT_FORMATS = [
+    '%Y/%m/%d %H:%M',           # '2016/09/05 20:45'
+    '%Y-%m-%d %H:%M',           # '2016-09-05 20:45'
+    '%Y年%n月%j日 %H:%M',        # '2016年9月5日 14:45'
+    '%Y/%m/%d %H:%M:%S',        # '2016/09/05 20:45:29'
+    '%Y-%m-%d %H:%M:%S',        # '2016-09-05 20:45:29'
+    '%Y年%n月%j日 %H:%M:%S',     # '2016年9月5日 20:45:29'
+    '%Y/%m/%d %H:%M:%S.%f',     # '2016/09/05 20:45:29.000200'
+    '%Y-%m-%d %H:%M:%S.%f',     # '2016-09-05 20:45:29.000200'
+    '%Y年%n月%j日 %H:%n:%S.%f',  # '2016年9月5日 20:45:29.000200'
+]
+
+DECIMAL_SEPARATOR = '.'
+THOUSAND_SEPARATOR = ''
+NUMBER_GROUPING = 4
Index: venv/Lib/site-packages/django/conf/project_template/project_name/asgi.py-tpl
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/project_template/project_name/asgi.py-tpl b/venv/Lib/site-packages/django/conf/project_template/project_name/asgi.py-tpl
new file mode 100644
--- /dev/null	(date 1617030482612)
+++ b/venv/Lib/site-packages/django/conf/project_template/project_name/asgi.py-tpl	(date 1617030482612)
@@ -0,0 +1,16 @@
+"""
+ASGI config for {{ project_name }} project.
+
+It exposes the ASGI callable as a module-level variable named ``application``.
+
+For more information on this file, see
+https://docs.djangoproject.com/en/{{ docs_version }}/howto/deployment/asgi/
+"""
+
+import os
+
+from django.core.asgi import get_asgi_application
+
+os.environ.setdefault('DJANGO_SETTINGS_MODULE', '{{ project_name }}.settings')
+
+application = get_asgi_application()
Index: venv/Lib/site-packages/django/conf/project_template/project_name/settings.py-tpl
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/project_template/project_name/settings.py-tpl b/venv/Lib/site-packages/django/conf/project_template/project_name/settings.py-tpl
new file mode 100644
--- /dev/null	(date 1617030482612)
+++ b/venv/Lib/site-packages/django/conf/project_template/project_name/settings.py-tpl	(date 1617030482612)
@@ -0,0 +1,120 @@
+"""
+Django settings for {{ project_name }} project.
+
+Generated by 'django-admin startproject' using Django {{ django_version }}.
+
+For more information on this file, see
+https://docs.djangoproject.com/en/{{ docs_version }}/topics/settings/
+
+For the full list of settings and their values, see
+https://docs.djangoproject.com/en/{{ docs_version }}/ref/settings/
+"""
+
+from pathlib import Path
+
+# Build paths inside the project like this: BASE_DIR / 'subdir'.
+BASE_DIR = Path(__file__).resolve().parent.parent
+
+
+# Quick-start development settings - unsuitable for production
+# See https://docs.djangoproject.com/en/{{ docs_version }}/howto/deployment/checklist/
+
+# SECURITY WARNING: keep the secret key used in production secret!
+SECRET_KEY = '{{ secret_key }}'
+
+# SECURITY WARNING: don't run with debug turned on in production!
+DEBUG = True
+
+ALLOWED_HOSTS = []
+
+
+# Application definition
+
+INSTALLED_APPS = [
+    'django.contrib.admin',
+    'django.contrib.auth',
+    'django.contrib.contenttypes',
+    'django.contrib.sessions',
+    'django.contrib.messages',
+    'django.contrib.staticfiles',
+]
+
+MIDDLEWARE = [
+    'django.middleware.security.SecurityMiddleware',
+    'django.contrib.sessions.middleware.SessionMiddleware',
+    'django.middleware.common.CommonMiddleware',
+    'django.middleware.csrf.CsrfViewMiddleware',
+    'django.contrib.auth.middleware.AuthenticationMiddleware',
+    'django.contrib.messages.middleware.MessageMiddleware',
+    'django.middleware.clickjacking.XFrameOptionsMiddleware',
+]
+
+ROOT_URLCONF = '{{ project_name }}.urls'
+
+TEMPLATES = [
+    {
+        'BACKEND': 'django.template.backends.django.DjangoTemplates',
+        'DIRS': [],
+        'APP_DIRS': True,
+        'OPTIONS': {
+            'context_processors': [
+                'django.template.context_processors.debug',
+                'django.template.context_processors.request',
+                'django.contrib.auth.context_processors.auth',
+                'django.contrib.messages.context_processors.messages',
+            ],
+        },
+    },
+]
+
+WSGI_APPLICATION = '{{ project_name }}.wsgi.application'
+
+
+# Database
+# https://docs.djangoproject.com/en/{{ docs_version }}/ref/settings/#databases
+
+DATABASES = {
+    'default': {
+        'ENGINE': 'django.db.backends.sqlite3',
+        'NAME': BASE_DIR / 'db.sqlite3',
+    }
+}
+
+
+# Password validation
+# https://docs.djangoproject.com/en/{{ docs_version }}/ref/settings/#auth-password-validators
+
+AUTH_PASSWORD_VALIDATORS = [
+    {
+        'NAME': 'django.contrib.auth.password_validation.UserAttributeSimilarityValidator',
+    },
+    {
+        'NAME': 'django.contrib.auth.password_validation.MinimumLengthValidator',
+    },
+    {
+        'NAME': 'django.contrib.auth.password_validation.CommonPasswordValidator',
+    },
+    {
+        'NAME': 'django.contrib.auth.password_validation.NumericPasswordValidator',
+    },
+]
+
+
+# Internationalization
+# https://docs.djangoproject.com/en/{{ docs_version }}/topics/i18n/
+
+LANGUAGE_CODE = 'en-us'
+
+TIME_ZONE = 'UTC'
+
+USE_I18N = True
+
+USE_L10N = True
+
+USE_TZ = True
+
+
+# Static files (CSS, JavaScript, Images)
+# https://docs.djangoproject.com/en/{{ docs_version }}/howto/static-files/
+
+STATIC_URL = '/static/'
Index: venv/Lib/site-packages/django/conf/project_template/project_name/urls.py-tpl
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/project_template/project_name/urls.py-tpl b/venv/Lib/site-packages/django/conf/project_template/project_name/urls.py-tpl
new file mode 100644
--- /dev/null	(date 1617030482612)
+++ b/venv/Lib/site-packages/django/conf/project_template/project_name/urls.py-tpl	(date 1617030482612)
@@ -0,0 +1,21 @@
+"""{{ project_name }} URL Configuration
+
+The `urlpatterns` list routes URLs to views. For more information please see:
+    https://docs.djangoproject.com/en/{{ docs_version }}/topics/http/urls/
+Examples:
+Function views
+    1. Add an import:  from my_app import views
+    2. Add a URL to urlpatterns:  path('', views.home, name='home')
+Class-based views
+    1. Add an import:  from other_app.views import Home
+    2. Add a URL to urlpatterns:  path('', Home.as_view(), name='home')
+Including another URLconf
+    1. Import the include() function: from django.urls import include, path
+    2. Add a URL to urlpatterns:  path('blog/', include('blog.urls'))
+"""
+from django.contrib import admin
+from django.urls import path
+
+urlpatterns = [
+    path('admin/', admin.site.urls),
+]
Index: venv/Lib/site-packages/django/conf/project_template/project_name/wsgi.py-tpl
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/conf/project_template/project_name/wsgi.py-tpl b/venv/Lib/site-packages/django/conf/project_template/project_name/wsgi.py-tpl
new file mode 100644
--- /dev/null	(date 1617030482613)
+++ b/venv/Lib/site-packages/django/conf/project_template/project_name/wsgi.py-tpl	(date 1617030482613)
@@ -0,0 +1,16 @@
+"""
+WSGI config for {{ project_name }} project.
+
+It exposes the WSGI callable as a module-level variable named ``application``.
+
+For more information on this file, see
+https://docs.djangoproject.com/en/{{ docs_version }}/howto/deployment/wsgi/
+"""
+
+import os
+
+from django.core.wsgi import get_wsgi_application
+
+os.environ.setdefault('DJANGO_SETTINGS_MODULE', '{{ project_name }}.settings')
+
+application = get_wsgi_application()
Index: venv/Lib/site-packages/django/core/mail/backends/base.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/core/mail/backends/base.py b/venv/Lib/site-packages/django/core/mail/backends/base.py
new file mode 100644
--- /dev/null	(date 1617030485648)
+++ b/venv/Lib/site-packages/django/core/mail/backends/base.py	(date 1617030485648)
@@ -0,0 +1,59 @@
+"""Base email backend class."""
+
+
+class BaseEmailBackend:
+    """
+    Base class for email backend implementations.
+
+    Subclasses must at least overwrite send_messages().
+
+    open() and close() can be called indirectly by using a backend object as a
+    context manager:
+
+       with backend as connection:
+           # do something with connection
+           pass
+    """
+    def __init__(self, fail_silently=False, **kwargs):
+        self.fail_silently = fail_silently
+
+    def open(self):
+        """
+        Open a network connection.
+
+        This method can be overwritten by backend implementations to
+        open a network connection.
+
+        It's up to the backend implementation to track the status of
+        a network connection if it's needed by the backend.
+
+        This method can be called by applications to force a single
+        network connection to be used when sending mails. See the
+        send_messages() method of the SMTP backend for a reference
+        implementation.
+
+        The default implementation does nothing.
+        """
+        pass
+
+    def close(self):
+        """Close a network connection."""
+        pass
+
+    def __enter__(self):
+        try:
+            self.open()
+        except Exception:
+            self.close()
+            raise
+        return self
+
+    def __exit__(self, exc_type, exc_value, traceback):
+        self.close()
+
+    def send_messages(self, email_messages):
+        """
+        Send one or more EmailMessage objects and return the number of email
+        messages sent.
+        """
+        raise NotImplementedError('subclasses of BaseEmailBackend must override send_messages() method')
Index: venv/Lib/site-packages/django/core/mail/backends/console.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/core/mail/backends/console.py b/venv/Lib/site-packages/django/core/mail/backends/console.py
new file mode 100644
--- /dev/null	(date 1617030485650)
+++ b/venv/Lib/site-packages/django/core/mail/backends/console.py	(date 1617030485650)
@@ -0,0 +1,42 @@
+"""
+Email backend that writes messages to console instead of sending them.
+"""
+import sys
+import threading
+
+from django.core.mail.backends.base import BaseEmailBackend
+
+
+class EmailBackend(BaseEmailBackend):
+    def __init__(self, *args, **kwargs):
+        self.stream = kwargs.pop('stream', sys.stdout)
+        self._lock = threading.RLock()
+        super().__init__(*args, **kwargs)
+
+    def write_message(self, message):
+        msg = message.message()
+        msg_data = msg.as_bytes()
+        charset = msg.get_charset().get_output_charset() if msg.get_charset() else 'utf-8'
+        msg_data = msg_data.decode(charset)
+        self.stream.write('%s\n' % msg_data)
+        self.stream.write('-' * 79)
+        self.stream.write('\n')
+
+    def send_messages(self, email_messages):
+        """Write all messages to the stream in a thread-safe way."""
+        if not email_messages:
+            return
+        msg_count = 0
+        with self._lock:
+            try:
+                stream_created = self.open()
+                for message in email_messages:
+                    self.write_message(message)
+                    self.stream.flush()  # flush after each message
+                    msg_count += 1
+                if stream_created:
+                    self.close()
+            except Exception:
+                if not self.fail_silently:
+                    raise
+        return msg_count
Index: venv/Lib/site-packages/django/core/mail/backends/dummy.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/core/mail/backends/dummy.py b/venv/Lib/site-packages/django/core/mail/backends/dummy.py
new file mode 100644
--- /dev/null	(date 1617030485651)
+++ b/venv/Lib/site-packages/django/core/mail/backends/dummy.py	(date 1617030485651)
@@ -0,0 +1,10 @@
+"""
+Dummy email backend that does nothing.
+"""
+
+from django.core.mail.backends.base import BaseEmailBackend
+
+
+class EmailBackend(BaseEmailBackend):
+    def send_messages(self, email_messages):
+        return len(list(email_messages))
Index: venv/Lib/site-packages/pip/__init__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/pip/__init__.py b/venv/Lib/site-packages/pip/__init__.py
new file mode 100644
--- /dev/null	(date 1617030442450)
+++ b/venv/Lib/site-packages/pip/__init__.py	(date 1617030442450)
@@ -0,0 +1,18 @@
+from pip._internal.utils.typing import MYPY_CHECK_RUNNING
+
+if MYPY_CHECK_RUNNING:
+    from typing import List, Optional
+
+
+__version__ = "21.0.1"
+
+
+def main(args=None):
+    # type: (Optional[List[str]]) -> int
+    """This is an internal API only meant for use by pip's own console scripts.
+
+    For additional details, see https://github.com/pypa/pip/issues/7498.
+    """
+    from pip._internal.utils.entrypoints import _wrapper
+
+    return _wrapper(args)
Index: venv/Lib/site-packages/django/core/mail/backends/filebased.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/core/mail/backends/filebased.py b/venv/Lib/site-packages/django/core/mail/backends/filebased.py
new file mode 100644
--- /dev/null	(date 1617030485651)
+++ b/venv/Lib/site-packages/django/core/mail/backends/filebased.py	(date 1617030485651)
@@ -0,0 +1,64 @@
+"""Email backend that writes messages to a file."""
+
+import datetime
+import os
+
+from django.conf import settings
+from django.core.exceptions import ImproperlyConfigured
+from django.core.mail.backends.console import (
+    EmailBackend as ConsoleEmailBackend,
+)
+
+
+class EmailBackend(ConsoleEmailBackend):
+    def __init__(self, *args, file_path=None, **kwargs):
+        self._fname = None
+        if file_path is not None:
+            self.file_path = file_path
+        else:
+            self.file_path = getattr(settings, 'EMAIL_FILE_PATH', None)
+        self.file_path = os.path.abspath(self.file_path)
+        try:
+            os.makedirs(self.file_path, exist_ok=True)
+        except FileExistsError:
+            raise ImproperlyConfigured(
+                'Path for saving email messages exists, but is not a directory: %s' % self.file_path
+            )
+        except OSError as err:
+            raise ImproperlyConfigured(
+                'Could not create directory for saving email messages: %s (%s)' % (self.file_path, err)
+            )
+        # Make sure that self.file_path is writable.
+        if not os.access(self.file_path, os.W_OK):
+            raise ImproperlyConfigured('Could not write to directory: %s' % self.file_path)
+        # Finally, call super().
+        # Since we're using the console-based backend as a base,
+        # force the stream to be None, so we don't default to stdout
+        kwargs['stream'] = None
+        super().__init__(*args, **kwargs)
+
+    def write_message(self, message):
+        self.stream.write(message.message().as_bytes() + b'\n')
+        self.stream.write(b'-' * 79)
+        self.stream.write(b'\n')
+
+    def _get_filename(self):
+        """Return a unique file name."""
+        if self._fname is None:
+            timestamp = datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
+            fname = "%s-%s.log" % (timestamp, abs(id(self)))
+            self._fname = os.path.join(self.file_path, fname)
+        return self._fname
+
+    def open(self):
+        if self.stream is None:
+            self.stream = open(self._get_filename(), 'ab')
+            return True
+        return False
+
+    def close(self):
+        try:
+            if self.stream is not None:
+                self.stream.close()
+        finally:
+            self.stream = None
Index: venv/Lib/site-packages/pip/__main__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/pip/__main__.py b/venv/Lib/site-packages/pip/__main__.py
new file mode 100644
--- /dev/null	(date 1617030442451)
+++ b/venv/Lib/site-packages/pip/__main__.py	(date 1617030442451)
@@ -0,0 +1,24 @@
+import os
+import sys
+
+# Remove '' and current working directory from the first entry
+# of sys.path, if present to avoid using current directory
+# in pip commands check, freeze, install, list and show,
+# when invoked as python -m pip <command>
+if sys.path[0] in ('', os.getcwd()):
+    sys.path.pop(0)
+
+# If we are running from a wheel, add the wheel to sys.path
+# This allows the usage python pip-*.whl/pip install pip-*.whl
+if __package__ == '':
+    # __file__ is pip-*.whl/pip/__main__.py
+    # first dirname call strips of '/__main__.py', second strips off '/pip'
+    # Resulting path is the name of the wheel itself
+    # Add that to sys.path so we can import pip
+    path = os.path.dirname(os.path.dirname(__file__))
+    sys.path.insert(0, path)
+
+from pip._internal.cli.main import main as _main
+
+if __name__ == '__main__':
+    sys.exit(_main())
Index: venv/Lib/site-packages/django/contrib/admin/migrations/0001_initial.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/admin/migrations/0001_initial.py b/venv/Lib/site-packages/django/contrib/admin/migrations/0001_initial.py
new file mode 100644
--- /dev/null	(date 1617030482799)
+++ b/venv/Lib/site-packages/django/contrib/admin/migrations/0001_initial.py	(date 1617030482799)
@@ -0,0 +1,47 @@
+import django.contrib.admin.models
+from django.conf import settings
+from django.db import migrations, models
+
+
+class Migration(migrations.Migration):
+
+    dependencies = [
+        migrations.swappable_dependency(settings.AUTH_USER_MODEL),
+        ('contenttypes', '__first__'),
+    ]
+
+    operations = [
+        migrations.CreateModel(
+            name='LogEntry',
+            fields=[
+                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),
+                ('action_time', models.DateTimeField(auto_now=True, verbose_name='action time')),
+                ('object_id', models.TextField(null=True, verbose_name='object id', blank=True)),
+                ('object_repr', models.CharField(max_length=200, verbose_name='object repr')),
+                ('action_flag', models.PositiveSmallIntegerField(verbose_name='action flag')),
+                ('change_message', models.TextField(verbose_name='change message', blank=True)),
+                ('content_type', models.ForeignKey(
+                    to_field='id',
+                    on_delete=models.SET_NULL,
+                    blank=True, null=True,
+                    to='contenttypes.ContentType',
+                    verbose_name='content type',
+                )),
+                ('user', models.ForeignKey(
+                    to=settings.AUTH_USER_MODEL,
+                    on_delete=models.CASCADE,
+                    verbose_name='user',
+                )),
+            ],
+            options={
+                'ordering': ['-action_time'],
+                'db_table': 'django_admin_log',
+                'verbose_name': 'log entry',
+                'verbose_name_plural': 'log entries',
+            },
+            bases=(models.Model,),
+            managers=[
+                ('objects', django.contrib.admin.models.LogEntryManager()),
+            ],
+        ),
+    ]
Index: venv/Lib/site-packages/django/core/mail/backends/locmem.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/core/mail/backends/locmem.py b/venv/Lib/site-packages/django/core/mail/backends/locmem.py
new file mode 100644
--- /dev/null	(date 1617030485651)
+++ b/venv/Lib/site-packages/django/core/mail/backends/locmem.py	(date 1617030485651)
@@ -0,0 +1,30 @@
+"""
+Backend for test environment.
+"""
+
+from django.core import mail
+from django.core.mail.backends.base import BaseEmailBackend
+
+
+class EmailBackend(BaseEmailBackend):
+    """
+    An email backend for use during test sessions.
+
+    The test connection stores email messages in a dummy outbox,
+    rather than sending them out on the wire.
+
+    The dummy outbox is accessible through the outbox instance attribute.
+    """
+    def __init__(self, *args, **kwargs):
+        super().__init__(*args, **kwargs)
+        if not hasattr(mail, 'outbox'):
+            mail.outbox = []
+
+    def send_messages(self, messages):
+        """Redirect messages to the dummy outbox"""
+        msg_count = 0
+        for message in messages:  # .message() triggers header validation
+            message.message()
+            mail.outbox.append(message)
+            msg_count += 1
+        return msg_count
Index: venv/Lib/site-packages/django/contrib/admin/migrations/0002_logentry_remove_auto_add.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/admin/migrations/0002_logentry_remove_auto_add.py b/venv/Lib/site-packages/django/contrib/admin/migrations/0002_logentry_remove_auto_add.py
new file mode 100644
--- /dev/null	(date 1617030482799)
+++ b/venv/Lib/site-packages/django/contrib/admin/migrations/0002_logentry_remove_auto_add.py	(date 1617030482799)
@@ -0,0 +1,22 @@
+from django.db import migrations, models
+from django.utils import timezone
+
+
+class Migration(migrations.Migration):
+
+    dependencies = [
+        ('admin', '0001_initial'),
+    ]
+
+    # No database changes; removes auto_add and adds default/editable.
+    operations = [
+        migrations.AlterField(
+            model_name='logentry',
+            name='action_time',
+            field=models.DateTimeField(
+                verbose_name='action time',
+                default=timezone.now,
+                editable=False,
+            ),
+        ),
+    ]
Index: venv/Lib/site-packages/django/core/mail/backends/smtp.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/core/mail/backends/smtp.py b/venv/Lib/site-packages/django/core/mail/backends/smtp.py
new file mode 100644
--- /dev/null	(date 1617030485652)
+++ b/venv/Lib/site-packages/django/core/mail/backends/smtp.py	(date 1617030485652)
@@ -0,0 +1,130 @@
+"""SMTP email backend class."""
+import smtplib
+import ssl
+import threading
+
+from django.conf import settings
+from django.core.mail.backends.base import BaseEmailBackend
+from django.core.mail.message import sanitize_address
+from django.core.mail.utils import DNS_NAME
+
+
+class EmailBackend(BaseEmailBackend):
+    """
+    A wrapper that manages the SMTP network connection.
+    """
+    def __init__(self, host=None, port=None, username=None, password=None,
+                 use_tls=None, fail_silently=False, use_ssl=None, timeout=None,
+                 ssl_keyfile=None, ssl_certfile=None,
+                 **kwargs):
+        super().__init__(fail_silently=fail_silently)
+        self.host = host or settings.EMAIL_HOST
+        self.port = port or settings.EMAIL_PORT
+        self.username = settings.EMAIL_HOST_USER if username is None else username
+        self.password = settings.EMAIL_HOST_PASSWORD if password is None else password
+        self.use_tls = settings.EMAIL_USE_TLS if use_tls is None else use_tls
+        self.use_ssl = settings.EMAIL_USE_SSL if use_ssl is None else use_ssl
+        self.timeout = settings.EMAIL_TIMEOUT if timeout is None else timeout
+        self.ssl_keyfile = settings.EMAIL_SSL_KEYFILE if ssl_keyfile is None else ssl_keyfile
+        self.ssl_certfile = settings.EMAIL_SSL_CERTFILE if ssl_certfile is None else ssl_certfile
+        if self.use_ssl and self.use_tls:
+            raise ValueError(
+                "EMAIL_USE_TLS/EMAIL_USE_SSL are mutually exclusive, so only set "
+                "one of those settings to True.")
+        self.connection = None
+        self._lock = threading.RLock()
+
+    @property
+    def connection_class(self):
+        return smtplib.SMTP_SSL if self.use_ssl else smtplib.SMTP
+
+    def open(self):
+        """
+        Ensure an open connection to the email server. Return whether or not a
+        new connection was required (True or False) or None if an exception
+        passed silently.
+        """
+        if self.connection:
+            # Nothing to do if the connection is already open.
+            return False
+
+        # If local_hostname is not specified, socket.getfqdn() gets used.
+        # For performance, we use the cached FQDN for local_hostname.
+        connection_params = {'local_hostname': DNS_NAME.get_fqdn()}
+        if self.timeout is not None:
+            connection_params['timeout'] = self.timeout
+        if self.use_ssl:
+            connection_params.update({
+                'keyfile': self.ssl_keyfile,
+                'certfile': self.ssl_certfile,
+            })
+        try:
+            self.connection = self.connection_class(self.host, self.port, **connection_params)
+
+            # TLS/SSL are mutually exclusive, so only attempt TLS over
+            # non-secure connections.
+            if not self.use_ssl and self.use_tls:
+                self.connection.starttls(keyfile=self.ssl_keyfile, certfile=self.ssl_certfile)
+            if self.username and self.password:
+                self.connection.login(self.username, self.password)
+            return True
+        except OSError:
+            if not self.fail_silently:
+                raise
+
+    def close(self):
+        """Close the connection to the email server."""
+        if self.connection is None:
+            return
+        try:
+            try:
+                self.connection.quit()
+            except (ssl.SSLError, smtplib.SMTPServerDisconnected):
+                # This happens when calling quit() on a TLS connection
+                # sometimes, or when the connection was already disconnected
+                # by the server.
+                self.connection.close()
+            except smtplib.SMTPException:
+                if self.fail_silently:
+                    return
+                raise
+        finally:
+            self.connection = None
+
+    def send_messages(self, email_messages):
+        """
+        Send one or more EmailMessage objects and return the number of email
+        messages sent.
+        """
+        if not email_messages:
+            return 0
+        with self._lock:
+            new_conn_created = self.open()
+            if not self.connection or new_conn_created is None:
+                # We failed silently on open().
+                # Trying to send would be pointless.
+                return 0
+            num_sent = 0
+            for message in email_messages:
+                sent = self._send(message)
+                if sent:
+                    num_sent += 1
+            if new_conn_created:
+                self.close()
+        return num_sent
+
+    def _send(self, email_message):
+        """A helper method that does the actual sending."""
+        if not email_message.recipients():
+            return False
+        encoding = email_message.encoding or settings.DEFAULT_CHARSET
+        from_email = sanitize_address(email_message.from_email, encoding)
+        recipients = [sanitize_address(addr, encoding) for addr in email_message.recipients()]
+        message = email_message.message()
+        try:
+            self.connection.sendmail(from_email, recipients, message.as_bytes(linesep='\r\n'))
+        except smtplib.SMTPException:
+            if not self.fail_silently:
+                raise
+            return False
+        return True
Index: venv/Lib/site-packages/django/contrib/admin/migrations/0003_logentry_add_action_flag_choices.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/admin/migrations/0003_logentry_add_action_flag_choices.py b/venv/Lib/site-packages/django/contrib/admin/migrations/0003_logentry_add_action_flag_choices.py
new file mode 100644
--- /dev/null	(date 1617030482800)
+++ b/venv/Lib/site-packages/django/contrib/admin/migrations/0003_logentry_add_action_flag_choices.py	(date 1617030482800)
@@ -0,0 +1,20 @@
+from django.db import migrations, models
+
+
+class Migration(migrations.Migration):
+
+    dependencies = [
+        ('admin', '0002_logentry_remove_auto_add'),
+    ]
+
+    # No database changes; adds choices to action_flag.
+    operations = [
+        migrations.AlterField(
+            model_name='logentry',
+            name='action_flag',
+            field=models.PositiveSmallIntegerField(
+                choices=[(1, 'Addition'), (2, 'Change'), (3, 'Deletion')],
+                verbose_name='action flag',
+            ),
+        ),
+    ]
Index: venv/Lib/site-packages/django/core/mail/backends/__init__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/core/mail/backends/__init__.py b/venv/Lib/site-packages/django/core/mail/backends/__init__.py
new file mode 100644
--- /dev/null	(date 1617030485647)
+++ b/venv/Lib/site-packages/django/core/mail/backends/__init__.py	(date 1617030485647)
@@ -0,0 +1,1 @@
+# Mail backends shipped with Django.
Index: venv/Lib/site-packages/django/core/cache/backends/base.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/core/cache/backends/base.py b/venv/Lib/site-packages/django/core/cache/backends/base.py
new file mode 100644
--- /dev/null	(date 1617030485633)
+++ b/venv/Lib/site-packages/django/core/cache/backends/base.py	(date 1617030485633)
@@ -0,0 +1,292 @@
+"Base Cache class."
+import time
+import warnings
+
+from django.core.exceptions import ImproperlyConfigured
+from django.utils.module_loading import import_string
+
+
+class InvalidCacheBackendError(ImproperlyConfigured):
+    pass
+
+
+class CacheKeyWarning(RuntimeWarning):
+    pass
+
+
+class InvalidCacheKey(ValueError):
+    pass
+
+
+# Stub class to ensure not passing in a `timeout` argument results in
+# the default timeout
+DEFAULT_TIMEOUT = object()
+
+# Memcached does not accept keys longer than this.
+MEMCACHE_MAX_KEY_LENGTH = 250
+
+
+def default_key_func(key, key_prefix, version):
+    """
+    Default function to generate keys.
+
+    Construct the key used by all other methods. By default, prepend
+    the `key_prefix'. KEY_FUNCTION can be used to specify an alternate
+    function with custom key making behavior.
+    """
+    return '%s:%s:%s' % (key_prefix, version, key)
+
+
+def get_key_func(key_func):
+    """
+    Function to decide which key function to use.
+
+    Default to ``default_key_func``.
+    """
+    if key_func is not None:
+        if callable(key_func):
+            return key_func
+        else:
+            return import_string(key_func)
+    return default_key_func
+
+
+class BaseCache:
+    def __init__(self, params):
+        timeout = params.get('timeout', params.get('TIMEOUT', 300))
+        if timeout is not None:
+            try:
+                timeout = int(timeout)
+            except (ValueError, TypeError):
+                timeout = 300
+        self.default_timeout = timeout
+
+        options = params.get('OPTIONS', {})
+        max_entries = params.get('max_entries', options.get('MAX_ENTRIES', 300))
+        try:
+            self._max_entries = int(max_entries)
+        except (ValueError, TypeError):
+            self._max_entries = 300
+
+        cull_frequency = params.get('cull_frequency', options.get('CULL_FREQUENCY', 3))
+        try:
+            self._cull_frequency = int(cull_frequency)
+        except (ValueError, TypeError):
+            self._cull_frequency = 3
+
+        self.key_prefix = params.get('KEY_PREFIX', '')
+        self.version = params.get('VERSION', 1)
+        self.key_func = get_key_func(params.get('KEY_FUNCTION'))
+
+    def get_backend_timeout(self, timeout=DEFAULT_TIMEOUT):
+        """
+        Return the timeout value usable by this backend based upon the provided
+        timeout.
+        """
+        if timeout == DEFAULT_TIMEOUT:
+            timeout = self.default_timeout
+        elif timeout == 0:
+            # ticket 21147 - avoid time.time() related precision issues
+            timeout = -1
+        return None if timeout is None else time.time() + timeout
+
+    def make_key(self, key, version=None):
+        """
+        Construct the key used by all other methods. By default, use the
+        key_func to generate a key (which, by default, prepends the
+        `key_prefix' and 'version'). A different key function can be provided
+        at the time of cache construction; alternatively, you can subclass the
+        cache backend to provide custom key making behavior.
+        """
+        if version is None:
+            version = self.version
+
+        return self.key_func(key, self.key_prefix, version)
+
+    def add(self, key, value, timeout=DEFAULT_TIMEOUT, version=None):
+        """
+        Set a value in the cache if the key does not already exist. If
+        timeout is given, use that timeout for the key; otherwise use the
+        default cache timeout.
+
+        Return True if the value was stored, False otherwise.
+        """
+        raise NotImplementedError('subclasses of BaseCache must provide an add() method')
+
+    def get(self, key, default=None, version=None):
+        """
+        Fetch a given key from the cache. If the key does not exist, return
+        default, which itself defaults to None.
+        """
+        raise NotImplementedError('subclasses of BaseCache must provide a get() method')
+
+    def set(self, key, value, timeout=DEFAULT_TIMEOUT, version=None):
+        """
+        Set a value in the cache. If timeout is given, use that timeout for the
+        key; otherwise use the default cache timeout.
+        """
+        raise NotImplementedError('subclasses of BaseCache must provide a set() method')
+
+    def touch(self, key, timeout=DEFAULT_TIMEOUT, version=None):
+        """
+        Update the key's expiry time using timeout. Return True if successful
+        or False if the key does not exist.
+        """
+        raise NotImplementedError('subclasses of BaseCache must provide a touch() method')
+
+    def delete(self, key, version=None):
+        """
+        Delete a key from the cache and return whether it succeeded, failing
+        silently.
+        """
+        raise NotImplementedError('subclasses of BaseCache must provide a delete() method')
+
+    def get_many(self, keys, version=None):
+        """
+        Fetch a bunch of keys from the cache. For certain backends (memcached,
+        pgsql) this can be *much* faster when fetching multiple values.
+
+        Return a dict mapping each key in keys to its value. If the given
+        key is missing, it will be missing from the response dict.
+        """
+        d = {}
+        for k in keys:
+            val = self.get(k, version=version)
+            if val is not None:
+                d[k] = val
+        return d
+
+    def get_or_set(self, key, default, timeout=DEFAULT_TIMEOUT, version=None):
+        """
+        Fetch a given key from the cache. If the key does not exist,
+        add the key and set it to the default value. The default value can
+        also be any callable. If timeout is given, use that timeout for the
+        key; otherwise use the default cache timeout.
+
+        Return the value of the key stored or retrieved.
+        """
+        val = self.get(key, version=version)
+        if val is None:
+            if callable(default):
+                default = default()
+            if default is not None:
+                self.add(key, default, timeout=timeout, version=version)
+                # Fetch the value again to avoid a race condition if another
+                # caller added a value between the first get() and the add()
+                # above.
+                return self.get(key, default, version=version)
+        return val
+
+    def has_key(self, key, version=None):
+        """
+        Return True if the key is in the cache and has not expired.
+        """
+        return self.get(key, version=version) is not None
+
+    def incr(self, key, delta=1, version=None):
+        """
+        Add delta to value in the cache. If the key does not exist, raise a
+        ValueError exception.
+        """
+        value = self.get(key, version=version)
+        if value is None:
+            raise ValueError("Key '%s' not found" % key)
+        new_value = value + delta
+        self.set(key, new_value, version=version)
+        return new_value
+
+    def decr(self, key, delta=1, version=None):
+        """
+        Subtract delta from value in the cache. If the key does not exist, raise
+        a ValueError exception.
+        """
+        return self.incr(key, -delta, version=version)
+
+    def __contains__(self, key):
+        """
+        Return True if the key is in the cache and has not expired.
+        """
+        # This is a separate method, rather than just a copy of has_key(),
+        # so that it always has the same functionality as has_key(), even
+        # if a subclass overrides it.
+        return self.has_key(key)
+
+    def set_many(self, data, timeout=DEFAULT_TIMEOUT, version=None):
+        """
+        Set a bunch of values in the cache at once from a dict of key/value
+        pairs.  For certain backends (memcached), this is much more efficient
+        than calling set() multiple times.
+
+        If timeout is given, use that timeout for the key; otherwise use the
+        default cache timeout.
+
+        On backends that support it, return a list of keys that failed
+        insertion, or an empty list if all keys were inserted successfully.
+        """
+        for key, value in data.items():
+            self.set(key, value, timeout=timeout, version=version)
+        return []
+
+    def delete_many(self, keys, version=None):
+        """
+        Delete a bunch of values in the cache at once. For certain backends
+        (memcached), this is much more efficient than calling delete() multiple
+        times.
+        """
+        for key in keys:
+            self.delete(key, version=version)
+
+    def clear(self):
+        """Remove *all* values from the cache at once."""
+        raise NotImplementedError('subclasses of BaseCache must provide a clear() method')
+
+    def validate_key(self, key):
+        """
+        Warn about keys that would not be portable to the memcached
+        backend. This encourages (but does not force) writing backend-portable
+        cache code.
+        """
+        for warning in memcache_key_warnings(key):
+            warnings.warn(warning, CacheKeyWarning)
+
+    def incr_version(self, key, delta=1, version=None):
+        """
+        Add delta to the cache version for the supplied key. Return the new
+        version.
+        """
+        if version is None:
+            version = self.version
+
+        value = self.get(key, version=version)
+        if value is None:
+            raise ValueError("Key '%s' not found" % key)
+
+        self.set(key, value, version=version + delta)
+        self.delete(key, version=version)
+        return version + delta
+
+    def decr_version(self, key, delta=1, version=None):
+        """
+        Subtract delta from the cache version for the supplied key. Return the
+        new version.
+        """
+        return self.incr_version(key, -delta, version)
+
+    def close(self, **kwargs):
+        """Close the cache connection"""
+        pass
+
+
+def memcache_key_warnings(key):
+    if len(key) > MEMCACHE_MAX_KEY_LENGTH:
+        yield (
+            'Cache key will cause errors if used with memcached: %r '
+            '(longer than %s)' % (key, MEMCACHE_MAX_KEY_LENGTH)
+        )
+    for char in key:
+        if ord(char) < 33 or ord(char) == 127:
+            yield (
+                'Cache key contains characters that will cause errors if '
+                'used with memcached: %r' % key
+            )
+            break
Index: venv/Lib/site-packages/django/core/cache/backends/db.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/core/cache/backends/db.py b/venv/Lib/site-packages/django/core/cache/backends/db.py
new file mode 100644
--- /dev/null	(date 1617030485633)
+++ b/venv/Lib/site-packages/django/core/cache/backends/db.py	(date 1617030485633)
@@ -0,0 +1,282 @@
+"Database cache backend."
+import base64
+import pickle
+from datetime import datetime
+
+from django.conf import settings
+from django.core.cache.backends.base import DEFAULT_TIMEOUT, BaseCache
+from django.db import DatabaseError, connections, models, router, transaction
+from django.utils import timezone
+
+
+class Options:
+    """A class that will quack like a Django model _meta class.
+
+    This allows cache operations to be controlled by the router
+    """
+    def __init__(self, table):
+        self.db_table = table
+        self.app_label = 'django_cache'
+        self.model_name = 'cacheentry'
+        self.verbose_name = 'cache entry'
+        self.verbose_name_plural = 'cache entries'
+        self.object_name = 'CacheEntry'
+        self.abstract = False
+        self.managed = True
+        self.proxy = False
+        self.swapped = False
+
+
+class BaseDatabaseCache(BaseCache):
+    def __init__(self, table, params):
+        super().__init__(params)
+        self._table = table
+
+        class CacheEntry:
+            _meta = Options(table)
+        self.cache_model_class = CacheEntry
+
+
+class DatabaseCache(BaseDatabaseCache):
+
+    # This class uses cursors provided by the database connection. This means
+    # it reads expiration values as aware or naive datetimes, depending on the
+    # value of USE_TZ and whether the database supports time zones. The ORM's
+    # conversion and adaptation infrastructure is then used to avoid comparing
+    # aware and naive datetimes accidentally.
+
+    pickle_protocol = pickle.HIGHEST_PROTOCOL
+
+    def get(self, key, default=None, version=None):
+        return self.get_many([key], version).get(key, default)
+
+    def get_many(self, keys, version=None):
+        if not keys:
+            return {}
+
+        key_map = {}
+        for key in keys:
+            self.validate_key(key)
+            key_map[self.make_key(key, version)] = key
+
+        db = router.db_for_read(self.cache_model_class)
+        connection = connections[db]
+        quote_name = connection.ops.quote_name
+        table = quote_name(self._table)
+
+        with connection.cursor() as cursor:
+            cursor.execute(
+                'SELECT %s, %s, %s FROM %s WHERE %s IN (%s)' % (
+                    quote_name('cache_key'),
+                    quote_name('value'),
+                    quote_name('expires'),
+                    table,
+                    quote_name('cache_key'),
+                    ', '.join(['%s'] * len(key_map)),
+                ),
+                list(key_map),
+            )
+            rows = cursor.fetchall()
+
+        result = {}
+        expired_keys = []
+        expression = models.Expression(output_field=models.DateTimeField())
+        converters = (connection.ops.get_db_converters(expression) + expression.get_db_converters(connection))
+        for key, value, expires in rows:
+            for converter in converters:
+                expires = converter(expires, expression, connection)
+            if expires < timezone.now():
+                expired_keys.append(key)
+            else:
+                value = connection.ops.process_clob(value)
+                value = pickle.loads(base64.b64decode(value.encode()))
+                result[key_map.get(key)] = value
+        self._base_delete_many(expired_keys)
+        return result
+
+    def set(self, key, value, timeout=DEFAULT_TIMEOUT, version=None):
+        key = self.make_key(key, version=version)
+        self.validate_key(key)
+        self._base_set('set', key, value, timeout)
+
+    def add(self, key, value, timeout=DEFAULT_TIMEOUT, version=None):
+        key = self.make_key(key, version=version)
+        self.validate_key(key)
+        return self._base_set('add', key, value, timeout)
+
+    def touch(self, key, timeout=DEFAULT_TIMEOUT, version=None):
+        key = self.make_key(key, version=version)
+        self.validate_key(key)
+        return self._base_set('touch', key, None, timeout)
+
+    def _base_set(self, mode, key, value, timeout=DEFAULT_TIMEOUT):
+        timeout = self.get_backend_timeout(timeout)
+        db = router.db_for_write(self.cache_model_class)
+        connection = connections[db]
+        quote_name = connection.ops.quote_name
+        table = quote_name(self._table)
+
+        with connection.cursor() as cursor:
+            cursor.execute("SELECT COUNT(*) FROM %s" % table)
+            num = cursor.fetchone()[0]
+            now = timezone.now()
+            now = now.replace(microsecond=0)
+            if timeout is None:
+                exp = datetime.max
+            elif settings.USE_TZ:
+                exp = datetime.utcfromtimestamp(timeout)
+            else:
+                exp = datetime.fromtimestamp(timeout)
+            exp = exp.replace(microsecond=0)
+            if num > self._max_entries:
+                self._cull(db, cursor, now)
+            pickled = pickle.dumps(value, self.pickle_protocol)
+            # The DB column is expecting a string, so make sure the value is a
+            # string, not bytes. Refs #19274.
+            b64encoded = base64.b64encode(pickled).decode('latin1')
+            try:
+                # Note: typecasting for datetimes is needed by some 3rd party
+                # database backends. All core backends work without typecasting,
+                # so be careful about changes here - test suite will NOT pick
+                # regressions.
+                with transaction.atomic(using=db):
+                    cursor.execute(
+                        'SELECT %s, %s FROM %s WHERE %s = %%s' % (
+                            quote_name('cache_key'),
+                            quote_name('expires'),
+                            table,
+                            quote_name('cache_key'),
+                        ),
+                        [key]
+                    )
+                    result = cursor.fetchone()
+
+                    if result:
+                        current_expires = result[1]
+                        expression = models.Expression(output_field=models.DateTimeField())
+                        for converter in (connection.ops.get_db_converters(expression) +
+                                          expression.get_db_converters(connection)):
+                            current_expires = converter(current_expires, expression, connection)
+
+                    exp = connection.ops.adapt_datetimefield_value(exp)
+                    if result and mode == 'touch':
+                        cursor.execute(
+                            'UPDATE %s SET %s = %%s WHERE %s = %%s' % (
+                                table,
+                                quote_name('expires'),
+                                quote_name('cache_key')
+                            ),
+                            [exp, key]
+                        )
+                    elif result and (mode == 'set' or (mode == 'add' and current_expires < now)):
+                        cursor.execute(
+                            'UPDATE %s SET %s = %%s, %s = %%s WHERE %s = %%s' % (
+                                table,
+                                quote_name('value'),
+                                quote_name('expires'),
+                                quote_name('cache_key'),
+                            ),
+                            [b64encoded, exp, key]
+                        )
+                    elif mode != 'touch':
+                        cursor.execute(
+                            'INSERT INTO %s (%s, %s, %s) VALUES (%%s, %%s, %%s)' % (
+                                table,
+                                quote_name('cache_key'),
+                                quote_name('value'),
+                                quote_name('expires'),
+                            ),
+                            [key, b64encoded, exp]
+                        )
+                    else:
+                        return False  # touch failed.
+            except DatabaseError:
+                # To be threadsafe, updates/inserts are allowed to fail silently
+                return False
+            else:
+                return True
+
+    def delete(self, key, version=None):
+        self.validate_key(key)
+        return self._base_delete_many([self.make_key(key, version)])
+
+    def delete_many(self, keys, version=None):
+        key_list = []
+        for key in keys:
+            self.validate_key(key)
+            key_list.append(self.make_key(key, version))
+        self._base_delete_many(key_list)
+
+    def _base_delete_many(self, keys):
+        if not keys:
+            return False
+
+        db = router.db_for_write(self.cache_model_class)
+        connection = connections[db]
+        quote_name = connection.ops.quote_name
+        table = quote_name(self._table)
+
+        with connection.cursor() as cursor:
+            cursor.execute(
+                'DELETE FROM %s WHERE %s IN (%s)' % (
+                    table,
+                    quote_name('cache_key'),
+                    ', '.join(['%s'] * len(keys)),
+                ),
+                keys,
+            )
+        return bool(cursor.rowcount)
+
+    def has_key(self, key, version=None):
+        key = self.make_key(key, version=version)
+        self.validate_key(key)
+
+        db = router.db_for_read(self.cache_model_class)
+        connection = connections[db]
+        quote_name = connection.ops.quote_name
+
+        if settings.USE_TZ:
+            now = datetime.utcnow()
+        else:
+            now = datetime.now()
+        now = now.replace(microsecond=0)
+
+        with connection.cursor() as cursor:
+            cursor.execute(
+                'SELECT %s FROM %s WHERE %s = %%s and expires > %%s' % (
+                    quote_name('cache_key'),
+                    quote_name(self._table),
+                    quote_name('cache_key'),
+                ),
+                [key, connection.ops.adapt_datetimefield_value(now)]
+            )
+            return cursor.fetchone() is not None
+
+    def _cull(self, db, cursor, now):
+        if self._cull_frequency == 0:
+            self.clear()
+        else:
+            connection = connections[db]
+            table = connection.ops.quote_name(self._table)
+            cursor.execute("DELETE FROM %s WHERE expires < %%s" % table,
+                           [connection.ops.adapt_datetimefield_value(now)])
+            cursor.execute("SELECT COUNT(*) FROM %s" % table)
+            num = cursor.fetchone()[0]
+            if num > self._max_entries:
+                cull_num = num // self._cull_frequency
+                cursor.execute(
+                    connection.ops.cache_key_culling_sql() % table,
+                    [cull_num])
+                last_cache_key = cursor.fetchone()
+                if last_cache_key:
+                    cursor.execute(
+                        'DELETE FROM %s WHERE cache_key < %%s' % table,
+                        [last_cache_key[0]],
+                    )
+
+    def clear(self):
+        db = router.db_for_write(self.cache_model_class)
+        connection = connections[db]
+        table = connection.ops.quote_name(self._table)
+        with connection.cursor() as cursor:
+            cursor.execute('DELETE FROM %s' % table)
Index: venv/Lib/site-packages/django/core/cache/backends/dummy.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/core/cache/backends/dummy.py b/venv/Lib/site-packages/django/core/cache/backends/dummy.py
new file mode 100644
--- /dev/null	(date 1617030485633)
+++ b/venv/Lib/site-packages/django/core/cache/backends/dummy.py	(date 1617030485633)
@@ -0,0 +1,39 @@
+"Dummy cache backend"
+
+from django.core.cache.backends.base import DEFAULT_TIMEOUT, BaseCache
+
+
+class DummyCache(BaseCache):
+    def __init__(self, host, *args, **kwargs):
+        super().__init__(*args, **kwargs)
+
+    def add(self, key, value, timeout=DEFAULT_TIMEOUT, version=None):
+        key = self.make_key(key, version=version)
+        self.validate_key(key)
+        return True
+
+    def get(self, key, default=None, version=None):
+        key = self.make_key(key, version=version)
+        self.validate_key(key)
+        return default
+
+    def set(self, key, value, timeout=DEFAULT_TIMEOUT, version=None):
+        key = self.make_key(key, version=version)
+        self.validate_key(key)
+
+    def touch(self, key, timeout=DEFAULT_TIMEOUT, version=None):
+        self.validate_key(key)
+        return False
+
+    def delete(self, key, version=None):
+        key = self.make_key(key, version=version)
+        self.validate_key(key)
+        return False
+
+    def has_key(self, key, version=None):
+        key = self.make_key(key, version=version)
+        self.validate_key(key)
+        return False
+
+    def clear(self):
+        pass
Index: venv/Lib/site-packages/django/core/cache/backends/filebased.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/core/cache/backends/filebased.py b/venv/Lib/site-packages/django/core/cache/backends/filebased.py
new file mode 100644
--- /dev/null	(date 1617030485634)
+++ b/venv/Lib/site-packages/django/core/cache/backends/filebased.py	(date 1617030485634)
@@ -0,0 +1,164 @@
+"File-based cache backend"
+import glob
+import hashlib
+import os
+import pickle
+import random
+import tempfile
+import time
+import zlib
+
+from django.core.cache.backends.base import DEFAULT_TIMEOUT, BaseCache
+from django.core.files import locks
+from django.core.files.move import file_move_safe
+
+
+class FileBasedCache(BaseCache):
+    cache_suffix = '.djcache'
+    pickle_protocol = pickle.HIGHEST_PROTOCOL
+
+    def __init__(self, dir, params):
+        super().__init__(params)
+        self._dir = os.path.abspath(dir)
+        self._createdir()
+
+    def add(self, key, value, timeout=DEFAULT_TIMEOUT, version=None):
+        if self.has_key(key, version):
+            return False
+        self.set(key, value, timeout, version)
+        return True
+
+    def get(self, key, default=None, version=None):
+        fname = self._key_to_file(key, version)
+        try:
+            with open(fname, 'rb') as f:
+                if not self._is_expired(f):
+                    return pickle.loads(zlib.decompress(f.read()))
+        except FileNotFoundError:
+            pass
+        return default
+
+    def _write_content(self, file, timeout, value):
+        expiry = self.get_backend_timeout(timeout)
+        file.write(pickle.dumps(expiry, self.pickle_protocol))
+        file.write(zlib.compress(pickle.dumps(value, self.pickle_protocol)))
+
+    def set(self, key, value, timeout=DEFAULT_TIMEOUT, version=None):
+        self._createdir()  # Cache dir can be deleted at any time.
+        fname = self._key_to_file(key, version)
+        self._cull()  # make some room if necessary
+        fd, tmp_path = tempfile.mkstemp(dir=self._dir)
+        renamed = False
+        try:
+            with open(fd, 'wb') as f:
+                self._write_content(f, timeout, value)
+            file_move_safe(tmp_path, fname, allow_overwrite=True)
+            renamed = True
+        finally:
+            if not renamed:
+                os.remove(tmp_path)
+
+    def touch(self, key, timeout=DEFAULT_TIMEOUT, version=None):
+        try:
+            with open(self._key_to_file(key, version), 'r+b') as f:
+                try:
+                    locks.lock(f, locks.LOCK_EX)
+                    if self._is_expired(f):
+                        return False
+                    else:
+                        previous_value = pickle.loads(zlib.decompress(f.read()))
+                        f.seek(0)
+                        self._write_content(f, timeout, previous_value)
+                        return True
+                finally:
+                    locks.unlock(f)
+        except FileNotFoundError:
+            return False
+
+    def delete(self, key, version=None):
+        return self._delete(self._key_to_file(key, version))
+
+    def _delete(self, fname):
+        if not fname.startswith(self._dir) or not os.path.exists(fname):
+            return False
+        try:
+            os.remove(fname)
+        except FileNotFoundError:
+            # The file may have been removed by another process.
+            return False
+        return True
+
+    def has_key(self, key, version=None):
+        fname = self._key_to_file(key, version)
+        if os.path.exists(fname):
+            with open(fname, 'rb') as f:
+                return not self._is_expired(f)
+        return False
+
+    def _cull(self):
+        """
+        Remove random cache entries if max_entries is reached at a ratio
+        of num_entries / cull_frequency. A value of 0 for CULL_FREQUENCY means
+        that the entire cache will be purged.
+        """
+        filelist = self._list_cache_files()
+        num_entries = len(filelist)
+        if num_entries < self._max_entries:
+            return  # return early if no culling is required
+        if self._cull_frequency == 0:
+            return self.clear()  # Clear the cache when CULL_FREQUENCY = 0
+        # Delete a random selection of entries
+        filelist = random.sample(filelist,
+                                 int(num_entries / self._cull_frequency))
+        for fname in filelist:
+            self._delete(fname)
+
+    def _createdir(self):
+        # Set the umask because os.makedirs() doesn't apply the "mode" argument
+        # to intermediate-level directories.
+        old_umask = os.umask(0o077)
+        try:
+            os.makedirs(self._dir, 0o700, exist_ok=True)
+        finally:
+            os.umask(old_umask)
+
+    def _key_to_file(self, key, version=None):
+        """
+        Convert a key into a cache file path. Basically this is the
+        root cache path joined with the md5sum of the key and a suffix.
+        """
+        key = self.make_key(key, version=version)
+        self.validate_key(key)
+        return os.path.join(self._dir, ''.join(
+            [hashlib.md5(key.encode()).hexdigest(), self.cache_suffix]))
+
+    def clear(self):
+        """
+        Remove all the cache files.
+        """
+        for fname in self._list_cache_files():
+            self._delete(fname)
+
+    def _is_expired(self, f):
+        """
+        Take an open cache file `f` and delete it if it's expired.
+        """
+        try:
+            exp = pickle.load(f)
+        except EOFError:
+            exp = 0  # An empty file is considered expired.
+        if exp is not None and exp < time.time():
+            f.close()  # On Windows a file has to be closed before deleting
+            self._delete(f.name)
+            return True
+        return False
+
+    def _list_cache_files(self):
+        """
+        Get a list of paths to all the cache files. These are all the files
+        in the root cache dir that end on the cache_suffix.
+        """
+        return [
+            os.path.join(self._dir, fname)
+            for fname in glob.glob1(self._dir, '*%s' % self.cache_suffix)
+        ]
Index: venv/pyvenv.cfg
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/pyvenv.cfg b/venv/pyvenv.cfg
new file mode 100644
--- /dev/null	(date 1617030431708)
+++ b/venv/pyvenv.cfg	(date 1617030431708)
@@ -0,0 +1,3 @@
+home = C:\Users\Joma\AppData\Local\Programs\Python\Python39
+include-system-site-packages = false
+version = 3.9.1
Index: venv/Lib/site-packages/django/core/cache/backends/locmem.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/core/cache/backends/locmem.py b/venv/Lib/site-packages/django/core/cache/backends/locmem.py
new file mode 100644
--- /dev/null	(date 1617030485634)
+++ b/venv/Lib/site-packages/django/core/cache/backends/locmem.py	(date 1617030485634)
@@ -0,0 +1,123 @@
+"Thread-safe in-memory cache backend."
+import pickle
+import time
+from collections import OrderedDict
+from threading import Lock
+
+from django.core.cache.backends.base import DEFAULT_TIMEOUT, BaseCache
+
+# Global in-memory store of cache data. Keyed by name, to provide
+# multiple named local memory caches.
+_caches = {}
+_expire_info = {}
+_locks = {}
+
+
+class LocMemCache(BaseCache):
+    pickle_protocol = pickle.HIGHEST_PROTOCOL
+
+    def __init__(self, name, params):
+        super().__init__(params)
+        self._cache = _caches.setdefault(name, OrderedDict())
+        self._expire_info = _expire_info.setdefault(name, {})
+        self._lock = _locks.setdefault(name, Lock())
+
+    def add(self, key, value, timeout=DEFAULT_TIMEOUT, version=None):
+        key = self.make_key(key, version=version)
+        self.validate_key(key)
+        pickled = pickle.dumps(value, self.pickle_protocol)
+        with self._lock:
+            if self._has_expired(key):
+                self._set(key, pickled, timeout)
+                return True
+            return False
+
+    def get(self, key, default=None, version=None):
+        key = self.make_key(key, version=version)
+        self.validate_key(key)
+        with self._lock:
+            if self._has_expired(key):
+                self._delete(key)
+                return default
+            pickled = self._cache[key]
+            self._cache.move_to_end(key, last=False)
+        return pickle.loads(pickled)
+
+    def _set(self, key, value, timeout=DEFAULT_TIMEOUT):
+        if len(self._cache) >= self._max_entries:
+            self._cull()
+        self._cache[key] = value
+        self._cache.move_to_end(key, last=False)
+        self._expire_info[key] = self.get_backend_timeout(timeout)
+
+    def set(self, key, value, timeout=DEFAULT_TIMEOUT, version=None):
+        key = self.make_key(key, version=version)
+        self.validate_key(key)
+        pickled = pickle.dumps(value, self.pickle_protocol)
+        with self._lock:
+            self._set(key, pickled, timeout)
+
+    def touch(self, key, timeout=DEFAULT_TIMEOUT, version=None):
+        key = self.make_key(key, version=version)
+        with self._lock:
+            if self._has_expired(key):
+                return False
+            self._expire_info[key] = self.get_backend_timeout(timeout)
+            return True
+
+    def incr(self, key, delta=1, version=None):
+        key = self.make_key(key, version=version)
+        self.validate_key(key)
+        with self._lock:
+            if self._has_expired(key):
+                self._delete(key)
+                raise ValueError("Key '%s' not found" % key)
+            pickled = self._cache[key]
+            value = pickle.loads(pickled)
+            new_value = value + delta
+            pickled = pickle.dumps(new_value, self.pickle_protocol)
+            self._cache[key] = pickled
+            self._cache.move_to_end(key, last=False)
+        return new_value
+
+    def has_key(self, key, version=None):
+        key = self.make_key(key, version=version)
+        self.validate_key(key)
+        with self._lock:
+            if self._has_expired(key):
+                self._delete(key)
+                return False
+            return True
+
+    def _has_expired(self, key):
+        exp = self._expire_info.get(key, -1)
+        return exp is not None and exp <= time.time()
+
+    def _cull(self):
+        if self._cull_frequency == 0:
+            self._cache.clear()
+            self._expire_info.clear()
+        else:
+            count = len(self._cache) // self._cull_frequency
+            for i in range(count):
+                key, _ = self._cache.popitem()
+                del self._expire_info[key]
+
+    def _delete(self, key):
+        try:
+            del self._cache[key]
+            del self._expire_info[key]
+        except KeyError:
+            return False
+        return True
+
+    def delete(self, key, version=None):
+        key = self.make_key(key, version=version)
+        self.validate_key(key)
+        with self._lock:
+            return self._delete(key)
+
+    def clear(self):
+        with self._lock:
+            self._cache.clear()
+            self._expire_info.clear()
Index: venv/Lib/site-packages/django/core/cache/backends/memcached.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/core/cache/backends/memcached.py b/venv/Lib/site-packages/django/core/cache/backends/memcached.py
new file mode 100644
--- /dev/null	(date 1617030485635)
+++ b/venv/Lib/site-packages/django/core/cache/backends/memcached.py	(date 1617030485635)
@@ -0,0 +1,215 @@
+"Memcached cache backend"
+
+import pickle
+import re
+import time
+
+from django.core.cache.backends.base import (
+    DEFAULT_TIMEOUT, BaseCache, InvalidCacheKey, memcache_key_warnings,
+)
+from django.utils.functional import cached_property
+
+
+class BaseMemcachedCache(BaseCache):
+    def __init__(self, server, params, library, value_not_found_exception):
+        super().__init__(params)
+        if isinstance(server, str):
+            self._servers = re.split('[;,]', server)
+        else:
+            self._servers = server
+
+        # The exception type to catch from the underlying library for a key
+        # that was not found. This is a ValueError for python-memcache,
+        # pylibmc.NotFound for pylibmc, and cmemcache will return None without
+        # raising an exception.
+        self.LibraryValueNotFoundException = value_not_found_exception
+
+        self._lib = library
+        self._options = params.get('OPTIONS') or {}
+
+    @property
+    def _cache(self):
+        """
+        Implement transparent thread-safe access to a memcached client.
+        """
+        if getattr(self, '_client', None) is None:
+            self._client = self._lib.Client(self._servers, **self._options)
+
+        return self._client
+
+    def get_backend_timeout(self, timeout=DEFAULT_TIMEOUT):
+        """
+        Memcached deals with long (> 30 days) timeouts in a special
+        way. Call this function to obtain a safe value for your timeout.
+        """
+        if timeout == DEFAULT_TIMEOUT:
+            timeout = self.default_timeout
+
+        if timeout is None:
+            # Using 0 in memcache sets a non-expiring timeout.
+            return 0
+        elif int(timeout) == 0:
+            # Other cache backends treat 0 as set-and-expire. To achieve this
+            # in memcache backends, a negative timeout must be passed.
+            timeout = -1
+
+        if timeout > 2592000:  # 60*60*24*30, 30 days
+            # See https://github.com/memcached/memcached/wiki/Programming#expiration
+            # "Expiration times can be set from 0, meaning "never expire", to
+            # 30 days. Any time higher than 30 days is interpreted as a Unix
+            # timestamp date. If you want to expire an object on January 1st of
+            # next year, this is how you do that."
+            #
+            # This means that we have to switch to absolute timestamps.
+            timeout += int(time.time())
+        return int(timeout)
+
+    def add(self, key, value, timeout=DEFAULT_TIMEOUT, version=None):
+        key = self.make_key(key, version=version)
+        self.validate_key(key)
+        return self._cache.add(key, value, self.get_backend_timeout(timeout))
+
+    def get(self, key, default=None, version=None):
+        key = self.make_key(key, version=version)
+        self.validate_key(key)
+        return self._cache.get(key, default)
+
+    def set(self, key, value, timeout=DEFAULT_TIMEOUT, version=None):
+        key = self.make_key(key, version=version)
+        self.validate_key(key)
+        if not self._cache.set(key, value, self.get_backend_timeout(timeout)):
+            # make sure the key doesn't keep its old value in case of failure to set (memcached's 1MB limit)
+            self._cache.delete(key)
+
+    def delete(self, key, version=None):
+        key = self.make_key(key, version=version)
+        self.validate_key(key)
+        return bool(self._cache.delete(key))
+
+    def get_many(self, keys, version=None):
+        key_map = {self.make_key(key, version=version): key for key in keys}
+        for key in key_map:
+            self.validate_key(key)
+        ret = self._cache.get_multi(key_map.keys())
+        return {key_map[k]: v for k, v in ret.items()}
+
+    def close(self, **kwargs):
+        # Many clients don't clean up connections properly.
+        self._cache.disconnect_all()
+
+    def incr(self, key, delta=1, version=None):
+        key = self.make_key(key, version=version)
+        self.validate_key(key)
+        # memcached doesn't support a negative delta
+        if delta < 0:
+            return self._cache.decr(key, -delta)
+        try:
+            val = self._cache.incr(key, delta)
+
+        # python-memcache responds to incr on nonexistent keys by
+        # raising a ValueError, pylibmc by raising a pylibmc.NotFound
+        # and Cmemcache returns None. In all cases,
+        # we should raise a ValueError though.
+        except self.LibraryValueNotFoundException:
+            val = None
+        if val is None:
+            raise ValueError("Key '%s' not found" % key)
+        return val
+
+    def decr(self, key, delta=1, version=None):
+        key = self.make_key(key, version=version)
+        self.validate_key(key)
+        # memcached doesn't support a negative delta
+        if delta < 0:
+            return self._cache.incr(key, -delta)
+        try:
+            val = self._cache.decr(key, delta)
+
+        # python-memcache responds to incr on nonexistent keys by
+        # raising a ValueError, pylibmc by raising a pylibmc.NotFound
+        # and Cmemcache returns None. In all cases,
+        # we should raise a ValueError though.
+        except self.LibraryValueNotFoundException:
+            val = None
+        if val is None:
+            raise ValueError("Key '%s' not found" % key)
+        return val
+
+    def set_many(self, data, timeout=DEFAULT_TIMEOUT, version=None):
+        safe_data = {}
+        original_keys = {}
+        for key, value in data.items():
+            safe_key = self.make_key(key, version=version)
+            self.validate_key(safe_key)
+            safe_data[safe_key] = value
+            original_keys[safe_key] = key
+        failed_keys = self._cache.set_multi(safe_data, self.get_backend_timeout(timeout))
+        return [original_keys[k] for k in failed_keys]
+
+    def delete_many(self, keys, version=None):
+        self._cache.delete_multi(self.make_key(key, version=version) for key in keys)
+
+    def clear(self):
+        self._cache.flush_all()
+
+    def validate_key(self, key):
+        for warning in memcache_key_warnings(key):
+            raise InvalidCacheKey(warning)
+
+
+class MemcachedCache(BaseMemcachedCache):
+    "An implementation of a cache binding using python-memcached"
+    def __init__(self, server, params):
+        import memcache
+        super().__init__(server, params, library=memcache, value_not_found_exception=ValueError)
+
+    @property
+    def _cache(self):
+        if getattr(self, '_client', None) is None:
+            client_kwargs = {'pickleProtocol': pickle.HIGHEST_PROTOCOL}
+            client_kwargs.update(self._options)
+            self._client = self._lib.Client(self._servers, **client_kwargs)
+        return self._client
+
+    def touch(self, key, timeout=DEFAULT_TIMEOUT, version=None):
+        key = self.make_key(key, version=version)
+        return self._cache.touch(key, self.get_backend_timeout(timeout)) != 0
+
+    def get(self, key, default=None, version=None):
+        key = self.make_key(key, version=version)
+        val = self._cache.get(key)
+        # python-memcached doesn't support default values in get().
+        # https://github.com/linsomniac/python-memcached/issues/159
+        # Remove this method if that issue is fixed.
+        if val is None:
+            return default
+        return val
+
+    def delete(self, key, version=None):
+        # python-memcached's delete() returns True when key doesn't exist.
+        # https://github.com/linsomniac/python-memcached/issues/170
+        # Call _deletetouch() without the NOT_FOUND in expected results.
+        key = self.make_key(key, version=version)
+        return bool(self._cache._deletetouch([b'DELETED'], 'delete', key))
+
+
+class PyLibMCCache(BaseMemcachedCache):
+    "An implementation of a cache binding using pylibmc"
+    def __init__(self, server, params):
+        import pylibmc
+        super().__init__(server, params, library=pylibmc, value_not_found_exception=pylibmc.NotFound)
+
+    @cached_property
+    def _cache(self):
+        return self._lib.Client(self._servers, **self._options)
+
+    def touch(self, key, timeout=DEFAULT_TIMEOUT, version=None):
+        key = self.make_key(key, version=version)
+        if timeout == 0:
+            return self._cache.delete(key)
+        return self._cache.touch(key, self.get_backend_timeout(timeout))
+
+    def close(self, **kwargs):
+        # libmemcached manages its own connections. Don't call disconnect_all()
+        # as it resets the failover state and creates unnecessary reconnects.
+        pass
Index: venv/Lib/site-packages/django/contrib/admin/templatetags/admin_list.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/admin/templatetags/admin_list.py b/venv/Lib/site-packages/django/contrib/admin/templatetags/admin_list.py
new file mode 100644
--- /dev/null	(date 1617030482872)
+++ b/venv/Lib/site-packages/django/contrib/admin/templatetags/admin_list.py	(date 1617030482872)
@@ -0,0 +1,499 @@
+import datetime
+
+from django.contrib.admin.templatetags.admin_urls import add_preserved_filters
+from django.contrib.admin.utils import (
+    display_for_field, display_for_value, get_fields_from_path,
+    label_for_field, lookup_field,
+)
+from django.contrib.admin.views.main import (
+    ALL_VAR, ORDER_VAR, PAGE_VAR, SEARCH_VAR,
+)
+from django.core.exceptions import ObjectDoesNotExist
+from django.db import models
+from django.template import Library
+from django.template.loader import get_template
+from django.templatetags.static import static
+from django.urls import NoReverseMatch
+from django.utils import formats, timezone
+from django.utils.html import format_html
+from django.utils.safestring import mark_safe
+from django.utils.text import capfirst
+from django.utils.translation import gettext as _
+
+from .base import InclusionAdminNode
+
+register = Library()
+
+DOT = '.'
+
+
+@register.simple_tag
+def paginator_number(cl, i):
+    """
+    Generate an individual page index link in a paginated list.
+    """
+    if i == DOT:
+        return '… '
+    elif i == cl.page_num:
+        return format_html('<span class="this-page">{}</span> ', i + 1)
+    else:
+        return format_html(
+            '<a href="{}"{}>{}</a> ',
+            cl.get_query_string({PAGE_VAR: i}),
+            mark_safe(' class="end"' if i == cl.paginator.num_pages - 1 else ''),
+            i + 1,
+        )
+
+
+def pagination(cl):
+    """
+    Generate the series of links to the pages in a paginated list.
+    """
+    paginator, page_num = cl.paginator, cl.page_num
+
+    pagination_required = (not cl.show_all or not cl.can_show_all) and cl.multi_page
+    if not pagination_required:
+        page_range = []
+    else:
+        ON_EACH_SIDE = 3
+        ON_ENDS = 2
+
+        # If there are 10 or fewer pages, display links to every page.
+        # Otherwise, do some fancy
+        if paginator.num_pages <= 10:
+            page_range = range(paginator.num_pages)
+        else:
+            # Insert "smart" pagination links, so that there are always ON_ENDS
+            # links at either end of the list of pages, and there are always
+            # ON_EACH_SIDE links at either end of the "current page" link.
+            page_range = []
+            if page_num > (ON_EACH_SIDE + ON_ENDS):
+                page_range += [
+                    *range(0, ON_ENDS), DOT,
+                    *range(page_num - ON_EACH_SIDE, page_num + 1),
+                ]
+            else:
+                page_range.extend(range(0, page_num + 1))
+            if page_num < (paginator.num_pages - ON_EACH_SIDE - ON_ENDS - 1):
+                page_range += [
+                    *range(page_num + 1, page_num + ON_EACH_SIDE + 1), DOT,
+                    *range(paginator.num_pages - ON_ENDS, paginator.num_pages)
+                ]
+            else:
+                page_range.extend(range(page_num + 1, paginator.num_pages))
+
+    need_show_all_link = cl.can_show_all and not cl.show_all and cl.multi_page
+    return {
+        'cl': cl,
+        'pagination_required': pagination_required,
+        'show_all_url': need_show_all_link and cl.get_query_string({ALL_VAR: ''}),
+        'page_range': page_range,
+        'ALL_VAR': ALL_VAR,
+        '1': 1,
+    }
+
+
+@register.tag(name='pagination')
+def pagination_tag(parser, token):
+    return InclusionAdminNode(
+        parser, token,
+        func=pagination,
+        template_name='pagination.html',
+        takes_context=False,
+    )
+
+
+def result_headers(cl):
+    """
+    Generate the list column headers.
+    """
+    ordering_field_columns = cl.get_ordering_field_columns()
+    for i, field_name in enumerate(cl.list_display):
+        text, attr = label_for_field(
+            field_name, cl.model,
+            model_admin=cl.model_admin,
+            return_attr=True
+        )
+        is_field_sortable = cl.sortable_by is None or field_name in cl.sortable_by
+        if attr:
+            field_name = _coerce_field_name(field_name, i)
+            # Potentially not sortable
+
+            # if the field is the action checkbox: no sorting and special class
+            if field_name == 'action_checkbox':
+                yield {
+                    "text": text,
+                    "class_attrib": mark_safe(' class="action-checkbox-column"'),
+                    "sortable": False,
+                }
+                continue
+
+            admin_order_field = getattr(attr, "admin_order_field", None)
+            # Set ordering for attr that is a property, if defined.
+            if isinstance(attr, property) and hasattr(attr, 'fget'):
+                admin_order_field = getattr(attr.fget, 'admin_order_field', None)
+            if not admin_order_field:
+                is_field_sortable = False
+
+        if not is_field_sortable:
+            # Not sortable
+            yield {
+                'text': text,
+                'class_attrib': format_html(' class="column-{}"', field_name),
+                'sortable': False,
+            }
+            continue
+
+        # OK, it is sortable if we got this far
+        th_classes = ['sortable', 'column-{}'.format(field_name)]
+        order_type = ''
+        new_order_type = 'asc'
+        sort_priority = 0
+        # Is it currently being sorted on?
+        is_sorted = i in ordering_field_columns
+        if is_sorted:
+            order_type = ordering_field_columns.get(i).lower()
+            sort_priority = list(ordering_field_columns).index(i) + 1
+            th_classes.append('sorted %sending' % order_type)
+            new_order_type = {'asc': 'desc', 'desc': 'asc'}[order_type]
+
+        # build new ordering param
+        o_list_primary = []  # URL for making this field the primary sort
+        o_list_remove = []  # URL for removing this field from sort
+        o_list_toggle = []  # URL for toggling order type for this field
+
+        def make_qs_param(t, n):
+            return ('-' if t == 'desc' else '') + str(n)
+
+        for j, ot in ordering_field_columns.items():
+            if j == i:  # Same column
+                param = make_qs_param(new_order_type, j)
+                # We want clicking on this header to bring the ordering to the
+                # front
+                o_list_primary.insert(0, param)
+                o_list_toggle.append(param)
+                # o_list_remove - omit
+            else:
+                param = make_qs_param(ot, j)
+                o_list_primary.append(param)
+                o_list_toggle.append(param)
+                o_list_remove.append(param)
+
+        if i not in ordering_field_columns:
+            o_list_primary.insert(0, make_qs_param(new_order_type, i))
+
+        yield {
+            "text": text,
+            "sortable": True,
+            "sorted": is_sorted,
+            "ascending": order_type == "asc",
+            "sort_priority": sort_priority,
+            "url_primary": cl.get_query_string({ORDER_VAR: '.'.join(o_list_primary)}),
+            "url_remove": cl.get_query_string({ORDER_VAR: '.'.join(o_list_remove)}),
+            "url_toggle": cl.get_query_string({ORDER_VAR: '.'.join(o_list_toggle)}),
+            "class_attrib": format_html(' class="{}"', ' '.join(th_classes)) if th_classes else '',
+        }
+
+
+def _boolean_icon(field_val):
+    icon_url = static('admin/img/icon-%s.svg' % {True: 'yes', False: 'no', None: 'unknown'}[field_val])
+    return format_html('<img src="{}" alt="{}">', icon_url, field_val)
+
+
+def _coerce_field_name(field_name, field_index):
+    """
+    Coerce a field_name (which may be a callable) to a string.
+    """
+    if callable(field_name):
+        if field_name.__name__ == '<lambda>':
+            return 'lambda' + str(field_index)
+        else:
+            return field_name.__name__
+    return field_name
+
+
+def items_for_result(cl, result, form):
+    """
+    Generate the actual list of data.
+    """
+
+    def link_in_col(is_first, field_name, cl):
+        if cl.list_display_links is None:
+            return False
+        if is_first and not cl.list_display_links:
+            return True
+        return field_name in cl.list_display_links
+
+    first = True
+    pk = cl.lookup_opts.pk.attname
+    for field_index, field_name in enumerate(cl.list_display):
+        empty_value_display = cl.model_admin.get_empty_value_display()
+        row_classes = ['field-%s' % _coerce_field_name(field_name, field_index)]
+        try:
+            f, attr, value = lookup_field(field_name, result, cl.model_admin)
+        except ObjectDoesNotExist:
+            result_repr = empty_value_display
+        else:
+            empty_value_display = getattr(attr, 'empty_value_display', empty_value_display)
+            if f is None or f.auto_created:
+                if field_name == 'action_checkbox':
+                    row_classes = ['action-checkbox']
+                boolean = getattr(attr, 'boolean', False)
+                result_repr = display_for_value(value, empty_value_display, boolean)
+                if isinstance(value, (datetime.date, datetime.time)):
+                    row_classes.append('nowrap')
+            else:
+                if isinstance(f.remote_field, models.ManyToOneRel):
+                    field_val = getattr(result, f.name)
+                    if field_val is None:
+                        result_repr = empty_value_display
+                    else:
+                        result_repr = field_val
+                else:
+                    result_repr = display_for_field(value, f, empty_value_display)
+                if isinstance(f, (models.DateField, models.TimeField, models.ForeignKey)):
+                    row_classes.append('nowrap')
+        row_class = mark_safe(' class="%s"' % ' '.join(row_classes))
+        # If list_display_links not defined, add the link tag to the first field
+        if link_in_col(first, field_name, cl):
+            table_tag = 'th' if first else 'td'
+            first = False
+
+            # Display link to the result's change_view if the url exists, else
+            # display just the result's representation.
+            try:
+                url = cl.url_for_result(result)
+            except NoReverseMatch:
+                link_or_text = result_repr
+            else:
+                url = add_preserved_filters({'preserved_filters': cl.preserved_filters, 'opts': cl.opts}, url)
+                # Convert the pk to something that can be used in Javascript.
+                # Problem cases are non-ASCII strings.
+                if cl.to_field:
+                    attr = str(cl.to_field)
+                else:
+                    attr = pk
+                value = result.serializable_value(attr)
+                link_or_text = format_html(
+                    '<a href="{}"{}>{}</a>',
+                    url,
+                    format_html(
+                        ' data-popup-opener="{}"', value
+                    ) if cl.is_popup else '',
+                    result_repr)
+
+            yield format_html('<{}{}>{}</{}>', table_tag, row_class, link_or_text, table_tag)
+        else:
+            # By default the fields come from ModelAdmin.list_editable, but if we pull
+            # the fields out of the form instead of list_editable custom admins
+            # can provide fields on a per request basis
+            if (form and field_name in form.fields and not (
+                    field_name == cl.model._meta.pk.name and
+                    form[cl.model._meta.pk.name].is_hidden)):
+                bf = form[field_name]
+                result_repr = mark_safe(str(bf.errors) + str(bf))
+            yield format_html('<td{}>{}</td>', row_class, result_repr)
+    if form and not form[cl.model._meta.pk.name].is_hidden:
+        yield format_html('<td>{}</td>', form[cl.model._meta.pk.name])
+
+
+class ResultList(list):
+    """
+    Wrapper class used to return items in a list_editable changelist, annotated
+    with the form object for error reporting purposes. Needed to maintain
+    backwards compatibility with existing admin templates.
+    """
+    def __init__(self, form, *items):
+        self.form = form
+        super().__init__(*items)
+
+
+def results(cl):
+    if cl.formset:
+        for res, form in zip(cl.result_list, cl.formset.forms):
+            yield ResultList(form, items_for_result(cl, res, form))
+    else:
+        for res in cl.result_list:
+            yield ResultList(None, items_for_result(cl, res, None))
+
+
+def result_hidden_fields(cl):
+    if cl.formset:
+        for res, form in zip(cl.result_list, cl.formset.forms):
+            if form[cl.model._meta.pk.name].is_hidden:
+                yield mark_safe(form[cl.model._meta.pk.name])
+
+
+def result_list(cl):
+    """
+    Display the headers and data list together.
+    """
+    headers = list(result_headers(cl))
+    num_sorted_fields = 0
+    for h in headers:
+        if h['sortable'] and h['sorted']:
+            num_sorted_fields += 1
+    return {
+        'cl': cl,
+        'result_hidden_fields': list(result_hidden_fields(cl)),
+        'result_headers': headers,
+        'num_sorted_fields': num_sorted_fields,
+        'results': list(results(cl)),
+    }
+
+
+@register.tag(name='result_list')
+def result_list_tag(parser, token):
+    return InclusionAdminNode(
+        parser, token,
+        func=result_list,
+        template_name='change_list_results.html',
+        takes_context=False,
+    )
+
+
+def date_hierarchy(cl):
+    """
+    Display the date hierarchy for date drill-down functionality.
+    """
+    if cl.date_hierarchy:
+        field_name = cl.date_hierarchy
+        field = get_fields_from_path(cl.model, field_name)[-1]
+        if isinstance(field, models.DateTimeField):
+            dates_or_datetimes = 'datetimes'
+            qs_kwargs = {'is_dst': True}
+        else:
+            dates_or_datetimes = 'dates'
+            qs_kwargs = {}
+        year_field = '%s__year' % field_name
+        month_field = '%s__month' % field_name
+        day_field = '%s__day' % field_name
+        field_generic = '%s__' % field_name
+        year_lookup = cl.params.get(year_field)
+        month_lookup = cl.params.get(month_field)
+        day_lookup = cl.params.get(day_field)
+
+        def link(filters):
+            return cl.get_query_string(filters, [field_generic])
+
+        if not (year_lookup or month_lookup or day_lookup):
+            # select appropriate start level
+            date_range = cl.queryset.aggregate(first=models.Min(field_name),
+                                               last=models.Max(field_name))
+            if date_range['first'] and date_range['last']:
+                if dates_or_datetimes == 'datetimes':
+                    date_range = {
+                        k: timezone.localtime(v) if timezone.is_aware(v) else v
+                        for k, v in date_range.items()
+                    }
+                if date_range['first'].year == date_range['last'].year:
+                    year_lookup = date_range['first'].year
+                    if date_range['first'].month == date_range['last'].month:
+                        month_lookup = date_range['first'].month
+
+        if year_lookup and month_lookup and day_lookup:
+            day = datetime.date(int(year_lookup), int(month_lookup), int(day_lookup))
+            return {
+                'show': True,
+                'back': {
+                    'link': link({year_field: year_lookup, month_field: month_lookup}),
+                    'title': capfirst(formats.date_format(day, 'YEAR_MONTH_FORMAT'))
+                },
+                'choices': [{'title': capfirst(formats.date_format(day, 'MONTH_DAY_FORMAT'))}]
+            }
+        elif year_lookup and month_lookup:
+            days = getattr(cl.queryset, dates_or_datetimes)(field_name, 'day', **qs_kwargs)
+            return {
+                'show': True,
+                'back': {
+                    'link': link({year_field: year_lookup}),
+                    'title': str(year_lookup)
+                },
+                'choices': [{
+                    'link': link({year_field: year_lookup, month_field: month_lookup, day_field: day.day}),
+                    'title': capfirst(formats.date_format(day, 'MONTH_DAY_FORMAT'))
+                } for day in days]
+            }
+        elif year_lookup:
+            months = getattr(cl.queryset, dates_or_datetimes)(field_name, 'month', **qs_kwargs)
+            return {
+                'show': True,
+                'back': {
+                    'link': link({}),
+                    'title': _('All dates')
+                },
+                'choices': [{
+                    'link': link({year_field: year_lookup, month_field: month.month}),
+                    'title': capfirst(formats.date_format(month, 'YEAR_MONTH_FORMAT'))
+                } for month in months]
+            }
+        else:
+            years = getattr(cl.queryset, dates_or_datetimes)(field_name, 'year', **qs_kwargs)
+            return {
+                'show': True,
+                'back': None,
+                'choices': [{
+                    'link': link({year_field: str(year.year)}),
+                    'title': str(year.year),
+                } for year in years]
+            }
+
+
+@register.tag(name='date_hierarchy')
+def date_hierarchy_tag(parser, token):
+    return InclusionAdminNode(
+        parser, token,
+        func=date_hierarchy,
+        template_name='date_hierarchy.html',
+        takes_context=False,
+    )
+
+
+def search_form(cl):
+    """
+    Display a search form for searching the list.
+    """
+    return {
+        'cl': cl,
+        'show_result_count': cl.result_count != cl.full_result_count,
+        'search_var': SEARCH_VAR
+    }
+
+
+@register.tag(name='search_form')
+def search_form_tag(parser, token):
+    return InclusionAdminNode(parser, token, func=search_form, template_name='search_form.html', takes_context=False)
+
+
+@register.simple_tag
+def admin_list_filter(cl, spec):
+    tpl = get_template(spec.template)
+    return tpl.render({
+        'title': spec.title,
+        'choices': list(spec.choices(cl)),
+        'spec': spec,
+    })
+
+
+def admin_actions(context):
+    """
+    Track the number of times the action field has been rendered on the page,
+    so we know which value to use.
+    """
+    context['action_index'] = context.get('action_index', -1) + 1
+    return context
+
+
+@register.tag(name='admin_actions')
+def admin_actions_tag(parser, token):
+    return InclusionAdminNode(parser, token, func=admin_actions, template_name='actions.html')
+
+
+@register.tag(name='change_list_object_tools')
+def change_list_object_tools_tag(parser, token):
+    """Display the row of change list object tools."""
+    return InclusionAdminNode(
+        parser, token,
+        func=lambda context: context,
+        template_name='change_list_object_tools.html',
+    )
Index: venv/Lib/site-packages/django/contrib/admin/templatetags/admin_modify.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/admin/templatetags/admin_modify.py b/venv/Lib/site-packages/django/contrib/admin/templatetags/admin_modify.py
new file mode 100644
--- /dev/null	(date 1617030482873)
+++ b/venv/Lib/site-packages/django/contrib/admin/templatetags/admin_modify.py	(date 1617030482873)
@@ -0,0 +1,116 @@
+import json
+
+from django import template
+from django.template.context import Context
+
+from .base import InclusionAdminNode
+
+register = template.Library()
+
+
+def prepopulated_fields_js(context):
+    """
+    Create a list of prepopulated_fields that should render Javascript for
+    the prepopulated fields for both the admin form and inlines.
+    """
+    prepopulated_fields = []
+    if 'adminform' in context:
+        prepopulated_fields.extend(context['adminform'].prepopulated_fields)
+    if 'inline_admin_formsets' in context:
+        for inline_admin_formset in context['inline_admin_formsets']:
+            for inline_admin_form in inline_admin_formset:
+                if inline_admin_form.original is None:
+                    prepopulated_fields.extend(inline_admin_form.prepopulated_fields)
+
+    prepopulated_fields_json = []
+    for field in prepopulated_fields:
+        prepopulated_fields_json.append({
+            "id": "#%s" % field["field"].auto_id,
+            "name": field["field"].name,
+            "dependency_ids": ["#%s" % dependency.auto_id for dependency in field["dependencies"]],
+            "dependency_list": [dependency.name for dependency in field["dependencies"]],
+            "maxLength": field["field"].field.max_length or 50,
+            "allowUnicode": getattr(field["field"].field, "allow_unicode", False)
+        })
+
+    context.update({
+        'prepopulated_fields': prepopulated_fields,
+        'prepopulated_fields_json': json.dumps(prepopulated_fields_json),
+    })
+    return context
+
+
+@register.tag(name='prepopulated_fields_js')
+def prepopulated_fields_js_tag(parser, token):
+    return InclusionAdminNode(parser, token, func=prepopulated_fields_js, template_name="prepopulated_fields_js.html")
+
+
+def submit_row(context):
+    """
+    Display the row of buttons for delete and save.
+    """
+    add = context['add']
+    change = context['change']
+    is_popup = context['is_popup']
+    save_as = context['save_as']
+    show_save = context.get('show_save', True)
+    show_save_and_add_another = context.get('show_save_and_add_another', True)
+    show_save_and_continue = context.get('show_save_and_continue', True)
+    has_add_permission = context['has_add_permission']
+    has_change_permission = context['has_change_permission']
+    has_view_permission = context['has_view_permission']
+    has_editable_inline_admin_formsets = context['has_editable_inline_admin_formsets']
+    can_save = (has_change_permission and change) or (has_add_permission and add) or has_editable_inline_admin_formsets
+    can_save_and_add_another = (
+        has_add_permission and
+        not is_popup and
+        (not save_as or add) and
+        can_save and
+        show_save_and_add_another
+    )
+    can_save_and_continue = not is_popup and can_save and has_view_permission and show_save_and_continue
+    can_change = has_change_permission or has_editable_inline_admin_formsets
+    ctx = Context(context)
+    ctx.update({
+        'can_change': can_change,
+        'show_delete_link': (
+            not is_popup and context['has_delete_permission'] and
+            change and context.get('show_delete', True)
+        ),
+        'show_save_as_new': not is_popup and has_change_permission and change and save_as,
+        'show_save_and_add_another': can_save_and_add_another,
+        'show_save_and_continue': can_save_and_continue,
+        'show_save': show_save and can_save,
+        'show_close': not(show_save and can_save)
+    })
+    return ctx
+
+
+@register.tag(name='submit_row')
+def submit_row_tag(parser, token):
+    return InclusionAdminNode(parser, token, func=submit_row, template_name='submit_line.html')
+
+
+@register.tag(name='change_form_object_tools')
+def change_form_object_tools_tag(parser, token):
+    """Display the row of change form object tools."""
+    return InclusionAdminNode(
+        parser, token,
+        func=lambda context: context,
+        template_name='change_form_object_tools.html',
+    )
+
+
+@register.filter
+def cell_count(inline_admin_form):
+    """Return the number of cells used in a tabular inline."""
+    count = 1  # Hidden cell with hidden 'id' field
+    for fieldset in inline_admin_form:
+        # Loop through all the fields (one per cell)
+        for line in fieldset:
+            for field in line:
+                count += 1
+    if inline_admin_form.formset.can_delete:
+        # Delete checkbox
+        count += 1
+    return count
Index: venv/Lib/site-packages/django/contrib/admin/templatetags/admin_urls.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/admin/templatetags/admin_urls.py b/venv/Lib/site-packages/django/contrib/admin/templatetags/admin_urls.py
new file mode 100644
--- /dev/null	(date 1617030482875)
+++ b/venv/Lib/site-packages/django/contrib/admin/templatetags/admin_urls.py	(date 1617030482875)
@@ -0,0 +1,56 @@
+from urllib.parse import parse_qsl, unquote, urlparse, urlunparse
+
+from django import template
+from django.contrib.admin.utils import quote
+from django.urls import Resolver404, get_script_prefix, resolve
+from django.utils.http import urlencode
+
+register = template.Library()
+
+
+@register.filter
+def admin_urlname(value, arg):
+    return 'admin:%s_%s_%s' % (value.app_label, value.model_name, arg)
+
+
+@register.filter
+def admin_urlquote(value):
+    return quote(value)
+
+
+@register.simple_tag(takes_context=True)
+def add_preserved_filters(context, url, popup=False, to_field=None):
+    opts = context.get('opts')
+    preserved_filters = context.get('preserved_filters')
+
+    parsed_url = list(urlparse(url))
+    parsed_qs = dict(parse_qsl(parsed_url[4]))
+    merged_qs = {}
+
+    if opts and preserved_filters:
+        preserved_filters = dict(parse_qsl(preserved_filters))
+
+        match_url = '/%s' % unquote(url).partition(get_script_prefix())[2]
+        try:
+            match = resolve(match_url)
+        except Resolver404:
+            pass
+        else:
+            current_url = '%s:%s' % (match.app_name, match.url_name)
+            changelist_url = 'admin:%s_%s_changelist' % (opts.app_label, opts.model_name)
+            if changelist_url == current_url and '_changelist_filters' in preserved_filters:
+                preserved_filters = dict(parse_qsl(preserved_filters['_changelist_filters']))
+
+        merged_qs.update(preserved_filters)
+
+    if popup:
+        from django.contrib.admin.options import IS_POPUP_VAR
+        merged_qs[IS_POPUP_VAR] = 1
+    if to_field:
+        from django.contrib.admin.options import TO_FIELD_VAR
+        merged_qs[TO_FIELD_VAR] = to_field
+
+    merged_qs.update(parsed_qs)
+
+    parsed_url[4] = urlencode(merged_qs)
+    return urlunparse(parsed_url)
Index: venv/Lib/site-packages/django/contrib/admin/templatetags/base.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/admin/templatetags/base.py b/venv/Lib/site-packages/django/contrib/admin/templatetags/base.py
new file mode 100644
--- /dev/null	(date 1617030482875)
+++ b/venv/Lib/site-packages/django/contrib/admin/templatetags/base.py	(date 1617030482875)
@@ -0,0 +1,33 @@
+from inspect import getfullargspec
+
+from django.template.library import InclusionNode, parse_bits
+
+
+class InclusionAdminNode(InclusionNode):
+    """
+    Template tag that allows its template to be overridden per model, per app,
+    or globally.
+    """
+
+    def __init__(self, parser, token, func, template_name, takes_context=True):
+        self.template_name = template_name
+        params, varargs, varkw, defaults, kwonly, kwonly_defaults, _ = getfullargspec(func)
+        bits = token.split_contents()
+        args, kwargs = parse_bits(
+            parser, bits[1:], params, varargs, varkw, defaults, kwonly,
+            kwonly_defaults, takes_context, bits[0],
+        )
+        super().__init__(func, takes_context, args, kwargs, filename=None)
+
+    def render(self, context):
+        opts = context['opts']
+        app_label = opts.app_label.lower()
+        object_name = opts.object_name.lower()
+        # Load template for this render call. (Setting self.filename isn't
+        # thread-safe.)
+        context.render_context[self] = context.template.engine.select_template([
+            'admin/%s/%s/%s' % (app_label, object_name, self.template_name),
+            'admin/%s/%s' % (app_label, self.template_name),
+            'admin/%s' % self.template_name,
+        ])
+        return super().render(context)
Index: venv/Lib/site-packages/django/contrib/admin/templatetags/log.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/admin/templatetags/log.py b/venv/Lib/site-packages/django/contrib/admin/templatetags/log.py
new file mode 100644
--- /dev/null	(date 1617030482875)
+++ b/venv/Lib/site-packages/django/contrib/admin/templatetags/log.py	(date 1617030482875)
@@ -0,0 +1,59 @@
+from django import template
+from django.contrib.admin.models import LogEntry
+
+register = template.Library()
+
+
+class AdminLogNode(template.Node):
+    def __init__(self, limit, varname, user):
+        self.limit, self.varname, self.user = limit, varname, user
+
+    def __repr__(self):
+        return "<GetAdminLog Node>"
+
+    def render(self, context):
+        if self.user is None:
+            entries = LogEntry.objects.all()
+        else:
+            user_id = self.user
+            if not user_id.isdigit():
+                user_id = context[self.user].pk
+            entries = LogEntry.objects.filter(user__pk=user_id)
+        context[self.varname] = entries.select_related('content_type', 'user')[:int(self.limit)]
+        return ''
+
+
+@register.tag
+def get_admin_log(parser, token):
+    """
+    Populate a template variable with the admin log for the given criteria.
+
+    Usage::
+
+        {% get_admin_log [limit] as [varname] for_user [context_var_containing_user_obj] %}
+
+    Examples::
+
+        {% get_admin_log 10 as admin_log for_user 23 %}
+        {% get_admin_log 10 as admin_log for_user user %}
+        {% get_admin_log 10 as admin_log %}
+
+    Note that ``context_var_containing_user_obj`` can be a hard-coded integer
+    (user ID) or the name of a template context variable containing the user
+    object whose ID you want.
+    """
+    tokens = token.contents.split()
+    if len(tokens) < 4:
+        raise template.TemplateSyntaxError(
+            "'get_admin_log' statements require two arguments")
+    if not tokens[1].isdigit():
+        raise template.TemplateSyntaxError(
+            "First argument to 'get_admin_log' must be an integer")
+    if tokens[2] != 'as':
+        raise template.TemplateSyntaxError(
+            "Second argument to 'get_admin_log' must be 'as'")
+    if len(tokens) > 4:
+        if tokens[4] != 'for_user':
+            raise template.TemplateSyntaxError(
+                "Fourth argument to 'get_admin_log' must be 'for_user'")
+    return AdminLogNode(limit=tokens[1], varname=tokens[3], user=(tokens[5] if len(tokens) > 5 else None))
Index: venv/Lib/site-packages/django/core/checks/security/base.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/core/checks/security/base.py b/venv/Lib/site-packages/django/core/checks/security/base.py
new file mode 100644
--- /dev/null	(date 1617030485639)
+++ b/venv/Lib/site-packages/django/core/checks/security/base.py	(date 1617030485639)
@@ -0,0 +1,238 @@
+from django.conf import settings
+
+from .. import Error, Tags, Warning, register
+
+REFERRER_POLICY_VALUES = {
+    'no-referrer', 'no-referrer-when-downgrade', 'origin',
+    'origin-when-cross-origin', 'same-origin', 'strict-origin',
+    'strict-origin-when-cross-origin', 'unsafe-url',
+}
+
+SECRET_KEY_MIN_LENGTH = 50
+SECRET_KEY_MIN_UNIQUE_CHARACTERS = 5
+
+W001 = Warning(
+    "You do not have 'django.middleware.security.SecurityMiddleware' "
+    "in your MIDDLEWARE so the SECURE_HSTS_SECONDS, "
+    "SECURE_CONTENT_TYPE_NOSNIFF, SECURE_BROWSER_XSS_FILTER, "
+    "SECURE_REFERRER_POLICY, and SECURE_SSL_REDIRECT settings will have no "
+    "effect.",
+    id='security.W001',
+)
+
+W002 = Warning(
+    "You do not have "
+    "'django.middleware.clickjacking.XFrameOptionsMiddleware' in your "
+    "MIDDLEWARE, so your pages will not be served with an "
+    "'x-frame-options' header. Unless there is a good reason for your "
+    "site to be served in a frame, you should consider enabling this "
+    "header to help prevent clickjacking attacks.",
+    id='security.W002',
+)
+
+W004 = Warning(
+    "You have not set a value for the SECURE_HSTS_SECONDS setting. "
+    "If your entire site is served only over SSL, you may want to consider "
+    "setting a value and enabling HTTP Strict Transport Security. "
+    "Be sure to read the documentation first; enabling HSTS carelessly "
+    "can cause serious, irreversible problems.",
+    id='security.W004',
+)
+
+W005 = Warning(
+    "You have not set the SECURE_HSTS_INCLUDE_SUBDOMAINS setting to True. "
+    "Without this, your site is potentially vulnerable to attack "
+    "via an insecure connection to a subdomain. Only set this to True if "
+    "you are certain that all subdomains of your domain should be served "
+    "exclusively via SSL.",
+    id='security.W005',
+)
+
+W006 = Warning(
+    "Your SECURE_CONTENT_TYPE_NOSNIFF setting is not set to True, "
+    "so your pages will not be served with an "
+    "'X-Content-Type-Options: nosniff' header. "
+    "You should consider enabling this header to prevent the "
+    "browser from identifying content types incorrectly.",
+    id='security.W006',
+)
+
+W008 = Warning(
+    "Your SECURE_SSL_REDIRECT setting is not set to True. "
+    "Unless your site should be available over both SSL and non-SSL "
+    "connections, you may want to either set this setting True "
+    "or configure a load balancer or reverse-proxy server "
+    "to redirect all connections to HTTPS.",
+    id='security.W008',
+)
+
+W009 = Warning(
+    "Your SECRET_KEY has less than %(min_length)s characters or less than "
+    "%(min_unique_chars)s unique characters. Please generate a long and random "
+    "SECRET_KEY, otherwise many of Django's security-critical features will be "
+    "vulnerable to attack." % {
+        'min_length': SECRET_KEY_MIN_LENGTH,
+        'min_unique_chars': SECRET_KEY_MIN_UNIQUE_CHARACTERS,
+    },
+    id='security.W009',
+)
+
+W018 = Warning(
+    "You should not have DEBUG set to True in deployment.",
+    id='security.W018',
+)
+
+W019 = Warning(
+    "You have "
+    "'django.middleware.clickjacking.XFrameOptionsMiddleware' in your "
+    "MIDDLEWARE, but X_FRAME_OPTIONS is not set to 'DENY'. "
+    "Unless there is a good reason for your site to serve other parts of "
+    "itself in a frame, you should change it to 'DENY'.",
+    id='security.W019',
+)
+
+W020 = Warning(
+    "ALLOWED_HOSTS must not be empty in deployment.",
+    id='security.W020',
+)
+
+W021 = Warning(
+    "You have not set the SECURE_HSTS_PRELOAD setting to True. Without this, "
+    "your site cannot be submitted to the browser preload list.",
+    id='security.W021',
+)
+
+W022 = Warning(
+    'You have not set the SECURE_REFERRER_POLICY setting. Without this, your '
+    'site will not send a Referrer-Policy header. You should consider '
+    'enabling this header to protect user privacy.',
+    id='security.W022',
+)
+
+E023 = Error(
+    'You have set the SECURE_REFERRER_POLICY setting to an invalid value.',
+    hint='Valid values are: {}.'.format(', '.join(sorted(REFERRER_POLICY_VALUES))),
+    id='security.E023',
+)
+
+E100 = Error(
+    "DEFAULT_HASHING_ALGORITHM must be 'sha1' or 'sha256'.",
+    id='security.E100',
+)
+
+
+def _security_middleware():
+    return 'django.middleware.security.SecurityMiddleware' in settings.MIDDLEWARE
+
+
+def _xframe_middleware():
+    return 'django.middleware.clickjacking.XFrameOptionsMiddleware' in settings.MIDDLEWARE
+
+
+@register(Tags.security, deploy=True)
+def check_security_middleware(app_configs, **kwargs):
+    passed_check = _security_middleware()
+    return [] if passed_check else [W001]
+
+
+@register(Tags.security, deploy=True)
+def check_xframe_options_middleware(app_configs, **kwargs):
+    passed_check = _xframe_middleware()
+    return [] if passed_check else [W002]
+
+
+@register(Tags.security, deploy=True)
+def check_sts(app_configs, **kwargs):
+    passed_check = not _security_middleware() or settings.SECURE_HSTS_SECONDS
+    return [] if passed_check else [W004]
+
+
+@register(Tags.security, deploy=True)
+def check_sts_include_subdomains(app_configs, **kwargs):
+    passed_check = (
+        not _security_middleware() or
+        not settings.SECURE_HSTS_SECONDS or
+        settings.SECURE_HSTS_INCLUDE_SUBDOMAINS is True
+    )
+    return [] if passed_check else [W005]
+
+
+@register(Tags.security, deploy=True)
+def check_sts_preload(app_configs, **kwargs):
+    passed_check = (
+        not _security_middleware() or
+        not settings.SECURE_HSTS_SECONDS or
+        settings.SECURE_HSTS_PRELOAD is True
+    )
+    return [] if passed_check else [W021]
+
+
+@register(Tags.security, deploy=True)
+def check_content_type_nosniff(app_configs, **kwargs):
+    passed_check = (
+        not _security_middleware() or
+        settings.SECURE_CONTENT_TYPE_NOSNIFF is True
+    )
+    return [] if passed_check else [W006]
+
+
+@register(Tags.security, deploy=True)
+def check_ssl_redirect(app_configs, **kwargs):
+    passed_check = (
+        not _security_middleware() or
+        settings.SECURE_SSL_REDIRECT is True
+    )
+    return [] if passed_check else [W008]
+
+
+@register(Tags.security, deploy=True)
+def check_secret_key(app_configs, **kwargs):
+    passed_check = (
+        getattr(settings, 'SECRET_KEY', None) and
+        len(set(settings.SECRET_KEY)) >= SECRET_KEY_MIN_UNIQUE_CHARACTERS and
+        len(settings.SECRET_KEY) >= SECRET_KEY_MIN_LENGTH
+    )
+    return [] if passed_check else [W009]
+
+
+@register(Tags.security, deploy=True)
+def check_debug(app_configs, **kwargs):
+    passed_check = not settings.DEBUG
+    return [] if passed_check else [W018]
+
+
+@register(Tags.security, deploy=True)
+def check_xframe_deny(app_configs, **kwargs):
+    passed_check = (
+        not _xframe_middleware() or
+        settings.X_FRAME_OPTIONS == 'DENY'
+    )
+    return [] if passed_check else [W019]
+
+
+@register(Tags.security, deploy=True)
+def check_allowed_hosts(app_configs, **kwargs):
+    return [] if settings.ALLOWED_HOSTS else [W020]
+
+
+@register(Tags.security, deploy=True)
+def check_referrer_policy(app_configs, **kwargs):
+    if _security_middleware():
+        if settings.SECURE_REFERRER_POLICY is None:
+            return [W022]
+        # Support a comma-separated string or iterable of values to allow fallback.
+        if isinstance(settings.SECURE_REFERRER_POLICY, str):
+            values = {v.strip() for v in settings.SECURE_REFERRER_POLICY.split(',')}
+        else:
+            values = set(settings.SECURE_REFERRER_POLICY)
+        if not values <= REFERRER_POLICY_VALUES:
+            return [E023]
+    return []
+
+
+# RemovedInDjango40Warning
+@register(Tags.security)
+def check_default_hashing_algorithm(app_configs, **kwargs):
+    if settings.DEFAULT_HASHING_ALGORITHM not in {'sha1', 'sha256'}:
+        return [E100]
+    return []
Index: venv/Lib/site-packages/django/core/checks/security/csrf.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/core/checks/security/csrf.py b/venv/Lib/site-packages/django/core/checks/security/csrf.py
new file mode 100644
--- /dev/null	(date 1617030485640)
+++ b/venv/Lib/site-packages/django/core/checks/security/csrf.py	(date 1617030485640)
@@ -0,0 +1,40 @@
+from django.conf import settings
+
+from .. import Tags, Warning, register
+
+W003 = Warning(
+    "You don't appear to be using Django's built-in "
+    "cross-site request forgery protection via the middleware "
+    "('django.middleware.csrf.CsrfViewMiddleware' is not in your "
+    "MIDDLEWARE). Enabling the middleware is the safest approach "
+    "to ensure you don't leave any holes.",
+    id='security.W003',
+)
+
+W016 = Warning(
+    "You have 'django.middleware.csrf.CsrfViewMiddleware' in your "
+    "MIDDLEWARE, but you have not set CSRF_COOKIE_SECURE to True. "
+    "Using a secure-only CSRF cookie makes it more difficult for network "
+    "traffic sniffers to steal the CSRF token.",
+    id='security.W016',
+)
+
+
+def _csrf_middleware():
+    return 'django.middleware.csrf.CsrfViewMiddleware' in settings.MIDDLEWARE
+
+
+@register(Tags.security, deploy=True)
+def check_csrf_middleware(app_configs, **kwargs):
+    passed_check = _csrf_middleware()
+    return [] if passed_check else [W003]
+
+
+@register(Tags.security, deploy=True)
+def check_csrf_cookie_secure(app_configs, **kwargs):
+    passed_check = (
+        settings.CSRF_USE_SESSIONS or
+        not _csrf_middleware() or
+        settings.CSRF_COOKIE_SECURE
+    )
+    return [] if passed_check else [W016]
Index: venv/Lib/site-packages/django/core/checks/security/sessions.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/core/checks/security/sessions.py b/venv/Lib/site-packages/django/core/checks/security/sessions.py
new file mode 100644
--- /dev/null	(date 1617030485640)
+++ b/venv/Lib/site-packages/django/core/checks/security/sessions.py	(date 1617030485640)
@@ -0,0 +1,97 @@
+from django.conf import settings
+
+from .. import Tags, Warning, register
+
+
+def add_session_cookie_message(message):
+    return message + (
+        " Using a secure-only session cookie makes it more difficult for "
+        "network traffic sniffers to hijack user sessions."
+    )
+
+
+W010 = Warning(
+    add_session_cookie_message(
+        "You have 'django.contrib.sessions' in your INSTALLED_APPS, "
+        "but you have not set SESSION_COOKIE_SECURE to True."
+    ),
+    id='security.W010',
+)
+
+W011 = Warning(
+    add_session_cookie_message(
+        "You have 'django.contrib.sessions.middleware.SessionMiddleware' "
+        "in your MIDDLEWARE, but you have not set "
+        "SESSION_COOKIE_SECURE to True."
+    ),
+    id='security.W011',
+)
+
+W012 = Warning(
+    add_session_cookie_message("SESSION_COOKIE_SECURE is not set to True."),
+    id='security.W012',
+)
+
+
+def add_httponly_message(message):
+    return message + (
+        " Using an HttpOnly session cookie makes it more difficult for "
+        "cross-site scripting attacks to hijack user sessions."
+    )
+
+
+W013 = Warning(
+    add_httponly_message(
+        "You have 'django.contrib.sessions' in your INSTALLED_APPS, "
+        "but you have not set SESSION_COOKIE_HTTPONLY to True.",
+    ),
+    id='security.W013',
+)
+
+W014 = Warning(
+    add_httponly_message(
+        "You have 'django.contrib.sessions.middleware.SessionMiddleware' "
+        "in your MIDDLEWARE, but you have not set "
+        "SESSION_COOKIE_HTTPONLY to True."
+    ),
+    id='security.W014',
+)
+
+W015 = Warning(
+    add_httponly_message("SESSION_COOKIE_HTTPONLY is not set to True."),
+    id='security.W015',
+)
+
+
+@register(Tags.security, deploy=True)
+def check_session_cookie_secure(app_configs, **kwargs):
+    errors = []
+    if not settings.SESSION_COOKIE_SECURE:
+        if _session_app():
+            errors.append(W010)
+        if _session_middleware():
+            errors.append(W011)
+        if len(errors) > 1:
+            errors = [W012]
+    return errors
+
+
+@register(Tags.security, deploy=True)
+def check_session_cookie_httponly(app_configs, **kwargs):
+    errors = []
+    if not settings.SESSION_COOKIE_HTTPONLY:
+        if _session_app():
+            errors.append(W013)
+        if _session_middleware():
+            errors.append(W014)
+        if len(errors) > 1:
+            errors = [W015]
+    return errors
+
+
+def _session_middleware():
+    return 'django.contrib.sessions.middleware.SessionMiddleware' in settings.MIDDLEWARE
+
+
+def _session_app():
+    return "django.contrib.sessions" in settings.INSTALLED_APPS
Index: venv/Lib/site-packages/django/core/management/commands/check.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/core/management/commands/check.py b/venv/Lib/site-packages/django/core/management/commands/check.py
new file mode 100644
--- /dev/null	(date 1617030485655)
+++ b/venv/Lib/site-packages/django/core/management/commands/check.py	(date 1617030485655)
@@ -0,0 +1,70 @@
+from django.apps import apps
+from django.core import checks
+from django.core.checks.registry import registry
+from django.core.management.base import BaseCommand, CommandError
+
+
+class Command(BaseCommand):
+    help = "Checks the entire Django project for potential problems."
+
+    requires_system_checks = False
+
+    def add_arguments(self, parser):
+        parser.add_argument('args', metavar='app_label', nargs='*')
+        parser.add_argument(
+            '--tag', '-t', action='append', dest='tags',
+            help='Run only checks labeled with given tag.',
+        )
+        parser.add_argument(
+            '--list-tags', action='store_true',
+            help='List available tags.',
+        )
+        parser.add_argument(
+            '--deploy', action='store_true',
+            help='Check deployment settings.',
+        )
+        parser.add_argument(
+            '--fail-level',
+            default='ERROR',
+            choices=['CRITICAL', 'ERROR', 'WARNING', 'INFO', 'DEBUG'],
+            help=(
+                'Message level that will cause the command to exit with a '
+                'non-zero status. Default is ERROR.'
+            ),
+        )
+        parser.add_argument(
+            '--database', action='append', dest='databases',
+            help='Run database related checks against these aliases.',
+        )
+
+    def handle(self, *app_labels, **options):
+        include_deployment_checks = options['deploy']
+        if options['list_tags']:
+            self.stdout.write('\n'.join(sorted(registry.tags_available(include_deployment_checks))))
+            return
+
+        if app_labels:
+            app_configs = [apps.get_app_config(app_label) for app_label in app_labels]
+        else:
+            app_configs = None
+
+        tags = options['tags']
+        if tags:
+            try:
+                invalid_tag = next(
+                    tag for tag in tags if not checks.tag_exists(tag, include_deployment_checks)
+                )
+            except StopIteration:
+                # no invalid tags
+                pass
+            else:
+                raise CommandError('There is no system check with the "%s" tag.' % invalid_tag)
+
+        self.check(
+            app_configs=app_configs,
+            tags=tags,
+            display_num_errors=True,
+            include_deployment_checks=include_deployment_checks,
+            fail_level=getattr(checks, options['fail_level']),
+            databases=options['databases'],
+        )
Index: venv/Lib/site-packages/django/core/management/commands/compilemessages.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/core/management/commands/compilemessages.py b/venv/Lib/site-packages/django/core/management/commands/compilemessages.py
new file mode 100644
--- /dev/null	(date 1617030485655)
+++ b/venv/Lib/site-packages/django/core/management/commands/compilemessages.py	(date 1617030485655)
@@ -0,0 +1,158 @@
+import codecs
+import concurrent.futures
+import glob
+import os
+
+from django.core.management.base import BaseCommand, CommandError
+from django.core.management.utils import (
+    find_command, is_ignored_path, popen_wrapper,
+)
+
+
+def has_bom(fn):
+    with open(fn, 'rb') as f:
+        sample = f.read(4)
+    return sample.startswith((codecs.BOM_UTF8, codecs.BOM_UTF16_LE, codecs.BOM_UTF16_BE))
+
+
+def is_writable(path):
+    # Known side effect: updating file access/modified time to current time if
+    # it is writable.
+    try:
+        with open(path, 'a'):
+            os.utime(path, None)
+    except OSError:
+        return False
+    return True
+
+
+class Command(BaseCommand):
+    help = 'Compiles .po files to .mo files for use with builtin gettext support.'
+
+    requires_system_checks = False
+
+    program = 'msgfmt'
+    program_options = ['--check-format']
+
+    def add_arguments(self, parser):
+        parser.add_argument(
+            '--locale', '-l', action='append', default=[],
+            help='Locale(s) to process (e.g. de_AT). Default is to process all. '
+                 'Can be used multiple times.',
+        )
+        parser.add_argument(
+            '--exclude', '-x', action='append', default=[],
+            help='Locales to exclude. Default is none. Can be used multiple times.',
+        )
+        parser.add_argument(
+            '--use-fuzzy', '-f', dest='fuzzy', action='store_true',
+            help='Use fuzzy translations.',
+        )
+        parser.add_argument(
+            '--ignore', '-i', action='append', dest='ignore_patterns',
+            default=[], metavar='PATTERN',
+            help='Ignore directories matching this glob-style pattern. '
+                 'Use multiple times to ignore more.',
+        )
+
+    def handle(self, **options):
+        locale = options['locale']
+        exclude = options['exclude']
+        ignore_patterns = set(options['ignore_patterns'])
+        self.verbosity = options['verbosity']
+        if options['fuzzy']:
+            self.program_options = self.program_options + ['-f']
+
+        if find_command(self.program) is None:
+            raise CommandError("Can't find %s. Make sure you have GNU gettext "
+                               "tools 0.15 or newer installed." % self.program)
+
+        basedirs = [os.path.join('conf', 'locale'), 'locale']
+        if os.environ.get('DJANGO_SETTINGS_MODULE'):
+            from django.conf import settings
+            basedirs.extend(settings.LOCALE_PATHS)
+
+        # Walk entire tree, looking for locale directories
+        for dirpath, dirnames, filenames in os.walk('.', topdown=True):
+            for dirname in dirnames:
+                if is_ignored_path(os.path.normpath(os.path.join(dirpath, dirname)), ignore_patterns):
+                    dirnames.remove(dirname)
+                elif dirname == 'locale':
+                    basedirs.append(os.path.join(dirpath, dirname))
+
+        # Gather existing directories.
+        basedirs = set(map(os.path.abspath, filter(os.path.isdir, basedirs)))
+
+        if not basedirs:
+            raise CommandError("This script should be run from the Django Git "
+                               "checkout or your project or app tree, or with "
+                               "the settings module specified.")
+
+        # Build locale list
+        all_locales = []
+        for basedir in basedirs:
+            locale_dirs = filter(os.path.isdir, glob.glob('%s/*' % basedir))
+            all_locales.extend(map(os.path.basename, locale_dirs))
+
+        # Account for excluded locales
+        locales = locale or all_locales
+        locales = set(locales).difference(exclude)
+
+        self.has_errors = False
+        for basedir in basedirs:
+            if locales:
+                dirs = [os.path.join(basedir, locale, 'LC_MESSAGES') for locale in locales]
+            else:
+                dirs = [basedir]
+            locations = []
+            for ldir in dirs:
+                for dirpath, dirnames, filenames in os.walk(ldir):
+                    locations.extend((dirpath, f) for f in filenames if f.endswith('.po'))
+            if locations:
+                self.compile_messages(locations)
+
+        if self.has_errors:
+            raise CommandError('compilemessages generated one or more errors.')
+
+    def compile_messages(self, locations):
+        """
+        Locations is a list of tuples: [(directory, file), ...]
+        """
+        with concurrent.futures.ThreadPoolExecutor() as executor:
+            futures = []
+            for i, (dirpath, f) in enumerate(locations):
+                if self.verbosity > 0:
+                    self.stdout.write('processing file %s in %s' % (f, dirpath))
+                po_path = os.path.join(dirpath, f)
+                if has_bom(po_path):
+                    self.stderr.write(
+                        'The %s file has a BOM (Byte Order Mark). Django only '
+                        'supports .po files encoded in UTF-8 and without any BOM.' % po_path
+                    )
+                    self.has_errors = True
+                    continue
+                base_path = os.path.splitext(po_path)[0]
+
+                # Check writability on first location
+                if i == 0 and not is_writable(base_path + '.mo'):
+                    self.stderr.write(
+                        'The po files under %s are in a seemingly not writable location. '
+                        'mo files will not be updated/created.' % dirpath
+                    )
+                    self.has_errors = True
+                    return
+
+                args = [self.program] + self.program_options + [
+                    '-o', base_path + '.mo', base_path + '.po'
+                ]
+                futures.append(executor.submit(popen_wrapper, args))
+
+            for future in concurrent.futures.as_completed(futures):
+                output, errors, status = future.result()
+                if status:
+                    if self.verbosity > 0:
+                        if errors:
+                            self.stderr.write("Execution of %s failed: %s" % (self.program, errors))
+                        else:
+                            self.stderr.write("Execution of %s failed" % self.program)
+                    self.has_errors = True
Index: venv/Lib/site-packages/django/core/management/commands/createcachetable.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/core/management/commands/createcachetable.py b/venv/Lib/site-packages/django/core/management/commands/createcachetable.py
new file mode 100644
--- /dev/null	(date 1617030485656)
+++ b/venv/Lib/site-packages/django/core/management/commands/createcachetable.py	(date 1617030485656)
@@ -0,0 +1,107 @@
+from django.conf import settings
+from django.core.cache import caches
+from django.core.cache.backends.db import BaseDatabaseCache
+from django.core.management.base import BaseCommand, CommandError
+from django.db import (
+    DEFAULT_DB_ALIAS, DatabaseError, connections, models, router, transaction,
+)
+
+
+class Command(BaseCommand):
+    help = "Creates the tables needed to use the SQL cache backend."
+
+    requires_system_checks = False
+
+    def add_arguments(self, parser):
+        parser.add_argument(
+            'args', metavar='table_name', nargs='*',
+            help='Optional table names. Otherwise, settings.CACHES is used to find cache tables.',
+        )
+        parser.add_argument(
+            '--database',
+            default=DEFAULT_DB_ALIAS,
+            help='Nominates a database onto which the cache tables will be '
+                 'installed. Defaults to the "default" database.',
+        )
+        parser.add_argument(
+            '--dry-run', action='store_true',
+            help='Does not create the table, just prints the SQL that would be run.',
+        )
+
+    def handle(self, *tablenames, **options):
+        db = options['database']
+        self.verbosity = options['verbosity']
+        dry_run = options['dry_run']
+        if tablenames:
+            # Legacy behavior, tablename specified as argument
+            for tablename in tablenames:
+                self.create_table(db, tablename, dry_run)
+        else:
+            for cache_alias in settings.CACHES:
+                cache = caches[cache_alias]
+                if isinstance(cache, BaseDatabaseCache):
+                    self.create_table(db, cache._table, dry_run)
+
+    def create_table(self, database, tablename, dry_run):
+        cache = BaseDatabaseCache(tablename, {})
+        if not router.allow_migrate_model(database, cache.cache_model_class):
+            return
+        connection = connections[database]
+
+        if tablename in connection.introspection.table_names():
+            if self.verbosity > 0:
+                self.stdout.write("Cache table '%s' already exists." % tablename)
+            return
+
+        fields = (
+            # "key" is a reserved word in MySQL, so use "cache_key" instead.
+            models.CharField(name='cache_key', max_length=255, unique=True, primary_key=True),
+            models.TextField(name='value'),
+            models.DateTimeField(name='expires', db_index=True),
+        )
+        table_output = []
+        index_output = []
+        qn = connection.ops.quote_name
+        for f in fields:
+            field_output = [
+                qn(f.name),
+                f.db_type(connection=connection),
+                '%sNULL' % ('NOT ' if not f.null else ''),
+            ]
+            if f.primary_key:
+                field_output.append("PRIMARY KEY")
+            elif f.unique:
+                field_output.append("UNIQUE")
+            if f.db_index:
+                unique = "UNIQUE " if f.unique else ""
+                index_output.append(
+                    "CREATE %sINDEX %s ON %s (%s);" %
+                    (unique, qn('%s_%s' % (tablename, f.name)), qn(tablename), qn(f.name))
+                )
+            table_output.append(" ".join(field_output))
+        full_statement = ["CREATE TABLE %s (" % qn(tablename)]
+        for i, line in enumerate(table_output):
+            full_statement.append('    %s%s' % (line, ',' if i < len(table_output) - 1 else ''))
+        full_statement.append(');')
+
+        full_statement = "\n".join(full_statement)
+
+        if dry_run:
+            self.stdout.write(full_statement)
+            for statement in index_output:
+                self.stdout.write(statement)
+            return
+
+        with transaction.atomic(using=database, savepoint=connection.features.can_rollback_ddl):
+            with connection.cursor() as curs:
+                try:
+                    curs.execute(full_statement)
+                except DatabaseError as e:
+                    raise CommandError(
+                        "Cache table '%s' could not be created.\nThe error was: %s." %
+                        (tablename, e))
+                for statement in index_output:
+                    curs.execute(statement)
+
+        if self.verbosity > 1:
+            self.stdout.write("Cache table '%s' created." % tablename)
Index: venv/Lib/site-packages/django/core/management/commands/dbshell.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/core/management/commands/dbshell.py b/venv/Lib/site-packages/django/core/management/commands/dbshell.py
new file mode 100644
--- /dev/null	(date 1617030485656)
+++ b/venv/Lib/site-packages/django/core/management/commands/dbshell.py	(date 1617030485656)
@@ -0,0 +1,43 @@
+import subprocess
+
+from django.core.management.base import BaseCommand, CommandError
+from django.db import DEFAULT_DB_ALIAS, connections
+
+
+class Command(BaseCommand):
+    help = (
+        "Runs the command-line client for specified database, or the "
+        "default database if none is provided."
+    )
+
+    requires_system_checks = False
+
+    def add_arguments(self, parser):
+        parser.add_argument(
+            '--database', default=DEFAULT_DB_ALIAS,
+            help='Nominates a database onto which to open a shell. Defaults to the "default" database.',
+        )
+        parameters = parser.add_argument_group('parameters', prefix_chars='--')
+        parameters.add_argument('parameters', nargs='*')
+
+    def handle(self, **options):
+        connection = connections[options['database']]
+        try:
+            connection.client.runshell(options['parameters'])
+        except FileNotFoundError:
+            # Note that we're assuming the FileNotFoundError relates to the
+            # command missing. It could be raised for some other reason, in
+            # which case this error message would be inaccurate. Still, this
+            # message catches the common case.
+            raise CommandError(
+                'You appear not to have the %r program installed or on your path.' %
+                connection.client.executable_name
+            )
+        except subprocess.CalledProcessError as e:
+            raise CommandError(
+                '"%s" returned non-zero exit status %s.' % (
+                    ' '.join(e.cmd),
+                    e.returncode,
+                ),
+                returncode=e.returncode,
+            )
Index: venv/Lib/site-packages/django/core/management/commands/diffsettings.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/core/management/commands/diffsettings.py b/venv/Lib/site-packages/django/core/management/commands/diffsettings.py
new file mode 100644
--- /dev/null	(date 1617030485656)
+++ b/venv/Lib/site-packages/django/core/management/commands/diffsettings.py	(date 1617030485656)
@@ -0,0 +1,79 @@
+from django.core.management.base import BaseCommand
+
+
+def module_to_dict(module, omittable=lambda k: k.startswith('_') or not k.isupper()):
+    """Convert a module namespace to a Python dictionary."""
+    return {k: repr(getattr(module, k)) for k in dir(module) if not omittable(k)}
+
+
+class Command(BaseCommand):
+    help = """Displays differences between the current settings.py and Django's
+    default settings."""
+
+    requires_system_checks = False
+
+    def add_arguments(self, parser):
+        parser.add_argument(
+            '--all', action='store_true',
+            help=(
+                'Display all settings, regardless of their value. In "hash" '
+                'mode, default values are prefixed by "###".'
+            ),
+        )
+        parser.add_argument(
+            '--default', metavar='MODULE',
+            help=(
+                "The settings module to compare the current settings against. Leave empty to "
+                "compare against Django's default settings."
+            ),
+        )
+        parser.add_argument(
+            '--output', default='hash', choices=('hash', 'unified'),
+            help=(
+                "Selects the output format. 'hash' mode displays each changed "
+                "setting, with the settings that don't appear in the defaults "
+                "followed by ###. 'unified' mode prefixes the default setting "
+                "with a minus sign, followed by the changed setting prefixed "
+                "with a plus sign."
+            ),
+        )
+
+    def handle(self, **options):
+        from django.conf import Settings, global_settings, settings
+
+        # Because settings are imported lazily, we need to explicitly load them.
+        if not settings.configured:
+            settings._setup()
+
+        user_settings = module_to_dict(settings._wrapped)
+        default = options['default']
+        default_settings = module_to_dict(Settings(default) if default else global_settings)
+        output_func = {
+            'hash': self.output_hash,
+            'unified': self.output_unified,
+        }[options['output']]
+        return '\n'.join(output_func(user_settings, default_settings, **options))
+
+    def output_hash(self, user_settings, default_settings, **options):
+        # Inspired by Postfix's "postconf -n".
+        output = []
+        for key in sorted(user_settings):
+            if key not in default_settings:
+                output.append("%s = %s  ###" % (key, user_settings[key]))
+            elif user_settings[key] != default_settings[key]:
+                output.append("%s = %s" % (key, user_settings[key]))
+            elif options['all']:
+                output.append("### %s = %s" % (key, user_settings[key]))
+        return output
+
+    def output_unified(self, user_settings, default_settings, **options):
+        output = []
+        for key in sorted(user_settings):
+            if key not in default_settings:
+                output.append(self.style.SUCCESS("+ %s = %s" % (key, user_settings[key])))
+            elif user_settings[key] != default_settings[key]:
+                output.append(self.style.ERROR("- %s = %s" % (key, default_settings[key])))
+                output.append(self.style.SUCCESS("+ %s = %s" % (key, user_settings[key])))
+            elif options['all']:
+                output.append("  %s = %s" % (key, user_settings[key]))
+        return output
Index: venv/Lib/site-packages/django/core/management/commands/dumpdata.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/core/management/commands/dumpdata.py b/venv/Lib/site-packages/django/core/management/commands/dumpdata.py
new file mode 100644
--- /dev/null	(date 1617030485657)
+++ b/venv/Lib/site-packages/django/core/management/commands/dumpdata.py	(date 1617030485657)
@@ -0,0 +1,203 @@
+import warnings
+
+from django.apps import apps
+from django.core import serializers
+from django.core.management.base import BaseCommand, CommandError
+from django.core.management.utils import parse_apps_and_model_labels
+from django.db import DEFAULT_DB_ALIAS, router
+
+
+class ProxyModelWarning(Warning):
+    pass
+
+
+class Command(BaseCommand):
+    help = (
+        "Output the contents of the database as a fixture of the given format "
+        "(using each model's default manager unless --all is specified)."
+    )
+
+    def add_arguments(self, parser):
+        parser.add_argument(
+            'args', metavar='app_label[.ModelName]', nargs='*',
+            help='Restricts dumped data to the specified app_label or app_label.ModelName.',
+        )
+        parser.add_argument(
+            '--format', default='json',
+            help='Specifies the output serialization format for fixtures.',
+        )
+        parser.add_argument(
+            '--indent', type=int,
+            help='Specifies the indent level to use when pretty-printing output.',
+        )
+        parser.add_argument(
+            '--database',
+            default=DEFAULT_DB_ALIAS,
+            help='Nominates a specific database to dump fixtures from. '
+                 'Defaults to the "default" database.',
+        )
+        parser.add_argument(
+            '-e', '--exclude', action='append', default=[],
+            help='An app_label or app_label.ModelName to exclude '
+                 '(use multiple --exclude to exclude multiple apps/models).',
+        )
+        parser.add_argument(
+            '--natural-foreign', action='store_true', dest='use_natural_foreign_keys',
+            help='Use natural foreign keys if they are available.',
+        )
+        parser.add_argument(
+            '--natural-primary', action='store_true', dest='use_natural_primary_keys',
+            help='Use natural primary keys if they are available.',
+        )
+        parser.add_argument(
+            '-a', '--all', action='store_true', dest='use_base_manager',
+            help="Use Django's base manager to dump all models stored in the database, "
+                 "including those that would otherwise be filtered or modified by a custom manager.",
+        )
+        parser.add_argument(
+            '--pks', dest='primary_keys',
+            help="Only dump objects with given primary keys. Accepts a comma-separated "
+                 "list of keys. This option only works when you specify one model.",
+        )
+        parser.add_argument(
+            '-o', '--output',
+            help='Specifies file to which the output is written.'
+        )
+
+    def handle(self, *app_labels, **options):
+        format = options['format']
+        indent = options['indent']
+        using = options['database']
+        excludes = options['exclude']
+        output = options['output']
+        show_traceback = options['traceback']
+        use_natural_foreign_keys = options['use_natural_foreign_keys']
+        use_natural_primary_keys = options['use_natural_primary_keys']
+        use_base_manager = options['use_base_manager']
+        pks = options['primary_keys']
+
+        if pks:
+            primary_keys = [pk.strip() for pk in pks.split(',')]
+        else:
+            primary_keys = []
+
+        excluded_models, excluded_apps = parse_apps_and_model_labels(excludes)
+
+        if not app_labels:
+            if primary_keys:
+                raise CommandError("You can only use --pks option with one model")
+            app_list = dict.fromkeys(
+                app_config for app_config in apps.get_app_configs()
+                if app_config.models_module is not None and app_config not in excluded_apps
+            )
+        else:
+            if len(app_labels) > 1 and primary_keys:
+                raise CommandError("You can only use --pks option with one model")
+            app_list = {}
+            for label in app_labels:
+                try:
+                    app_label, model_label = label.split('.')
+                    try:
+                        app_config = apps.get_app_config(app_label)
+                    except LookupError as e:
+                        raise CommandError(str(e))
+                    if app_config.models_module is None or app_config in excluded_apps:
+                        continue
+                    try:
+                        model = app_config.get_model(model_label)
+                    except LookupError:
+                        raise CommandError("Unknown model: %s.%s" % (app_label, model_label))
+
+                    app_list_value = app_list.setdefault(app_config, [])
+
+                    # We may have previously seen an "all-models" request for
+                    # this app (no model qualifier was given). In this case
+                    # there is no need adding specific models to the list.
+                    if app_list_value is not None:
+                        if model not in app_list_value:
+                            app_list_value.append(model)
+                except ValueError:
+                    if primary_keys:
+                        raise CommandError("You can only use --pks option with one model")
+                    # This is just an app - no model qualifier
+                    app_label = label
+                    try:
+                        app_config = apps.get_app_config(app_label)
+                    except LookupError as e:
+                        raise CommandError(str(e))
+                    if app_config.models_module is None or app_config in excluded_apps:
+                        continue
+                    app_list[app_config] = None
+
+        # Check that the serialization format exists; this is a shortcut to
+        # avoid collating all the objects and _then_ failing.
+        if format not in serializers.get_public_serializer_formats():
+            try:
+                serializers.get_serializer(format)
+            except serializers.SerializerDoesNotExist:
+                pass
+
+            raise CommandError("Unknown serialization format: %s" % format)
+
+        def get_objects(count_only=False):
+            """
+            Collate the objects to be serialized. If count_only is True, just
+            count the number of objects to be serialized.
+            """
+            if use_natural_foreign_keys:
+                models = serializers.sort_dependencies(app_list.items(), allow_cycles=True)
+            else:
+                # There is no need to sort dependencies when natural foreign
+                # keys are not used.
+                models = []
+                for (app_config, model_list) in app_list.items():
+                    if model_list is None:
+                        models.extend(app_config.get_models())
+                    else:
+                        models.extend(model_list)
+            for model in models:
+                if model in excluded_models:
+                    continue
+                if model._meta.proxy and model._meta.proxy_for_model not in models:
+                    warnings.warn(
+                        "%s is a proxy model and won't be serialized." % model._meta.label,
+                        category=ProxyModelWarning,
+                    )
+                if not model._meta.proxy and router.allow_migrate_model(using, model):
+                    if use_base_manager:
+                        objects = model._base_manager
+                    else:
+                        objects = model._default_manager
+
+                    queryset = objects.using(using).order_by(model._meta.pk.name)
+                    if primary_keys:
+                        queryset = queryset.filter(pk__in=primary_keys)
+                    if count_only:
+                        yield queryset.order_by().count()
+                    else:
+                        yield from queryset.iterator()
+
+        try:
+            self.stdout.ending = None
+            progress_output = None
+            object_count = 0
+            # If dumpdata is outputting to stdout, there is no way to display progress
+            if output and self.stdout.isatty() and options['verbosity'] > 0:
+                progress_output = self.stdout
+                object_count = sum(get_objects(count_only=True))
+            stream = open(output, 'w') if output else None
+            try:
+                serializers.serialize(
+                    format, get_objects(), indent=indent,
+                    use_natural_foreign_keys=use_natural_foreign_keys,
+                    use_natural_primary_keys=use_natural_primary_keys,
+                    stream=stream or self.stdout, progress_output=progress_output,
+                    object_count=object_count,
+                )
+            finally:
+                if stream:
+                    stream.close()
+        except Exception as e:
+            if show_traceback:
+                raise
+            raise CommandError("Unable to serialize database: %s" % e)
Index: venv/Lib/site-packages/django/core/management/commands/flush.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/core/management/commands/flush.py b/venv/Lib/site-packages/django/core/management/commands/flush.py
new file mode 100644
--- /dev/null	(date 1617030485657)
+++ b/venv/Lib/site-packages/django/core/management/commands/flush.py	(date 1617030485657)
@@ -0,0 +1,82 @@
+from importlib import import_module
+
+from django.apps import apps
+from django.core.management.base import BaseCommand, CommandError
+from django.core.management.color import no_style
+from django.core.management.sql import emit_post_migrate_signal, sql_flush
+from django.db import DEFAULT_DB_ALIAS, connections
+
+
+class Command(BaseCommand):
+    help = (
+        'Removes ALL DATA from the database, including data added during '
+        'migrations. Does not achieve a "fresh install" state.'
+    )
+    stealth_options = ('reset_sequences', 'allow_cascade', 'inhibit_post_migrate')
+
+    def add_arguments(self, parser):
+        parser.add_argument(
+            '--noinput', '--no-input', action='store_false', dest='interactive',
+            help='Tells Django to NOT prompt the user for input of any kind.',
+        )
+        parser.add_argument(
+            '--database', default=DEFAULT_DB_ALIAS,
+            help='Nominates a database to flush. Defaults to the "default" database.',
+        )
+
+    def handle(self, **options):
+        database = options['database']
+        connection = connections[database]
+        verbosity = options['verbosity']
+        interactive = options['interactive']
+        # The following are stealth options used by Django's internals.
+        reset_sequences = options.get('reset_sequences', True)
+        allow_cascade = options.get('allow_cascade', False)
+        inhibit_post_migrate = options.get('inhibit_post_migrate', False)
+
+        self.style = no_style()
+
+        # Import the 'management' module within each installed app, to register
+        # dispatcher events.
+        for app_config in apps.get_app_configs():
+            try:
+                import_module('.management', app_config.name)
+            except ImportError:
+                pass
+
+        sql_list = sql_flush(self.style, connection, only_django=True,
+                             reset_sequences=reset_sequences,
+                             allow_cascade=allow_cascade)
+
+        if interactive:
+            confirm = input("""You have requested a flush of the database.
+This will IRREVERSIBLY DESTROY all data currently in the "%s" database,
+and return each table to an empty state.
+Are you sure you want to do this?
+
+    Type 'yes' to continue, or 'no' to cancel: """ % connection.settings_dict['NAME'])
+        else:
+            confirm = 'yes'
+
+        if confirm == 'yes':
+            try:
+                connection.ops.execute_sql_flush(sql_list)
+            except Exception as exc:
+                raise CommandError(
+                    "Database %s couldn't be flushed. Possible reasons:\n"
+                    "  * The database isn't running or isn't configured correctly.\n"
+                    "  * At least one of the expected database tables doesn't exist.\n"
+                    "  * The SQL was invalid.\n"
+                    "Hint: Look at the output of 'django-admin sqlflush'. "
+                    "That's the SQL this command wasn't able to run." % (
+                        connection.settings_dict['NAME'],
+                    )
+                ) from exc
+
+            # Empty sql_list may signify an empty database and post_migrate would then crash
+            if sql_list and not inhibit_post_migrate:
+                # Emit the post migrate signal. This allows individual applications to
+                # respond as if the database had been migrated from scratch.
+                emit_post_migrate_signal(verbosity, interactive, database)
+        else:
+            self.stdout.write('Flush cancelled.')
Index: venv/Lib/site-packages/django/core/management/commands/inspectdb.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/core/management/commands/inspectdb.py b/venv/Lib/site-packages/django/core/management/commands/inspectdb.py
new file mode 100644
--- /dev/null	(date 1617030485658)
+++ b/venv/Lib/site-packages/django/core/management/commands/inspectdb.py	(date 1617030485658)
@@ -0,0 +1,296 @@
+import keyword
+import re
+
+from django.core.management.base import BaseCommand, CommandError
+from django.db import DEFAULT_DB_ALIAS, connections
+from django.db.models.constants import LOOKUP_SEP
+
+
+class Command(BaseCommand):
+    help = "Introspects the database tables in the given database and outputs a Django model module."
+    requires_system_checks = False
+    stealth_options = ('table_name_filter',)
+    db_module = 'django.db'
+
+    def add_arguments(self, parser):
+        parser.add_argument(
+            'table', nargs='*', type=str,
+            help='Selects what tables or views should be introspected.',
+        )
+        parser.add_argument(
+            '--database', default=DEFAULT_DB_ALIAS,
+            help='Nominates a database to introspect. Defaults to using the "default" database.',
+        )
+        parser.add_argument(
+            '--include-partitions', action='store_true', help='Also output models for partition tables.',
+        )
+        parser.add_argument(
+            '--include-views', action='store_true', help='Also output models for database views.',
+        )
+
+    def handle(self, **options):
+        try:
+            for line in self.handle_inspection(options):
+                self.stdout.write(line)
+        except NotImplementedError:
+            raise CommandError("Database inspection isn't supported for the currently selected database backend.")
+
+    def handle_inspection(self, options):
+        connection = connections[options['database']]
+        # 'table_name_filter' is a stealth option
+        table_name_filter = options.get('table_name_filter')
+
+        def table2model(table_name):
+            return re.sub(r'[^a-zA-Z0-9]', '', table_name.title())
+
+        with connection.cursor() as cursor:
+            yield "# This is an auto-generated Django model module."
+            yield "# You'll have to do the following manually to clean this up:"
+            yield "#   * Rearrange models' order"
+            yield "#   * Make sure each model has one field with primary_key=True"
+            yield "#   * Make sure each ForeignKey and OneToOneField has `on_delete` set to the desired behavior"
+            yield (
+                "#   * Remove `managed = False` lines if you wish to allow "
+                "Django to create, modify, and delete the table"
+            )
+            yield "# Feel free to rename the models, but don't rename db_table values or field names."
+            yield 'from %s import models' % self.db_module
+            known_models = []
+            table_info = connection.introspection.get_table_list(cursor)
+
+            # Determine types of tables and/or views to be introspected.
+            types = {'t'}
+            if options['include_partitions']:
+                types.add('p')
+            if options['include_views']:
+                types.add('v')
+
+            for table_name in (options['table'] or sorted(info.name for info in table_info if info.type in types)):
+                if table_name_filter is not None and callable(table_name_filter):
+                    if not table_name_filter(table_name):
+                        continue
+                try:
+                    try:
+                        relations = connection.introspection.get_relations(cursor, table_name)
+                    except NotImplementedError:
+                        relations = {}
+                    try:
+                        constraints = connection.introspection.get_constraints(cursor, table_name)
+                    except NotImplementedError:
+                        constraints = {}
+                    primary_key_column = connection.introspection.get_primary_key_column(cursor, table_name)
+                    unique_columns = [
+                        c['columns'][0] for c in constraints.values()
+                        if c['unique'] and len(c['columns']) == 1
+                    ]
+                    table_description = connection.introspection.get_table_description(cursor, table_name)
+                except Exception as e:
+                    yield "# Unable to inspect table '%s'" % table_name
+                    yield "# The error was: %s" % e
+                    continue
+
+                yield ''
+                yield ''
+                yield 'class %s(models.Model):' % table2model(table_name)
+                known_models.append(table2model(table_name))
+                used_column_names = []  # Holds column names used in the table so far
+                column_to_field_name = {}  # Maps column names to names of model fields
+                for row in table_description:
+                    comment_notes = []  # Holds Field notes, to be displayed in a Python comment.
+                    extra_params = {}  # Holds Field parameters such as 'db_column'.
+                    column_name = row.name
+                    is_relation = column_name in relations
+
+                    att_name, params, notes = self.normalize_col_name(
+                        column_name, used_column_names, is_relation)
+                    extra_params.update(params)
+                    comment_notes.extend(notes)
+
+                    used_column_names.append(att_name)
+                    column_to_field_name[column_name] = att_name
+
+                    # Add primary_key and unique, if necessary.
+                    if column_name == primary_key_column:
+                        extra_params['primary_key'] = True
+                    elif column_name in unique_columns:
+                        extra_params['unique'] = True
+
+                    if is_relation:
+                        if extra_params.pop('unique', False) or extra_params.get('primary_key'):
+                            rel_type = 'OneToOneField'
+                        else:
+                            rel_type = 'ForeignKey'
+                        rel_to = (
+                            "self" if relations[column_name][1] == table_name
+                            else table2model(relations[column_name][1])
+                        )
+                        if rel_to in known_models:
+                            field_type = '%s(%s' % (rel_type, rel_to)
+                        else:
+                            field_type = "%s('%s'" % (rel_type, rel_to)
+                    else:
+                        # Calling `get_field_type` to get the field type string and any
+                        # additional parameters and notes.
+                        field_type, field_params, field_notes = self.get_field_type(connection, table_name, row)
+                        extra_params.update(field_params)
+                        comment_notes.extend(field_notes)
+
+                        field_type += '('
+
+                    # Don't output 'id = meta.AutoField(primary_key=True)', because
+                    # that's assumed if it doesn't exist.
+                    if att_name == 'id' and extra_params == {'primary_key': True}:
+                        if field_type == 'AutoField(':
+                            continue
+                        elif field_type == 'IntegerField(' and not connection.features.can_introspect_autofield:
+                            comment_notes.append('AutoField?')
+
+                    # Add 'null' and 'blank', if the 'null_ok' flag was present in the
+                    # table description.
+                    if row.null_ok:  # If it's NULL...
+                        extra_params['blank'] = True
+                        extra_params['null'] = True
+
+                    field_desc = '%s = %s%s' % (
+                        att_name,
+                        # Custom fields will have a dotted path
+                        '' if '.' in field_type else 'models.',
+                        field_type,
+                    )
+                    if field_type.startswith(('ForeignKey(', 'OneToOneField(')):
+                        field_desc += ', models.DO_NOTHING'
+
+                    if extra_params:
+                        if not field_desc.endswith('('):
+                            field_desc += ', '
+                        field_desc += ', '.join('%s=%r' % (k, v) for k, v in extra_params.items())
+                    field_desc += ')'
+                    if comment_notes:
+                        field_desc += '  # ' + ' '.join(comment_notes)
+                    yield '    %s' % field_desc
+                is_view = any(info.name == table_name and info.type == 'v' for info in table_info)
+                is_partition = any(info.name == table_name and info.type == 'p' for info in table_info)
+                yield from self.get_meta(table_name, constraints, column_to_field_name, is_view, is_partition)
+
+    def normalize_col_name(self, col_name, used_column_names, is_relation):
+        """
+        Modify the column name to make it Python-compatible as a field name
+        """
+        field_params = {}
+        field_notes = []
+
+        new_name = col_name.lower()
+        if new_name != col_name:
+            field_notes.append('Field name made lowercase.')
+
+        if is_relation:
+            if new_name.endswith('_id'):
+                new_name = new_name[:-3]
+            else:
+                field_params['db_column'] = col_name
+
+        new_name, num_repl = re.subn(r'\W', '_', new_name)
+        if num_repl > 0:
+            field_notes.append('Field renamed to remove unsuitable characters.')
+
+        if new_name.find(LOOKUP_SEP) >= 0:
+            while new_name.find(LOOKUP_SEP) >= 0:
+                new_name = new_name.replace(LOOKUP_SEP, '_')
+            if col_name.lower().find(LOOKUP_SEP) >= 0:
+                # Only add the comment if the double underscore was in the original name
+                field_notes.append("Field renamed because it contained more than one '_' in a row.")
+
+        if new_name.startswith('_'):
+            new_name = 'field%s' % new_name
+            field_notes.append("Field renamed because it started with '_'.")
+
+        if new_name.endswith('_'):
+            new_name = '%sfield' % new_name
+            field_notes.append("Field renamed because it ended with '_'.")
+
+        if keyword.iskeyword(new_name):
+            new_name += '_field'
+            field_notes.append('Field renamed because it was a Python reserved word.')
+
+        if new_name[0].isdigit():
+            new_name = 'number_%s' % new_name
+            field_notes.append("Field renamed because it wasn't a valid Python identifier.")
+
+        if new_name in used_column_names:
+            num = 0
+            while '%s_%d' % (new_name, num) in used_column_names:
+                num += 1
+            new_name = '%s_%d' % (new_name, num)
+            field_notes.append('Field renamed because of name conflict.')
+
+        if col_name != new_name and field_notes:
+            field_params['db_column'] = col_name
+
+        return new_name, field_params, field_notes
+
+    def get_field_type(self, connection, table_name, row):
+        """
+        Given the database connection, the table name, and the cursor row
+        description, this routine will return the given field type name, as
+        well as any additional keyword parameters and notes for the field.
+        """
+        field_params = {}
+        field_notes = []
+
+        try:
+            field_type = connection.introspection.get_field_type(row.type_code, row)
+        except KeyError:
+            field_type = 'TextField'
+            field_notes.append('This field type is a guess.')
+
+        # Add max_length for all CharFields.
+        if field_type == 'CharField' and row.internal_size:
+            field_params['max_length'] = int(row.internal_size)
+
+        if field_type == 'DecimalField':
+            if row.precision is None or row.scale is None:
+                field_notes.append(
+                    'max_digits and decimal_places have been guessed, as this '
+                    'database handles decimal fields as float')
+                field_params['max_digits'] = row.precision if row.precision is not None else 10
+                field_params['decimal_places'] = row.scale if row.scale is not None else 5
+            else:
+                field_params['max_digits'] = row.precision
+                field_params['decimal_places'] = row.scale
+
+        return field_type, field_params, field_notes
+
+    def get_meta(self, table_name, constraints, column_to_field_name, is_view, is_partition):
+        """
+        Return a sequence comprising the lines of code necessary
+        to construct the inner Meta class for the model corresponding
+        to the given database table name.
+        """
+        unique_together = []
+        has_unsupported_constraint = False
+        for params in constraints.values():
+            if params['unique']:
+                columns = params['columns']
+                if None in columns:
+                    has_unsupported_constraint = True
+                columns = [x for x in columns if x is not None]
+                if len(columns) > 1:
+                    unique_together.append(str(tuple(column_to_field_name[c] for c in columns)))
+        if is_view:
+            managed_comment = "  # Created from a view. Don't remove."
+        elif is_partition:
+            managed_comment = "  # Created from a partition. Don't remove."
+        else:
+            managed_comment = ''
+        meta = ['']
+        if has_unsupported_constraint:
+            meta.append('    # A unique constraint could not be introspected.')
+        meta += [
+            '    class Meta:',
+            '        managed = False%s' % managed_comment,
+            '        db_table = %r' % table_name
+        ]
+        if unique_together:
+            tup = '(' + ', '.join(unique_together) + ',)'
+            meta += ["        unique_together = %s" % tup]
+        return meta
Index: venv/Lib/site-packages/django/core/management/commands/loaddata.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/core/management/commands/loaddata.py b/venv/Lib/site-packages/django/core/management/commands/loaddata.py
new file mode 100644
--- /dev/null	(date 1617030485658)
+++ b/venv/Lib/site-packages/django/core/management/commands/loaddata.py	(date 1617030485658)
@@ -0,0 +1,350 @@
+import functools
+import glob
+import gzip
+import os
+import sys
+import warnings
+import zipfile
+from itertools import product
+
+from django.apps import apps
+from django.conf import settings
+from django.core import serializers
+from django.core.exceptions import ImproperlyConfigured
+from django.core.management.base import BaseCommand, CommandError
+from django.core.management.color import no_style
+from django.core.management.utils import parse_apps_and_model_labels
+from django.db import (
+    DEFAULT_DB_ALIAS, DatabaseError, IntegrityError, connections, router,
+    transaction,
+)
+from django.utils.functional import cached_property
+
+try:
+    import bz2
+    has_bz2 = True
+except ImportError:
+    has_bz2 = False
+
+READ_STDIN = '-'
+
+
+class Command(BaseCommand):
+    help = 'Installs the named fixture(s) in the database.'
+    missing_args_message = (
+        "No database fixture specified. Please provide the path of at least "
+        "one fixture in the command line."
+    )
+
+    def add_arguments(self, parser):
+        parser.add_argument('args', metavar='fixture', nargs='+', help='Fixture labels.')
+        parser.add_argument(
+            '--database', default=DEFAULT_DB_ALIAS,
+            help='Nominates a specific database to load fixtures into. Defaults to the "default" database.',
+        )
+        parser.add_argument(
+            '--app', dest='app_label',
+            help='Only look for fixtures in the specified app.',
+        )
+        parser.add_argument(
+            '--ignorenonexistent', '-i', action='store_true', dest='ignore',
+            help='Ignores entries in the serialized data for fields that do not '
+                 'currently exist on the model.',
+        )
+        parser.add_argument(
+            '-e', '--exclude', action='append', default=[],
+            help='An app_label or app_label.ModelName to exclude. Can be used multiple times.',
+        )
+        parser.add_argument(
+            '--format',
+            help='Format of serialized data when reading from stdin.',
+        )
+
+    def handle(self, *fixture_labels, **options):
+        self.ignore = options['ignore']
+        self.using = options['database']
+        self.app_label = options['app_label']
+        self.verbosity = options['verbosity']
+        self.excluded_models, self.excluded_apps = parse_apps_and_model_labels(options['exclude'])
+        self.format = options['format']
+
+        with transaction.atomic(using=self.using):
+            self.loaddata(fixture_labels)
+
+        # Close the DB connection -- unless we're still in a transaction. This
+        # is required as a workaround for an edge case in MySQL: if the same
+        # connection is used to create tables, load data, and query, the query
+        # can return incorrect results. See Django #7572, MySQL #37735.
+        if transaction.get_autocommit(self.using):
+            connections[self.using].close()
+
+    def loaddata(self, fixture_labels):
+        connection = connections[self.using]
+
+        # Keep a count of the installed objects and fixtures
+        self.fixture_count = 0
+        self.loaded_object_count = 0
+        self.fixture_object_count = 0
+        self.models = set()
+
+        self.serialization_formats = serializers.get_public_serializer_formats()
+        # Forcing binary mode may be revisited after dropping Python 2 support (see #22399)
+        self.compression_formats = {
+            None: (open, 'rb'),
+            'gz': (gzip.GzipFile, 'rb'),
+            'zip': (SingleZipReader, 'r'),
+            'stdin': (lambda *args: sys.stdin, None),
+        }
+        if has_bz2:
+            self.compression_formats['bz2'] = (bz2.BZ2File, 'r')
+
+        # Django's test suite repeatedly tries to load initial_data fixtures
+        # from apps that don't have any fixtures. Because disabling constraint
+        # checks can be expensive on some database (especially MSSQL), bail
+        # out early if no fixtures are found.
+        for fixture_label in fixture_labels:
+            if self.find_fixtures(fixture_label):
+                break
+        else:
+            return
+
+        with connection.constraint_checks_disabled():
+            self.objs_with_deferred_fields = []
+            for fixture_label in fixture_labels:
+                self.load_label(fixture_label)
+            for obj in self.objs_with_deferred_fields:
+                obj.save_deferred_fields(using=self.using)
+
+        # Since we disabled constraint checks, we must manually check for
+        # any invalid keys that might have been added
+        table_names = [model._meta.db_table for model in self.models]
+        try:
+            connection.check_constraints(table_names=table_names)
+        except Exception as e:
+            e.args = ("Problem installing fixtures: %s" % e,)
+            raise
+
+        # If we found even one object in a fixture, we need to reset the
+        # database sequences.
+        if self.loaded_object_count > 0:
+            sequence_sql = connection.ops.sequence_reset_sql(no_style(), self.models)
+            if sequence_sql:
+                if self.verbosity >= 2:
+                    self.stdout.write('Resetting sequences')
+                with connection.cursor() as cursor:
+                    for line in sequence_sql:
+                        cursor.execute(line)
+
+        if self.verbosity >= 1:
+            if self.fixture_object_count == self.loaded_object_count:
+                self.stdout.write(
+                    "Installed %d object(s) from %d fixture(s)"
+                    % (self.loaded_object_count, self.fixture_count)
+                )
+            else:
+                self.stdout.write(
+                    "Installed %d object(s) (of %d) from %d fixture(s)"
+                    % (self.loaded_object_count, self.fixture_object_count, self.fixture_count)
+                )
+
+    def load_label(self, fixture_label):
+        """Load fixtures files for a given label."""
+        show_progress = self.verbosity >= 3
+        for fixture_file, fixture_dir, fixture_name in self.find_fixtures(fixture_label):
+            _, ser_fmt, cmp_fmt = self.parse_name(os.path.basename(fixture_file))
+            open_method, mode = self.compression_formats[cmp_fmt]
+            fixture = open_method(fixture_file, mode)
+            try:
+                self.fixture_count += 1
+                objects_in_fixture = 0
+                loaded_objects_in_fixture = 0
+                if self.verbosity >= 2:
+                    self.stdout.write(
+                        "Installing %s fixture '%s' from %s."
+                        % (ser_fmt, fixture_name, humanize(fixture_dir))
+                    )
+
+                objects = serializers.deserialize(
+                    ser_fmt, fixture, using=self.using, ignorenonexistent=self.ignore,
+                    handle_forward_references=True,
+                )
+
+                for obj in objects:
+                    objects_in_fixture += 1
+                    if (obj.object._meta.app_config in self.excluded_apps or
+                            type(obj.object) in self.excluded_models):
+                        continue
+                    if router.allow_migrate_model(self.using, obj.object.__class__):
+                        loaded_objects_in_fixture += 1
+                        self.models.add(obj.object.__class__)
+                        try:
+                            obj.save(using=self.using)
+                            if show_progress:
+                                self.stdout.write(
+                                    '\rProcessed %i object(s).' % loaded_objects_in_fixture,
+                                    ending=''
+                                )
+                        # psycopg2 raises ValueError if data contains NUL chars.
+                        except (DatabaseError, IntegrityError, ValueError) as e:
+                            e.args = ("Could not load %(app_label)s.%(object_name)s(pk=%(pk)s): %(error_msg)s" % {
+                                'app_label': obj.object._meta.app_label,
+                                'object_name': obj.object._meta.object_name,
+                                'pk': obj.object.pk,
+                                'error_msg': e,
+                            },)
+                            raise
+                    if obj.deferred_fields:
+                        self.objs_with_deferred_fields.append(obj)
+                if objects and show_progress:
+                    self.stdout.write()  # Add a newline after progress indicator.
+                self.loaded_object_count += loaded_objects_in_fixture
+                self.fixture_object_count += objects_in_fixture
+            except Exception as e:
+                if not isinstance(e, CommandError):
+                    e.args = ("Problem installing fixture '%s': %s" % (fixture_file, e),)
+                raise
+            finally:
+                fixture.close()
+
+            # Warn if the fixture we loaded contains 0 objects.
+            if objects_in_fixture == 0:
+                warnings.warn(
+                    "No fixture data found for '%s'. (File format may be "
+                    "invalid.)" % fixture_name,
+                    RuntimeWarning
+                )
+
+    @functools.lru_cache(maxsize=None)
+    def find_fixtures(self, fixture_label):
+        """Find fixture files for a given label."""
+        if fixture_label == READ_STDIN:
+            return [(READ_STDIN, None, READ_STDIN)]
+
+        fixture_name, ser_fmt, cmp_fmt = self.parse_name(fixture_label)
+        databases = [self.using, None]
+        cmp_fmts = list(self.compression_formats) if cmp_fmt is None else [cmp_fmt]
+        ser_fmts = serializers.get_public_serializer_formats() if ser_fmt is None else [ser_fmt]
+
+        if self.verbosity >= 2:
+            self.stdout.write("Loading '%s' fixtures..." % fixture_name)
+
+        if os.path.isabs(fixture_name):
+            fixture_dirs = [os.path.dirname(fixture_name)]
+            fixture_name = os.path.basename(fixture_name)
+        else:
+            fixture_dirs = self.fixture_dirs
+            if os.path.sep in os.path.normpath(fixture_name):
+                fixture_dirs = [os.path.join(dir_, os.path.dirname(fixture_name))
+                                for dir_ in fixture_dirs]
+                fixture_name = os.path.basename(fixture_name)
+
+        suffixes = (
+            '.'.join(ext for ext in combo if ext)
+            for combo in product(databases, ser_fmts, cmp_fmts)
+        )
+        targets = {'.'.join((fixture_name, suffix)) for suffix in suffixes}
+
+        fixture_files = []
+        for fixture_dir in fixture_dirs:
+            if self.verbosity >= 2:
+                self.stdout.write("Checking %s for fixtures..." % humanize(fixture_dir))
+            fixture_files_in_dir = []
+            path = os.path.join(fixture_dir, fixture_name)
+            for candidate in glob.iglob(glob.escape(path) + '*'):
+                if os.path.basename(candidate) in targets:
+                    # Save the fixture_dir and fixture_name for future error messages.
+                    fixture_files_in_dir.append((candidate, fixture_dir, fixture_name))
+
+            if self.verbosity >= 2 and not fixture_files_in_dir:
+                self.stdout.write("No fixture '%s' in %s." %
+                                  (fixture_name, humanize(fixture_dir)))
+
+            # Check kept for backwards-compatibility; it isn't clear why
+            # duplicates are only allowed in different directories.
+            if len(fixture_files_in_dir) > 1:
+                raise CommandError(
+                    "Multiple fixtures named '%s' in %s. Aborting." %
+                    (fixture_name, humanize(fixture_dir)))
+            fixture_files.extend(fixture_files_in_dir)
+
+        if not fixture_files:
+            raise CommandError("No fixture named '%s' found." % fixture_name)
+
+        return fixture_files
+
+    @cached_property
+    def fixture_dirs(self):
+        """
+        Return a list of fixture directories.
+
+        The list contains the 'fixtures' subdirectory of each installed
+        application, if it exists, the directories in FIXTURE_DIRS, and the
+        current directory.
+        """
+        dirs = []
+        fixture_dirs = settings.FIXTURE_DIRS
+        if len(fixture_dirs) != len(set(fixture_dirs)):
+            raise ImproperlyConfigured("settings.FIXTURE_DIRS contains duplicates.")
+        for app_config in apps.get_app_configs():
+            app_label = app_config.label
+            app_dir = os.path.join(app_config.path, 'fixtures')
+            if app_dir in fixture_dirs:
+                raise ImproperlyConfigured(
+                    "'%s' is a default fixture directory for the '%s' app "
+                    "and cannot be listed in settings.FIXTURE_DIRS." % (app_dir, app_label)
+                )
+
+            if self.app_label and app_label != self.app_label:
+                continue
+            if os.path.isdir(app_dir):
+                dirs.append(app_dir)
+        dirs.extend(fixture_dirs)
+        dirs.append('')
+        return [os.path.realpath(d) for d in dirs]
+
+    def parse_name(self, fixture_name):
+        """
+        Split fixture name in name, serialization format, compression format.
+        """
+        if fixture_name == READ_STDIN:
+            if not self.format:
+                raise CommandError('--format must be specified when reading from stdin.')
+            return READ_STDIN, self.format, 'stdin'
+
+        parts = fixture_name.rsplit('.', 2)
+
+        if len(parts) > 1 and parts[-1] in self.compression_formats:
+            cmp_fmt = parts[-1]
+            parts = parts[:-1]
+        else:
+            cmp_fmt = None
+
+        if len(parts) > 1:
+            if parts[-1] in self.serialization_formats:
+                ser_fmt = parts[-1]
+                parts = parts[:-1]
+            else:
+                raise CommandError(
+                    "Problem installing fixture '%s': %s is not a known "
+                    "serialization format." % ('.'.join(parts[:-1]), parts[-1]))
+        else:
+            ser_fmt = None
+
+        name = '.'.join(parts)
+
+        return name, ser_fmt, cmp_fmt
+
+
+class SingleZipReader(zipfile.ZipFile):
+
+    def __init__(self, *args, **kwargs):
+        super().__init__(*args, **kwargs)
+        if len(self.namelist()) != 1:
+            raise ValueError("Zip-compressed fixtures must contain one file.")
+
+    def read(self):
+        return zipfile.ZipFile.read(self, self.namelist()[0])
+
+
+def humanize(dirname):
+    return "'%s'" % dirname if dirname else 'absolute path'
Index: venv/Lib/site-packages/django/core/management/commands/makemessages.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/core/management/commands/makemessages.py b/venv/Lib/site-packages/django/core/management/commands/makemessages.py
new file mode 100644
--- /dev/null	(date 1617030485658)
+++ b/venv/Lib/site-packages/django/core/management/commands/makemessages.py	(date 1617030485658)
@@ -0,0 +1,662 @@
+import glob
+import os
+import re
+import sys
+from functools import total_ordering
+from itertools import dropwhile
+
+import django
+from django.conf import settings
+from django.core.exceptions import ImproperlyConfigured
+from django.core.files.temp import NamedTemporaryFile
+from django.core.management.base import BaseCommand, CommandError
+from django.core.management.utils import (
+    find_command, handle_extensions, is_ignored_path, popen_wrapper,
+)
+from django.utils.encoding import DEFAULT_LOCALE_ENCODING
+from django.utils.functional import cached_property
+from django.utils.jslex import prepare_js_for_gettext
+from django.utils.regex_helper import _lazy_re_compile
+from django.utils.text import get_text_list
+from django.utils.translation import templatize
+
+plural_forms_re = _lazy_re_compile(r'^(?P<value>"Plural-Forms.+?\\n")\s*$', re.MULTILINE | re.DOTALL)
+STATUS_OK = 0
+NO_LOCALE_DIR = object()
+
+
+def check_programs(*programs):
+    for program in programs:
+        if find_command(program) is None:
+            raise CommandError(
+                "Can't find %s. Make sure you have GNU gettext tools 0.15 or "
+                "newer installed." % program
+            )
+
+
+@total_ordering
+class TranslatableFile:
+    def __init__(self, dirpath, file_name, locale_dir):
+        self.file = file_name
+        self.dirpath = dirpath
+        self.locale_dir = locale_dir
+
+    def __repr__(self):
+        return "<%s: %s>" % (
+            self.__class__.__name__,
+            os.sep.join([self.dirpath, self.file]),
+        )
+
+    def __eq__(self, other):
+        return self.path == other.path
+
+    def __lt__(self, other):
+        return self.path < other.path
+
+    @property
+    def path(self):
+        return os.path.join(self.dirpath, self.file)
+
+
+class BuildFile:
+    """
+    Represent the state of a translatable file during the build process.
+    """
+    def __init__(self, command, domain, translatable):
+        self.command = command
+        self.domain = domain
+        self.translatable = translatable
+
+    @cached_property
+    def is_templatized(self):
+        if self.domain == 'djangojs':
+            return self.command.gettext_version < (0, 18, 3)
+        elif self.domain == 'django':
+            file_ext = os.path.splitext(self.translatable.file)[1]
+            return file_ext != '.py'
+        return False
+
+    @cached_property
+    def path(self):
+        return self.translatable.path
+
+    @cached_property
+    def work_path(self):
+        """
+        Path to a file which is being fed into GNU gettext pipeline. This may
+        be either a translatable or its preprocessed version.
+        """
+        if not self.is_templatized:
+            return self.path
+        extension = {
+            'djangojs': 'c',
+            'django': 'py',
+        }.get(self.domain)
+        filename = '%s.%s' % (self.translatable.file, extension)
+        return os.path.join(self.translatable.dirpath, filename)
+
+    def preprocess(self):
+        """
+        Preprocess (if necessary) a translatable file before passing it to
+        xgettext GNU gettext utility.
+        """
+        if not self.is_templatized:
+            return
+
+        with open(self.path, encoding='utf-8') as fp:
+            src_data = fp.read()
+
+        if self.domain == 'djangojs':
+            content = prepare_js_for_gettext(src_data)
+        elif self.domain == 'django':
+            content = templatize(src_data, origin=self.path[2:])
+
+        with open(self.work_path, 'w', encoding='utf-8') as fp:
+            fp.write(content)
+
+    def postprocess_messages(self, msgs):
+        """
+        Postprocess messages generated by xgettext GNU gettext utility.
+
+        Transform paths as if these messages were generated from original
+        translatable files rather than from preprocessed versions.
+        """
+        if not self.is_templatized:
+            return msgs
+
+        # Remove '.py' suffix
+        if os.name == 'nt':
+            # Preserve '.\' prefix on Windows to respect gettext behavior
+            old_path = self.work_path
+            new_path = self.path
+        else:
+            old_path = self.work_path[2:]
+            new_path = self.path[2:]
+
+        return re.sub(
+            r'^(#: .*)(' + re.escape(old_path) + r')',
+            lambda match: match[0].replace(old_path, new_path),
+            msgs,
+            flags=re.MULTILINE
+        )
+
+    def cleanup(self):
+        """
+        Remove a preprocessed copy of a translatable file (if any).
+        """
+        if self.is_templatized:
+            # This check is needed for the case of a symlinked file and its
+            # source being processed inside a single group (locale dir);
+            # removing either of those two removes both.
+            if os.path.exists(self.work_path):
+                os.unlink(self.work_path)
+
+
+def normalize_eols(raw_contents):
+    """
+    Take a block of raw text that will be passed through str.splitlines() to
+    get universal newlines treatment.
+
+    Return the resulting block of text with normalized `\n` EOL sequences ready
+    to be written to disk using current platform's native EOLs.
+    """
+    lines_list = raw_contents.splitlines()
+    # Ensure last line has its EOL
+    if lines_list and lines_list[-1]:
+        lines_list.append('')
+    return '\n'.join(lines_list)
+
+
+def write_pot_file(potfile, msgs):
+    """
+    Write the `potfile` with the `msgs` contents, making sure its format is
+    valid.
+    """
+    pot_lines = msgs.splitlines()
+    if os.path.exists(potfile):
+        # Strip the header
+        lines = dropwhile(len, pot_lines)
+    else:
+        lines = []
+        found, header_read = False, False
+        for line in pot_lines:
+            if not found and not header_read:
+                if 'charset=CHARSET' in line:
+                    found = True
+                    line = line.replace('charset=CHARSET', 'charset=UTF-8')
+            if not line and not found:
+                header_read = True
+            lines.append(line)
+    msgs = '\n'.join(lines)
+    # Force newlines of POT files to '\n' to work around
+    # https://savannah.gnu.org/bugs/index.php?52395
+    with open(potfile, 'a', encoding='utf-8', newline='\n') as fp:
+        fp.write(msgs)
+
+
+class Command(BaseCommand):
+    help = (
+        "Runs over the entire source tree of the current directory and "
+        "pulls out all strings marked for translation. It creates (or updates) a message "
+        "file in the conf/locale (in the django tree) or locale (for projects and "
+        "applications) directory.\n\nYou must run this command with one of either the "
+        "--locale, --exclude, or --all options."
+    )
+
+    translatable_file_class = TranslatableFile
+    build_file_class = BuildFile
+
+    requires_system_checks = False
+
+    msgmerge_options = ['-q', '--previous']
+    msguniq_options = ['--to-code=utf-8']
+    msgattrib_options = ['--no-obsolete']
+    xgettext_options = ['--from-code=UTF-8', '--add-comments=Translators']
+
+    def add_arguments(self, parser):
+        parser.add_argument(
+            '--locale', '-l', default=[], action='append',
+            help='Creates or updates the message files for the given locale(s) (e.g. pt_BR). '
+                 'Can be used multiple times.',
+        )
+        parser.add_argument(
+            '--exclude', '-x', default=[], action='append',
+            help='Locales to exclude. Default is none. Can be used multiple times.',
+        )
+        parser.add_argument(
+            '--domain', '-d', default='django',
+            help='The domain of the message files (default: "django").',
+        )
+        parser.add_argument(
+            '--all', '-a', action='store_true',
+            help='Updates the message files for all existing locales.',
+        )
+        parser.add_argument(
+            '--extension', '-e', dest='extensions', action='append',
+            help='The file extension(s) to examine (default: "html,txt,py", or "js" '
+                 'if the domain is "djangojs"). Separate multiple extensions with '
+                 'commas, or use -e multiple times.',
+        )
+        parser.add_argument(
+            '--symlinks', '-s', action='store_true',
+            help='Follows symlinks to directories when examining source code '
+                 'and templates for translation strings.',
+        )
+        parser.add_argument(
+            '--ignore', '-i', action='append', dest='ignore_patterns',
+            default=[], metavar='PATTERN',
+            help='Ignore files or directories matching this glob-style pattern. '
+                 'Use multiple times to ignore more.',
+        )
+        parser.add_argument(
+            '--no-default-ignore', action='store_false', dest='use_default_ignore_patterns',
+            help="Don't ignore the common glob-style patterns 'CVS', '.*', '*~' and '*.pyc'.",
+        )
+        parser.add_argument(
+            '--no-wrap', action='store_true',
+            help="Don't break long message lines into several lines.",
+        )
+        parser.add_argument(
+            '--no-location', action='store_true',
+            help="Don't write '#: filename:line' lines.",
+        )
+        parser.add_argument(
+            '--add-location',
+            choices=('full', 'file', 'never'), const='full', nargs='?',
+            help=(
+                "Controls '#: filename:line' lines. If the option is 'full' "
+                "(the default if not given), the lines  include both file name "
+                "and line number. If it's 'file', the line number is omitted. If "
+                "it's 'never', the lines are suppressed (same as --no-location). "
+                "--add-location requires gettext 0.19 or newer."
+            ),
+        )
+        parser.add_argument(
+            '--no-obsolete', action='store_true',
+            help="Remove obsolete message strings.",
+        )
+        parser.add_argument(
+            '--keep-pot', action='store_true',
+            help="Keep .pot file after making messages. Useful when debugging.",
+        )
+
+    def handle(self, *args, **options):
+        locale = options['locale']
+        exclude = options['exclude']
+        self.domain = options['domain']
+        self.verbosity = options['verbosity']
+        process_all = options['all']
+        extensions = options['extensions']
+        self.symlinks = options['symlinks']
+
+        ignore_patterns = options['ignore_patterns']
+        if options['use_default_ignore_patterns']:
+            ignore_patterns += ['CVS', '.*', '*~', '*.pyc']
+        self.ignore_patterns = list(set(ignore_patterns))
+
+        # Avoid messing with mutable class variables
+        if options['no_wrap']:
+            self.msgmerge_options = self.msgmerge_options[:] + ['--no-wrap']
+            self.msguniq_options = self.msguniq_options[:] + ['--no-wrap']
+            self.msgattrib_options = self.msgattrib_options[:] + ['--no-wrap']
+            self.xgettext_options = self.xgettext_options[:] + ['--no-wrap']
+        if options['no_location']:
+            self.msgmerge_options = self.msgmerge_options[:] + ['--no-location']
+            self.msguniq_options = self.msguniq_options[:] + ['--no-location']
+            self.msgattrib_options = self.msgattrib_options[:] + ['--no-location']
+            self.xgettext_options = self.xgettext_options[:] + ['--no-location']
+        if options['add_location']:
+            if self.gettext_version < (0, 19):
+                raise CommandError(
+                    "The --add-location option requires gettext 0.19 or later. "
+                    "You have %s." % '.'.join(str(x) for x in self.gettext_version)
+                )
+            arg_add_location = "--add-location=%s" % options['add_location']
+            self.msgmerge_options = self.msgmerge_options[:] + [arg_add_location]
+            self.msguniq_options = self.msguniq_options[:] + [arg_add_location]
+            self.msgattrib_options = self.msgattrib_options[:] + [arg_add_location]
+            self.xgettext_options = self.xgettext_options[:] + [arg_add_location]
+
+        self.no_obsolete = options['no_obsolete']
+        self.keep_pot = options['keep_pot']
+
+        if self.domain not in ('django', 'djangojs'):
+            raise CommandError("currently makemessages only supports domains "
+                               "'django' and 'djangojs'")
+        if self.domain == 'djangojs':
+            exts = extensions or ['js']
+        else:
+            exts = extensions or ['html', 'txt', 'py']
+        self.extensions = handle_extensions(exts)
+
+        if (not locale and not exclude and not process_all) or self.domain is None:
+            raise CommandError(
+                "Type '%s help %s' for usage information."
+                % (os.path.basename(sys.argv[0]), sys.argv[1])
+            )
+
+        if self.verbosity > 1:
+            self.stdout.write(
+                'examining files with the extensions: %s'
+                % get_text_list(list(self.extensions), 'and')
+            )
+
+        self.invoked_for_django = False
+        self.locale_paths = []
+        self.default_locale_path = None
+        if os.path.isdir(os.path.join('conf', 'locale')):
+            self.locale_paths = [os.path.abspath(os.path.join('conf', 'locale'))]
+            self.default_locale_path = self.locale_paths[0]
+            self.invoked_for_django = True
+        else:
+            if self.settings_available:
+                self.locale_paths.extend(settings.LOCALE_PATHS)
+            # Allow to run makemessages inside an app dir
+            if os.path.isdir('locale'):
+                self.locale_paths.append(os.path.abspath('locale'))
+            if self.locale_paths:
+                self.default_locale_path = self.locale_paths[0]
+                os.makedirs(self.default_locale_path, exist_ok=True)
+
+        # Build locale list
+        looks_like_locale = re.compile(r'[a-z]{2}')
+        locale_dirs = filter(os.path.isdir, glob.glob('%s/*' % self.default_locale_path))
+        all_locales = [
+            lang_code for lang_code in map(os.path.basename, locale_dirs)
+            if looks_like_locale.match(lang_code)
+        ]
+
+        # Account for excluded locales
+        if process_all:
+            locales = all_locales
+        else:
+            locales = locale or all_locales
+            locales = set(locales).difference(exclude)
+
+        if locales:
+            check_programs('msguniq', 'msgmerge', 'msgattrib')
+
+        check_programs('xgettext')
+
+        try:
+            potfiles = self.build_potfiles()
+
+            # Build po files for each selected locale
+            for locale in locales:
+                if self.verbosity > 0:
+                    self.stdout.write('processing locale %s' % locale)
+                for potfile in potfiles:
+                    self.write_po_file(potfile, locale)
+        finally:
+            if not self.keep_pot:
+                self.remove_potfiles()
+
+    @cached_property
+    def gettext_version(self):
+        # Gettext tools will output system-encoded bytestrings instead of UTF-8,
+        # when looking up the version. It's especially a problem on Windows.
+        out, err, status = popen_wrapper(
+            ['xgettext', '--version'],
+            stdout_encoding=DEFAULT_LOCALE_ENCODING,
+        )
+        m = re.search(r'(\d+)\.(\d+)\.?(\d+)?', out)
+        if m:
+            return tuple(int(d) for d in m.groups() if d is not None)
+        else:
+            raise CommandError("Unable to get gettext version. Is it installed?")
+
+    @cached_property
+    def settings_available(self):
+        try:
+            settings.LOCALE_PATHS
+        except ImproperlyConfigured:
+            if self.verbosity > 1:
+                self.stderr.write("Running without configured settings.")
+            return False
+        return True
+
+    def build_potfiles(self):
+        """
+        Build pot files and apply msguniq to them.
+        """
+        file_list = self.find_files(".")
+        self.remove_potfiles()
+        self.process_files(file_list)
+        potfiles = []
+        for path in self.locale_paths:
+            potfile = os.path.join(path, '%s.pot' % self.domain)
+            if not os.path.exists(potfile):
+                continue
+            args = ['msguniq'] + self.msguniq_options + [potfile]
+            msgs, errors, status = popen_wrapper(args)
+            if errors:
+                if status != STATUS_OK:
+                    raise CommandError(
+                        "errors happened while running msguniq\n%s" % errors)
+                elif self.verbosity > 0:
+                    self.stdout.write(errors)
+            msgs = normalize_eols(msgs)
+            with open(potfile, 'w', encoding='utf-8') as fp:
+                fp.write(msgs)
+            potfiles.append(potfile)
+        return potfiles
+
+    def remove_potfiles(self):
+        for path in self.locale_paths:
+            pot_path = os.path.join(path, '%s.pot' % self.domain)
+            if os.path.exists(pot_path):
+                os.unlink(pot_path)
+
+    def find_files(self, root):
+        """
+        Get all files in the given root. Also check that there is a matching
+        locale dir for each file.
+        """
+        all_files = []
+        ignored_roots = []
+        if self.settings_available:
+            ignored_roots = [os.path.normpath(p) for p in (settings.MEDIA_ROOT, settings.STATIC_ROOT) if p]
+        for dirpath, dirnames, filenames in os.walk(root, topdown=True, followlinks=self.symlinks):
+            for dirname in dirnames[:]:
+                if (is_ignored_path(os.path.normpath(os.path.join(dirpath, dirname)), self.ignore_patterns) or
+                        os.path.join(os.path.abspath(dirpath), dirname) in ignored_roots):
+                    dirnames.remove(dirname)
+                    if self.verbosity > 1:
+                        self.stdout.write('ignoring directory %s' % dirname)
+                elif dirname == 'locale':
+                    dirnames.remove(dirname)
+                    self.locale_paths.insert(0, os.path.join(os.path.abspath(dirpath), dirname))
+            for filename in filenames:
+                file_path = os.path.normpath(os.path.join(dirpath, filename))
+                file_ext = os.path.splitext(filename)[1]
+                if file_ext not in self.extensions or is_ignored_path(file_path, self.ignore_patterns):
+                    if self.verbosity > 1:
+                        self.stdout.write('ignoring file %s in %s' % (filename, dirpath))
+                else:
+                    locale_dir = None
+                    for path in self.locale_paths:
+                        if os.path.abspath(dirpath).startswith(os.path.dirname(path)):
+                            locale_dir = path
+                            break
+                    locale_dir = locale_dir or self.default_locale_path or NO_LOCALE_DIR
+                    all_files.append(self.translatable_file_class(dirpath, filename, locale_dir))
+        return sorted(all_files)
+
+    def process_files(self, file_list):
+        """
+        Group translatable files by locale directory and run pot file build
+        process for each group.
+        """
+        file_groups = {}
+        for translatable in file_list:
+            file_group = file_groups.setdefault(translatable.locale_dir, [])
+            file_group.append(translatable)
+        for locale_dir, files in file_groups.items():
+            self.process_locale_dir(locale_dir, files)
+
+    def process_locale_dir(self, locale_dir, files):
+        """
+        Extract translatable literals from the specified files, creating or
+        updating the POT file for a given locale directory.
+
+        Use the xgettext GNU gettext utility.
+        """
+        build_files = []
+        for translatable in files:
+            if self.verbosity > 1:
+                self.stdout.write('processing file %s in %s' % (
+                    translatable.file, translatable.dirpath
+                ))
+            if self.domain not in ('djangojs', 'django'):
+                continue
+            build_file = self.build_file_class(self, self.domain, translatable)
+            try:
+                build_file.preprocess()
+            except UnicodeDecodeError as e:
+                self.stdout.write(
+                    'UnicodeDecodeError: skipped file %s in %s (reason: %s)' % (
+                        translatable.file, translatable.dirpath, e,
+                    )
+                )
+                continue
+            build_files.append(build_file)
+
+        if self.domain == 'djangojs':
+            is_templatized = build_file.is_templatized
+            args = [
+                'xgettext',
+                '-d', self.domain,
+                '--language=%s' % ('C' if is_templatized else 'JavaScript',),
+                '--keyword=gettext_noop',
+                '--keyword=gettext_lazy',
+                '--keyword=ngettext_lazy:1,2',
+                '--keyword=pgettext:1c,2',
+                '--keyword=npgettext:1c,2,3',
+                '--output=-',
+            ]
+        elif self.domain == 'django':
+            args = [
+                'xgettext',
+                '-d', self.domain,
+                '--language=Python',
+                '--keyword=gettext_noop',
+                '--keyword=gettext_lazy',
+                '--keyword=ngettext_lazy:1,2',
+                '--keyword=ugettext_noop',
+                '--keyword=ugettext_lazy',
+                '--keyword=ungettext_lazy:1,2',
+                '--keyword=pgettext:1c,2',
+                '--keyword=npgettext:1c,2,3',
+                '--keyword=pgettext_lazy:1c,2',
+                '--keyword=npgettext_lazy:1c,2,3',
+                '--output=-',
+            ]
+        else:
+            return
+
+        input_files = [bf.work_path for bf in build_files]
+        with NamedTemporaryFile(mode='w+') as input_files_list:
+            input_files_list.write('\n'.join(input_files))
+            input_files_list.flush()
+            args.extend(['--files-from', input_files_list.name])
+            args.extend(self.xgettext_options)
+            msgs, errors, status = popen_wrapper(args)
+
+        if errors:
+            if status != STATUS_OK:
+                for build_file in build_files:
+                    build_file.cleanup()
+                raise CommandError(
+                    'errors happened while running xgettext on %s\n%s' %
+                    ('\n'.join(input_files), errors)
+                )
+            elif self.verbosity > 0:
+                # Print warnings
+                self.stdout.write(errors)
+
+        if msgs:
+            if locale_dir is NO_LOCALE_DIR:
+                file_path = os.path.normpath(build_files[0].path)
+                raise CommandError(
+                    'Unable to find a locale path to store translations for '
+                    'file %s' % file_path
+                )
+            for build_file in build_files:
+                msgs = build_file.postprocess_messages(msgs)
+            potfile = os.path.join(locale_dir, '%s.pot' % self.domain)
+            write_pot_file(potfile, msgs)
+
+        for build_file in build_files:
+            build_file.cleanup()
+
+    def write_po_file(self, potfile, locale):
+        """
+        Create or update the PO file for self.domain and `locale`.
+        Use contents of the existing `potfile`.
+
+        Use msgmerge and msgattrib GNU gettext utilities.
+        """
+        basedir = os.path.join(os.path.dirname(potfile), locale, 'LC_MESSAGES')
+        os.makedirs(basedir, exist_ok=True)
+        pofile = os.path.join(basedir, '%s.po' % self.domain)
+
+        if os.path.exists(pofile):
+            args = ['msgmerge'] + self.msgmerge_options + [pofile, potfile]
+            msgs, errors, status = popen_wrapper(args)
+            if errors:
+                if status != STATUS_OK:
+                    raise CommandError(
+                        "errors happened while running msgmerge\n%s" % errors)
+                elif self.verbosity > 0:
+                    self.stdout.write(errors)
+        else:
+            with open(potfile, encoding='utf-8') as fp:
+                msgs = fp.read()
+            if not self.invoked_for_django:
+                msgs = self.copy_plural_forms(msgs, locale)
+        msgs = normalize_eols(msgs)
+        msgs = msgs.replace(
+            "#. #-#-#-#-#  %s.pot (PACKAGE VERSION)  #-#-#-#-#\n" % self.domain, "")
+        with open(pofile, 'w', encoding='utf-8') as fp:
+            fp.write(msgs)
+
+        if self.no_obsolete:
+            args = ['msgattrib'] + self.msgattrib_options + ['-o', pofile, pofile]
+            msgs, errors, status = popen_wrapper(args)
+            if errors:
+                if status != STATUS_OK:
+                    raise CommandError(
+                        "errors happened while running msgattrib\n%s" % errors)
+                elif self.verbosity > 0:
+                    self.stdout.write(errors)
+
+    def copy_plural_forms(self, msgs, locale):
+        """
+        Copy plural forms header contents from a Django catalog of locale to
+        the msgs string, inserting it at the right place. msgs should be the
+        contents of a newly created .po file.
+        """
+        django_dir = os.path.normpath(os.path.join(os.path.dirname(django.__file__)))
+        if self.domain == 'djangojs':
+            domains = ('djangojs', 'django')
+        else:
+            domains = ('django',)
+        for domain in domains:
+            django_po = os.path.join(django_dir, 'conf', 'locale', locale, 'LC_MESSAGES', '%s.po' % domain)
+            if os.path.exists(django_po):
+                with open(django_po, encoding='utf-8') as fp:
+                    m = plural_forms_re.search(fp.read())
+                if m:
+                    plural_form_line = m['value']
+                    if self.verbosity > 1:
+                        self.stdout.write('copying plural forms: %s' % plural_form_line)
+                    lines = []
+                    found = False
+                    for line in msgs.splitlines():
+                        if not found and (not line or plural_forms_re.search(line)):
+                            line = plural_form_line
+                            found = True
+                        lines.append(line)
+                    msgs = '\n'.join(lines)
+                    break
+        return msgs
Index: venv/Lib/site-packages/django/core/management/commands/makemigrations.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/core/management/commands/makemigrations.py b/venv/Lib/site-packages/django/core/management/commands/makemigrations.py
new file mode 100644
--- /dev/null	(date 1617030485659)
+++ b/venv/Lib/site-packages/django/core/management/commands/makemigrations.py	(date 1617030485659)
@@ -0,0 +1,310 @@
+import os
+import sys
+from itertools import takewhile
+
+from django.apps import apps
+from django.conf import settings
+from django.core.management.base import (
+    BaseCommand, CommandError, no_translations,
+)
+from django.db import DEFAULT_DB_ALIAS, connections, router
+from django.db.migrations import Migration
+from django.db.migrations.autodetector import MigrationAutodetector
+from django.db.migrations.loader import MigrationLoader
+from django.db.migrations.questioner import (
+    InteractiveMigrationQuestioner, MigrationQuestioner,
+    NonInteractiveMigrationQuestioner,
+)
+from django.db.migrations.state import ProjectState
+from django.db.migrations.utils import get_migration_name_timestamp
+from django.db.migrations.writer import MigrationWriter
+
+
+class Command(BaseCommand):
+    help = "Creates new migration(s) for apps."
+
+    def add_arguments(self, parser):
+        parser.add_argument(
+            'args', metavar='app_label', nargs='*',
+            help='Specify the app label(s) to create migrations for.',
+        )
+        parser.add_argument(
+            '--dry-run', action='store_true',
+            help="Just show what migrations would be made; don't actually write them.",
+        )
+        parser.add_argument(
+            '--merge', action='store_true',
+            help="Enable fixing of migration conflicts.",
+        )
+        parser.add_argument(
+            '--empty', action='store_true',
+            help="Create an empty migration.",
+        )
+        parser.add_argument(
+            '--noinput', '--no-input', action='store_false', dest='interactive',
+            help='Tells Django to NOT prompt the user for input of any kind.',
+        )
+        parser.add_argument(
+            '-n', '--name',
+            help="Use this name for migration file(s).",
+        )
+        parser.add_argument(
+            '--no-header', action='store_false', dest='include_header',
+            help='Do not add header comments to new migration file(s).',
+        )
+        parser.add_argument(
+            '--check', action='store_true', dest='check_changes',
+            help='Exit with a non-zero status if model changes are missing migrations.',
+        )
+
+    @no_translations
+    def handle(self, *app_labels, **options):
+        self.verbosity = options['verbosity']
+        self.interactive = options['interactive']
+        self.dry_run = options['dry_run']
+        self.merge = options['merge']
+        self.empty = options['empty']
+        self.migration_name = options['name']
+        if self.migration_name and not self.migration_name.isidentifier():
+            raise CommandError('The migration name must be a valid Python identifier.')
+        self.include_header = options['include_header']
+        check_changes = options['check_changes']
+
+        # Make sure the app they asked for exists
+        app_labels = set(app_labels)
+        has_bad_labels = False
+        for app_label in app_labels:
+            try:
+                apps.get_app_config(app_label)
+            except LookupError as err:
+                self.stderr.write(str(err))
+                has_bad_labels = True
+        if has_bad_labels:
+            sys.exit(2)
+
+        # Load the current graph state. Pass in None for the connection so
+        # the loader doesn't try to resolve replaced migrations from DB.
+        loader = MigrationLoader(None, ignore_no_migrations=True)
+
+        # Raise an error if any migrations are applied before their dependencies.
+        consistency_check_labels = {config.label for config in apps.get_app_configs()}
+        # Non-default databases are only checked if database routers used.
+        aliases_to_check = connections if settings.DATABASE_ROUTERS else [DEFAULT_DB_ALIAS]
+        for alias in sorted(aliases_to_check):
+            connection = connections[alias]
+            if (connection.settings_dict['ENGINE'] != 'django.db.backends.dummy' and any(
+                    # At least one model must be migrated to the database.
+                    router.allow_migrate(connection.alias, app_label, model_name=model._meta.object_name)
+                    for app_label in consistency_check_labels
+                    for model in apps.get_app_config(app_label).get_models()
+            )):
+                loader.check_consistent_history(connection)
+
+        # Before anything else, see if there's conflicting apps and drop out
+        # hard if there are any and they don't want to merge
+        conflicts = loader.detect_conflicts()
+
+        # If app_labels is specified, filter out conflicting migrations for unspecified apps
+        if app_labels:
+            conflicts = {
+                app_label: conflict for app_label, conflict in conflicts.items()
+                if app_label in app_labels
+            }
+
+        if conflicts and not self.merge:
+            name_str = "; ".join(
+                "%s in %s" % (", ".join(names), app)
+                for app, names in conflicts.items()
+            )
+            raise CommandError(
+                "Conflicting migrations detected; multiple leaf nodes in the "
+                "migration graph: (%s).\nTo fix them run "
+                "'python manage.py makemigrations --merge'" % name_str
+            )
+
+        # If they want to merge and there's nothing to merge, then politely exit
+        if self.merge and not conflicts:
+            self.stdout.write("No conflicts detected to merge.")
+            return
+
+        # If they want to merge and there is something to merge, then
+        # divert into the merge code
+        if self.merge and conflicts:
+            return self.handle_merge(loader, conflicts)
+
+        if self.interactive:
+            questioner = InteractiveMigrationQuestioner(specified_apps=app_labels, dry_run=self.dry_run)
+        else:
+            questioner = NonInteractiveMigrationQuestioner(specified_apps=app_labels, dry_run=self.dry_run)
+        # Set up autodetector
+        autodetector = MigrationAutodetector(
+            loader.project_state(),
+            ProjectState.from_apps(apps),
+            questioner,
+        )
+
+        # If they want to make an empty migration, make one for each app
+        if self.empty:
+            if not app_labels:
+                raise CommandError("You must supply at least one app label when using --empty.")
+            # Make a fake changes() result we can pass to arrange_for_graph
+            changes = {
+                app: [Migration("custom", app)]
+                for app in app_labels
+            }
+            changes = autodetector.arrange_for_graph(
+                changes=changes,
+                graph=loader.graph,
+                migration_name=self.migration_name,
+            )
+            self.write_migration_files(changes)
+            return
+
+        # Detect changes
+        changes = autodetector.changes(
+            graph=loader.graph,
+            trim_to_apps=app_labels or None,
+            convert_apps=app_labels or None,
+            migration_name=self.migration_name,
+        )
+
+        if not changes:
+            # No changes? Tell them.
+            if self.verbosity >= 1:
+                if app_labels:
+                    if len(app_labels) == 1:
+                        self.stdout.write("No changes detected in app '%s'" % app_labels.pop())
+                    else:
+                        self.stdout.write("No changes detected in apps '%s'" % ("', '".join(app_labels)))
+                else:
+                    self.stdout.write("No changes detected")
+        else:
+            self.write_migration_files(changes)
+            if check_changes:
+                sys.exit(1)
+
+    def write_migration_files(self, changes):
+        """
+        Take a changes dict and write them out as migration files.
+        """
+        directory_created = {}
+        for app_label, app_migrations in changes.items():
+            if self.verbosity >= 1:
+                self.stdout.write(self.style.MIGRATE_HEADING("Migrations for '%s':" % app_label))
+            for migration in app_migrations:
+                # Describe the migration
+                writer = MigrationWriter(migration, self.include_header)
+                if self.verbosity >= 1:
+                    # Display a relative path if it's below the current working
+                    # directory, or an absolute path otherwise.
+                    try:
+                        migration_string = os.path.relpath(writer.path)
+                    except ValueError:
+                        migration_string = writer.path
+                    if migration_string.startswith('..'):
+                        migration_string = writer.path
+                    self.stdout.write('  %s\n' % self.style.MIGRATE_LABEL(migration_string))
+                    for operation in migration.operations:
+                        self.stdout.write('    - %s' % operation.describe())
+                if not self.dry_run:
+                    # Write the migrations file to the disk.
+                    migrations_directory = os.path.dirname(writer.path)
+                    if not directory_created.get(app_label):
+                        os.makedirs(migrations_directory, exist_ok=True)
+                        init_path = os.path.join(migrations_directory, "__init__.py")
+                        if not os.path.isfile(init_path):
+                            open(init_path, "w").close()
+                        # We just do this once per app
+                        directory_created[app_label] = True
+                    migration_string = writer.as_string()
+                    with open(writer.path, "w", encoding='utf-8') as fh:
+                        fh.write(migration_string)
+                elif self.verbosity == 3:
+                    # Alternatively, makemigrations --dry-run --verbosity 3
+                    # will output the migrations to stdout rather than saving
+                    # the file to the disk.
+                    self.stdout.write(self.style.MIGRATE_HEADING(
+                        "Full migrations file '%s':" % writer.filename
+                    ))
+                    self.stdout.write(writer.as_string())
+
+    def handle_merge(self, loader, conflicts):
+        """
+        Handles merging together conflicted migrations interactively,
+        if it's safe; otherwise, advises on how to fix it.
+        """
+        if self.interactive:
+            questioner = InteractiveMigrationQuestioner()
+        else:
+            questioner = MigrationQuestioner(defaults={'ask_merge': True})
+
+        for app_label, migration_names in conflicts.items():
+            # Grab out the migrations in question, and work out their
+            # common ancestor.
+            merge_migrations = []
+            for migration_name in migration_names:
+                migration = loader.get_migration(app_label, migration_name)
+                migration.ancestry = [
+                    mig for mig in loader.graph.forwards_plan((app_label, migration_name))
+                    if mig[0] == migration.app_label
+                ]
+                merge_migrations.append(migration)
+
+            def all_items_equal(seq):
+                return all(item == seq[0] for item in seq[1:])
+
+            merge_migrations_generations = zip(*(m.ancestry for m in merge_migrations))
+            common_ancestor_count = sum(1 for common_ancestor_generation
+                                        in takewhile(all_items_equal, merge_migrations_generations))
+            if not common_ancestor_count:
+                raise ValueError("Could not find common ancestor of %s" % migration_names)
+            # Now work out the operations along each divergent branch
+            for migration in merge_migrations:
+                migration.branch = migration.ancestry[common_ancestor_count:]
+                migrations_ops = (loader.get_migration(node_app, node_name).operations
+                                  for node_app, node_name in migration.branch)
+                migration.merged_operations = sum(migrations_ops, [])
+            # In future, this could use some of the Optimizer code
+            # (can_optimize_through) to automatically see if they're
+            # mergeable. For now, we always just prompt the user.
+            if self.verbosity > 0:
+                self.stdout.write(self.style.MIGRATE_HEADING("Merging %s" % app_label))
+                for migration in merge_migrations:
+                    self.stdout.write(self.style.MIGRATE_LABEL("  Branch %s" % migration.name))
+                    for operation in migration.merged_operations:
+                        self.stdout.write('    - %s' % operation.describe())
+            if questioner.ask_merge(app_label):
+                # If they still want to merge it, then write out an empty
+                # file depending on the migrations needing merging.
+                numbers = [
+                    MigrationAutodetector.parse_number(migration.name)
+                    for migration in merge_migrations
+                ]
+                try:
+                    biggest_number = max(x for x in numbers if x is not None)
+                except ValueError:
+                    biggest_number = 1
+                subclass = type("Migration", (Migration,), {
+                    "dependencies": [(app_label, migration.name) for migration in merge_migrations],
+                })
+                migration_name = "%04i_%s" % (
+                    biggest_number + 1,
+                    self.migration_name or ("merge_%s" % get_migration_name_timestamp())
+                )
+                new_migration = subclass(migration_name, app_label)
+                writer = MigrationWriter(new_migration, self.include_header)
+
+                if not self.dry_run:
+                    # Write the merge migrations file to the disk
+                    with open(writer.path, "w", encoding='utf-8') as fh:
+                        fh.write(writer.as_string())
+                    if self.verbosity > 0:
+                        self.stdout.write("\nCreated new merge migration %s" % writer.path)
+                elif self.verbosity == 3:
+                    # Alternatively, makemigrations --merge --dry-run --verbosity 3
+                    # will output the merge migrations to stdout rather than saving
+                    # the file to the disk.
+                    self.stdout.write(self.style.MIGRATE_HEADING(
+                        "Full merge migrations file '%s':" % writer.filename
+                    ))
+                    self.stdout.write(writer.as_string())
Index: venv/Lib/site-packages/django/core/management/commands/migrate.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/core/management/commands/migrate.py b/venv/Lib/site-packages/django/core/management/commands/migrate.py
new file mode 100644
--- /dev/null	(date 1617030485659)
+++ b/venv/Lib/site-packages/django/core/management/commands/migrate.py	(date 1617030485659)
@@ -0,0 +1,376 @@
+import sys
+import time
+from importlib import import_module
+
+from django.apps import apps
+from django.core.management.base import (
+    BaseCommand, CommandError, no_translations,
+)
+from django.core.management.sql import (
+    emit_post_migrate_signal, emit_pre_migrate_signal,
+)
+from django.db import DEFAULT_DB_ALIAS, connections, router
+from django.db.migrations.autodetector import MigrationAutodetector
+from django.db.migrations.executor import MigrationExecutor
+from django.db.migrations.loader import AmbiguityError
+from django.db.migrations.state import ModelState, ProjectState
+from django.utils.module_loading import module_has_submodule
+from django.utils.text import Truncator
+
+
+class Command(BaseCommand):
+    help = "Updates database schema. Manages both apps with migrations and those without."
+    requires_system_checks = False
+
+    def add_arguments(self, parser):
+        parser.add_argument(
+            '--skip-checks', action='store_true',
+            help='Skip system checks.',
+        )
+        parser.add_argument(
+            'app_label', nargs='?',
+            help='App label of an application to synchronize the state.',
+        )
+        parser.add_argument(
+            'migration_name', nargs='?',
+            help='Database state will be brought to the state after that '
+                 'migration. Use the name "zero" to unapply all migrations.',
+        )
+        parser.add_argument(
+            '--noinput', '--no-input', action='store_false', dest='interactive',
+            help='Tells Django to NOT prompt the user for input of any kind.',
+        )
+        parser.add_argument(
+            '--database',
+            default=DEFAULT_DB_ALIAS,
+            help='Nominates a database to synchronize. Defaults to the "default" database.',
+        )
+        parser.add_argument(
+            '--fake', action='store_true',
+            help='Mark migrations as run without actually running them.',
+        )
+        parser.add_argument(
+            '--fake-initial', action='store_true',
+            help='Detect if tables already exist and fake-apply initial migrations if so. Make sure '
+                 'that the current database schema matches your initial migration before using this '
+                 'flag. Django will only check for an existing table name.',
+        )
+        parser.add_argument(
+            '--plan', action='store_true',
+            help='Shows a list of the migration actions that will be performed.',
+        )
+        parser.add_argument(
+            '--run-syncdb', action='store_true',
+            help='Creates tables for apps without migrations.',
+        )
+        parser.add_argument(
+            '--check', action='store_true', dest='check_unapplied',
+            help='Exits with a non-zero status if unapplied migrations exist.',
+        )
+
+    @no_translations
+    def handle(self, *args, **options):
+        database = options['database']
+        if not options['skip_checks']:
+            self.check(databases=[database])
+
+        self.verbosity = options['verbosity']
+        self.interactive = options['interactive']
+
+        # Import the 'management' module within each installed app, to register
+        # dispatcher events.
+        for app_config in apps.get_app_configs():
+            if module_has_submodule(app_config.module, "management"):
+                import_module('.management', app_config.name)
+
+        # Get the database we're operating from
+        connection = connections[database]
+
+        # Hook for backends needing any database preparation
+        connection.prepare_database()
+        # Work out which apps have migrations and which do not
+        executor = MigrationExecutor(connection, self.migration_progress_callback)
+
+        # Raise an error if any migrations are applied before their dependencies.
+        executor.loader.check_consistent_history(connection)
+
+        # Before anything else, see if there's conflicting apps and drop out
+        # hard if there are any
+        conflicts = executor.loader.detect_conflicts()
+        if conflicts:
+            name_str = "; ".join(
+                "%s in %s" % (", ".join(names), app)
+                for app, names in conflicts.items()
+            )
+            raise CommandError(
+                "Conflicting migrations detected; multiple leaf nodes in the "
+                "migration graph: (%s).\nTo fix them run "
+                "'python manage.py makemigrations --merge'" % name_str
+            )
+
+        # If they supplied command line arguments, work out what they mean.
+        run_syncdb = options['run_syncdb']
+        target_app_labels_only = True
+        if options['app_label']:
+            # Validate app_label.
+            app_label = options['app_label']
+            try:
+                apps.get_app_config(app_label)
+            except LookupError as err:
+                raise CommandError(str(err))
+            if run_syncdb:
+                if app_label in executor.loader.migrated_apps:
+                    raise CommandError("Can't use run_syncdb with app '%s' as it has migrations." % app_label)
+            elif app_label not in executor.loader.migrated_apps:
+                raise CommandError("App '%s' does not have migrations." % app_label)
+
+        if options['app_label'] and options['migration_name']:
+            migration_name = options['migration_name']
+            if migration_name == "zero":
+                targets = [(app_label, None)]
+            else:
+                try:
+                    migration = executor.loader.get_migration_by_prefix(app_label, migration_name)
+                except AmbiguityError:
+                    raise CommandError(
+                        "More than one migration matches '%s' in app '%s'. "
+                        "Please be more specific." %
+                        (migration_name, app_label)
+                    )
+                except KeyError:
+                    raise CommandError("Cannot find a migration matching '%s' from app '%s'." % (
+                        migration_name, app_label))
+                targets = [(app_label, migration.name)]
+            target_app_labels_only = False
+        elif options['app_label']:
+            targets = [key for key in executor.loader.graph.leaf_nodes() if key[0] == app_label]
+        else:
+            targets = executor.loader.graph.leaf_nodes()
+
+        plan = executor.migration_plan(targets)
+        exit_dry = plan and options['check_unapplied']
+
+        if options['plan']:
+            self.stdout.write('Planned operations:', self.style.MIGRATE_LABEL)
+            if not plan:
+                self.stdout.write('  No planned migration operations.')
+            for migration, backwards in plan:
+                self.stdout.write(str(migration), self.style.MIGRATE_HEADING)
+                for operation in migration.operations:
+                    message, is_error = self.describe_operation(operation, backwards)
+                    style = self.style.WARNING if is_error else None
+                    self.stdout.write('    ' + message, style)
+            if exit_dry:
+                sys.exit(1)
+            return
+        if exit_dry:
+            sys.exit(1)
+
+        # At this point, ignore run_syncdb if there aren't any apps to sync.
+        run_syncdb = options['run_syncdb'] and executor.loader.unmigrated_apps
+        # Print some useful info
+        if self.verbosity >= 1:
+            self.stdout.write(self.style.MIGRATE_HEADING("Operations to perform:"))
+            if run_syncdb:
+                if options['app_label']:
+                    self.stdout.write(
+                        self.style.MIGRATE_LABEL("  Synchronize unmigrated app: %s" % app_label)
+                    )
+                else:
+                    self.stdout.write(
+                        self.style.MIGRATE_LABEL("  Synchronize unmigrated apps: ") +
+                        (", ".join(sorted(executor.loader.unmigrated_apps)))
+                    )
+            if target_app_labels_only:
+                self.stdout.write(
+                    self.style.MIGRATE_LABEL("  Apply all migrations: ") +
+                    (", ".join(sorted({a for a, n in targets})) or "(none)")
+                )
+            else:
+                if targets[0][1] is None:
+                    self.stdout.write(
+                        self.style.MIGRATE_LABEL('  Unapply all migrations: ') +
+                        str(targets[0][0])
+                    )
+                else:
+                    self.stdout.write(self.style.MIGRATE_LABEL(
+                        "  Target specific migration: ") + "%s, from %s"
+                        % (targets[0][1], targets[0][0])
+                    )
+
+        pre_migrate_state = executor._create_project_state(with_applied_migrations=True)
+        pre_migrate_apps = pre_migrate_state.apps
+        emit_pre_migrate_signal(
+            self.verbosity, self.interactive, connection.alias, apps=pre_migrate_apps, plan=plan,
+        )
+
+        # Run the syncdb phase.
+        if run_syncdb:
+            if self.verbosity >= 1:
+                self.stdout.write(self.style.MIGRATE_HEADING("Synchronizing apps without migrations:"))
+            if options['app_label']:
+                self.sync_apps(connection, [app_label])
+            else:
+                self.sync_apps(connection, executor.loader.unmigrated_apps)
+
+        # Migrate!
+        if self.verbosity >= 1:
+            self.stdout.write(self.style.MIGRATE_HEADING("Running migrations:"))
+        if not plan:
+            if self.verbosity >= 1:
+                self.stdout.write("  No migrations to apply.")
+                # If there's changes that aren't in migrations yet, tell them how to fix it.
+                autodetector = MigrationAutodetector(
+                    executor.loader.project_state(),
+                    ProjectState.from_apps(apps),
+                )
+                changes = autodetector.changes(graph=executor.loader.graph)
+                if changes:
+                    self.stdout.write(self.style.NOTICE(
+                        "  Your models have changes that are not yet reflected "
+                        "in a migration, and so won't be applied."
+                    ))
+                    self.stdout.write(self.style.NOTICE(
+                        "  Run 'manage.py makemigrations' to make new "
+                        "migrations, and then re-run 'manage.py migrate' to "
+                        "apply them."
+                    ))
+            fake = False
+            fake_initial = False
+        else:
+            fake = options['fake']
+            fake_initial = options['fake_initial']
+        post_migrate_state = executor.migrate(
+            targets, plan=plan, state=pre_migrate_state.clone(), fake=fake,
+            fake_initial=fake_initial,
+        )
+        # post_migrate signals have access to all models. Ensure that all models
+        # are reloaded in case any are delayed.
+        post_migrate_state.clear_delayed_apps_cache()
+        post_migrate_apps = post_migrate_state.apps
+
+        # Re-render models of real apps to include relationships now that
+        # we've got a final state. This wouldn't be necessary if real apps
+        # models were rendered with relationships in the first place.
+        with post_migrate_apps.bulk_update():
+            model_keys = []
+            for model_state in post_migrate_apps.real_models:
+                model_key = model_state.app_label, model_state.name_lower
+                model_keys.append(model_key)
+                post_migrate_apps.unregister_model(*model_key)
+        post_migrate_apps.render_multiple([
+            ModelState.from_model(apps.get_model(*model)) for model in model_keys
+        ])
+
+        # Send the post_migrate signal, so individual apps can do whatever they need
+        # to do at this point.
+        emit_post_migrate_signal(
+            self.verbosity, self.interactive, connection.alias, apps=post_migrate_apps, plan=plan,
+        )
+
+    def migration_progress_callback(self, action, migration=None, fake=False):
+        if self.verbosity >= 1:
+            compute_time = self.verbosity > 1
+            if action == "apply_start":
+                if compute_time:
+                    self.start = time.monotonic()
+                self.stdout.write("  Applying %s..." % migration, ending="")
+                self.stdout.flush()
+            elif action == "apply_success":
+                elapsed = " (%.3fs)" % (time.monotonic() - self.start) if compute_time else ""
+                if fake:
+                    self.stdout.write(self.style.SUCCESS(" FAKED" + elapsed))
+                else:
+                    self.stdout.write(self.style.SUCCESS(" OK" + elapsed))
+            elif action == "unapply_start":
+                if compute_time:
+                    self.start = time.monotonic()
+                self.stdout.write("  Unapplying %s..." % migration, ending="")
+                self.stdout.flush()
+            elif action == "unapply_success":
+                elapsed = " (%.3fs)" % (time.monotonic() - self.start) if compute_time else ""
+                if fake:
+                    self.stdout.write(self.style.SUCCESS(" FAKED" + elapsed))
+                else:
+                    self.stdout.write(self.style.SUCCESS(" OK" + elapsed))
+            elif action == "render_start":
+                if compute_time:
+                    self.start = time.monotonic()
+                self.stdout.write("  Rendering model states...", ending="")
+                self.stdout.flush()
+            elif action == "render_success":
+                elapsed = " (%.3fs)" % (time.monotonic() - self.start) if compute_time else ""
+                self.stdout.write(self.style.SUCCESS(" DONE" + elapsed))
+
+    def sync_apps(self, connection, app_labels):
+        """Run the old syncdb-style operation on a list of app_labels."""
+        with connection.cursor() as cursor:
+            tables = connection.introspection.table_names(cursor)
+
+        # Build the manifest of apps and models that are to be synchronized.
+        all_models = [
+            (
+                app_config.label,
+                router.get_migratable_models(app_config, connection.alias, include_auto_created=False),
+            )
+            for app_config in apps.get_app_configs()
+            if app_config.models_module is not None and app_config.label in app_labels
+        ]
+
+        def model_installed(model):
+            opts = model._meta
+            converter = connection.introspection.identifier_converter
+            return not (
+                (converter(opts.db_table) in tables) or
+                (opts.auto_created and converter(opts.auto_created._meta.db_table) in tables)
+            )
+
+        manifest = {
+            app_name: list(filter(model_installed, model_list))
+            for app_name, model_list in all_models
+        }
+
+        # Create the tables for each model
+        if self.verbosity >= 1:
+            self.stdout.write('  Creating tables...')
+        with connection.schema_editor() as editor:
+            for app_name, model_list in manifest.items():
+                for model in model_list:
+                    # Never install unmanaged models, etc.
+                    if not model._meta.can_migrate(connection):
+                        continue
+                    if self.verbosity >= 3:
+                        self.stdout.write(
+                            '    Processing %s.%s model' % (app_name, model._meta.object_name)
+                        )
+                    if self.verbosity >= 1:
+                        self.stdout.write('    Creating table %s' % model._meta.db_table)
+                    editor.create_model(model)
+
+            # Deferred SQL is executed when exiting the editor's context.
+            if self.verbosity >= 1:
+                self.stdout.write('    Running deferred SQL...')
+
+    @staticmethod
+    def describe_operation(operation, backwards):
+        """Return a string that describes a migration operation for --plan."""
+        prefix = ''
+        is_error = False
+        if hasattr(operation, 'code'):
+            code = operation.reverse_code if backwards else operation.code
+            action = (code.__doc__ or '') if code else None
+        elif hasattr(operation, 'sql'):
+            action = operation.reverse_sql if backwards else operation.sql
+        else:
+            action = ''
+            if backwards:
+                prefix = 'Undo '
+        if action is not None:
+            action = str(action).replace('\n', '')
+        elif backwards:
+            action = 'IRREVERSIBLE'
+            is_error = True
+        if action:
+            action = ' -> ' + action
+        truncated = Truncator(action)
+        return prefix + operation.describe() + truncated.chars(40), is_error
Index: venv/Lib/site-packages/django/core/management/commands/runserver.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/core/management/commands/runserver.py b/venv/Lib/site-packages/django/core/management/commands/runserver.py
new file mode 100644
--- /dev/null	(date 1617030485660)
+++ b/venv/Lib/site-packages/django/core/management/commands/runserver.py	(date 1617030485660)
@@ -0,0 +1,158 @@
+import errno
+import os
+import re
+import socket
+import sys
+from datetime import datetime
+
+from django.conf import settings
+from django.core.management.base import BaseCommand, CommandError
+from django.core.servers.basehttp import (
+    WSGIServer, get_internal_wsgi_application, run,
+)
+from django.utils import autoreload
+from django.utils.regex_helper import _lazy_re_compile
+
+naiveip_re = _lazy_re_compile(r"""^(?:
+(?P<addr>
+    (?P<ipv4>\d{1,3}(?:\.\d{1,3}){3}) |         # IPv4 address
+    (?P<ipv6>\[[a-fA-F0-9:]+\]) |               # IPv6 address
+    (?P<fqdn>[a-zA-Z0-9-]+(?:\.[a-zA-Z0-9-]+)*) # FQDN
+):)?(?P<port>\d+)$""", re.X)
+
+
+class Command(BaseCommand):
+    help = "Starts a lightweight Web server for development."
+
+    # Validation is called explicitly each time the server is reloaded.
+    requires_system_checks = False
+    stealth_options = ('shutdown_message',)
+
+    default_addr = '127.0.0.1'
+    default_addr_ipv6 = '::1'
+    default_port = '8000'
+    protocol = 'http'
+    server_cls = WSGIServer
+
+    def add_arguments(self, parser):
+        parser.add_argument(
+            'addrport', nargs='?',
+            help='Optional port number, or ipaddr:port'
+        )
+        parser.add_argument(
+            '--ipv6', '-6', action='store_true', dest='use_ipv6',
+            help='Tells Django to use an IPv6 address.',
+        )
+        parser.add_argument(
+            '--nothreading', action='store_false', dest='use_threading',
+            help='Tells Django to NOT use threading.',
+        )
+        parser.add_argument(
+            '--noreload', action='store_false', dest='use_reloader',
+            help='Tells Django to NOT use the auto-reloader.',
+        )
+
+    def execute(self, *args, **options):
+        if options['no_color']:
+            # We rely on the environment because it's currently the only
+            # way to reach WSGIRequestHandler. This seems an acceptable
+            # compromise considering `runserver` runs indefinitely.
+            os.environ["DJANGO_COLORS"] = "nocolor"
+        super().execute(*args, **options)
+
+    def get_handler(self, *args, **options):
+        """Return the default WSGI handler for the runner."""
+        return get_internal_wsgi_application()
+
+    def handle(self, *args, **options):
+        if not settings.DEBUG and not settings.ALLOWED_HOSTS:
+            raise CommandError('You must set settings.ALLOWED_HOSTS if DEBUG is False.')
+
+        self.use_ipv6 = options['use_ipv6']
+        if self.use_ipv6 and not socket.has_ipv6:
+            raise CommandError('Your Python does not support IPv6.')
+        self._raw_ipv6 = False
+        if not options['addrport']:
+            self.addr = ''
+            self.port = self.default_port
+        else:
+            m = re.match(naiveip_re, options['addrport'])
+            if m is None:
+                raise CommandError('"%s" is not a valid port number '
+                                   'or address:port pair.' % options['addrport'])
+            self.addr, _ipv4, _ipv6, _fqdn, self.port = m.groups()
+            if not self.port.isdigit():
+                raise CommandError("%r is not a valid port number." % self.port)
+            if self.addr:
+                if _ipv6:
+                    self.addr = self.addr[1:-1]
+                    self.use_ipv6 = True
+                    self._raw_ipv6 = True
+                elif self.use_ipv6 and not _fqdn:
+                    raise CommandError('"%s" is not a valid IPv6 address.' % self.addr)
+        if not self.addr:
+            self.addr = self.default_addr_ipv6 if self.use_ipv6 else self.default_addr
+            self._raw_ipv6 = self.use_ipv6
+        self.run(**options)
+
+    def run(self, **options):
+        """Run the server, using the autoreloader if needed."""
+        use_reloader = options['use_reloader']
+
+        if use_reloader:
+            autoreload.run_with_reloader(self.inner_run, **options)
+        else:
+            self.inner_run(None, **options)
+
+    def inner_run(self, *args, **options):
+        # If an exception was silenced in ManagementUtility.execute in order
+        # to be raised in the child process, raise it now.
+        autoreload.raise_last_exception()
+
+        threading = options['use_threading']
+        # 'shutdown_message' is a stealth option.
+        shutdown_message = options.get('shutdown_message', '')
+        quit_command = 'CTRL-BREAK' if sys.platform == 'win32' else 'CONTROL-C'
+
+        self.stdout.write("Performing system checks...\n\n")
+        self.check(display_num_errors=True)
+        # Need to check migrations here, so can't use the
+        # requires_migrations_check attribute.
+        self.check_migrations()
+        now = datetime.now().strftime('%B %d, %Y - %X')
+        self.stdout.write(now)
+        self.stdout.write((
+            "Django version %(version)s, using settings %(settings)r\n"
+            "Starting development server at %(protocol)s://%(addr)s:%(port)s/\n"
+            "Quit the server with %(quit_command)s."
+        ) % {
+            "version": self.get_version(),
+            "settings": settings.SETTINGS_MODULE,
+            "protocol": self.protocol,
+            "addr": '[%s]' % self.addr if self._raw_ipv6 else self.addr,
+            "port": self.port,
+            "quit_command": quit_command,
+        })
+
+        try:
+            handler = self.get_handler(*args, **options)
+            run(self.addr, int(self.port), handler,
+                ipv6=self.use_ipv6, threading=threading, server_cls=self.server_cls)
+        except OSError as e:
+            # Use helpful error messages instead of ugly tracebacks.
+            ERRORS = {
+                errno.EACCES: "You don't have permission to access that port.",
+                errno.EADDRINUSE: "That port is already in use.",
+                errno.EADDRNOTAVAIL: "That IP address can't be assigned to.",
+            }
+            try:
+                error_text = ERRORS[e.errno]
+            except KeyError:
+                error_text = e
+            self.stderr.write("Error: %s" % error_text)
+            # Need to use an OS exit because sys.exit doesn't work in a thread
+            os._exit(1)
+        except KeyboardInterrupt:
+            if shutdown_message:
+                self.stdout.write(shutdown_message)
+            sys.exit(0)
Index: venv/Lib/site-packages/django/core/management/commands/sendtestemail.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/core/management/commands/sendtestemail.py b/venv/Lib/site-packages/django/core/management/commands/sendtestemail.py
new file mode 100644
--- /dev/null	(date 1617030485660)
+++ b/venv/Lib/site-packages/django/core/management/commands/sendtestemail.py	(date 1617030485660)
@@ -0,0 +1,40 @@
+import socket
+
+from django.core.mail import mail_admins, mail_managers, send_mail
+from django.core.management.base import BaseCommand
+from django.utils import timezone
+
+
+class Command(BaseCommand):
+    help = "Sends a test email to the email addresses specified as arguments."
+    missing_args_message = "You must specify some email recipients, or pass the --managers or --admin options."
+
+    def add_arguments(self, parser):
+        parser.add_argument(
+            'email', nargs='*',
+            help='One or more email addresses to send a test email to.',
+        )
+        parser.add_argument(
+            '--managers', action='store_true',
+            help='Send a test email to the addresses specified in settings.MANAGERS.',
+        )
+        parser.add_argument(
+            '--admins', action='store_true',
+            help='Send a test email to the addresses specified in settings.ADMINS.',
+        )
+
+    def handle(self, *args, **kwargs):
+        subject = 'Test email from %s on %s' % (socket.gethostname(), timezone.now())
+
+        send_mail(
+            subject=subject,
+            message="If you\'re reading this, it was successful.",
+            from_email=None,
+            recipient_list=kwargs['email'],
+        )
+
+        if kwargs['managers']:
+            mail_managers(subject, "This email was sent to the site managers.")
+
+        if kwargs['admins']:
+            mail_admins(subject, "This email was sent to the site admins.")
Index: venv/Lib/site-packages/django/core/management/commands/shell.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/core/management/commands/shell.py b/venv/Lib/site-packages/django/core/management/commands/shell.py
new file mode 100644
--- /dev/null	(date 1617030485660)
+++ b/venv/Lib/site-packages/django/core/management/commands/shell.py	(date 1617030485660)
@@ -0,0 +1,103 @@
+import os
+import select
+import sys
+import traceback
+
+from django.core.management import BaseCommand, CommandError
+from django.utils.datastructures import OrderedSet
+
+
+class Command(BaseCommand):
+    help = (
+        "Runs a Python interactive interpreter. Tries to use IPython or "
+        "bpython, if one of them is available. Any standard input is executed "
+        "as code."
+    )
+
+    requires_system_checks = False
+    shells = ['ipython', 'bpython', 'python']
+
+    def add_arguments(self, parser):
+        parser.add_argument(
+            '--no-startup', action='store_true',
+            help='When using plain Python, ignore the PYTHONSTARTUP environment variable and ~/.pythonrc.py script.',
+        )
+        parser.add_argument(
+            '-i', '--interface', choices=self.shells,
+            help='Specify an interactive interpreter interface. Available options: "ipython", "bpython", and "python"',
+        )
+        parser.add_argument(
+            '-c', '--command',
+            help='Instead of opening an interactive shell, run a command as Django and exit.',
+        )
+
+    def ipython(self, options):
+        from IPython import start_ipython
+        start_ipython(argv=[])
+
+    def bpython(self, options):
+        import bpython
+        bpython.embed()
+
+    def python(self, options):
+        import code
+
+        # Set up a dictionary to serve as the environment for the shell, so
+        # that tab completion works on objects that are imported at runtime.
+        imported_objects = {}
+        try:  # Try activating rlcompleter, because it's handy.
+            import readline
+        except ImportError:
+            pass
+        else:
+            # We don't have to wrap the following import in a 'try', because
+            # we already know 'readline' was imported successfully.
+            import rlcompleter
+            readline.set_completer(rlcompleter.Completer(imported_objects).complete)
+            # Enable tab completion on systems using libedit (e.g. macOS).
+            # These lines are copied from Python's Lib/site.py.
+            readline_doc = getattr(readline, '__doc__', '')
+            if readline_doc is not None and 'libedit' in readline_doc:
+                readline.parse_and_bind("bind ^I rl_complete")
+            else:
+                readline.parse_and_bind("tab:complete")
+
+        # We want to honor both $PYTHONSTARTUP and .pythonrc.py, so follow system
+        # conventions and get $PYTHONSTARTUP first then .pythonrc.py.
+        if not options['no_startup']:
+            for pythonrc in OrderedSet([os.environ.get("PYTHONSTARTUP"), os.path.expanduser('~/.pythonrc.py')]):
+                if not pythonrc:
+                    continue
+                if not os.path.isfile(pythonrc):
+                    continue
+                with open(pythonrc) as handle:
+                    pythonrc_code = handle.read()
+                # Match the behavior of the cpython shell where an error in
+                # PYTHONSTARTUP prints an exception and continues.
+                try:
+                    exec(compile(pythonrc_code, pythonrc, 'exec'), imported_objects)
+                except Exception:
+                    traceback.print_exc()
+
+        code.interact(local=imported_objects)
+
+    def handle(self, **options):
+        # Execute the command and exit.
+        if options['command']:
+            exec(options['command'])
+            return
+
+        # Execute stdin if it has anything to read and exit.
+        # Not supported on Windows due to select.select() limitations.
+        if sys.platform != 'win32' and not sys.stdin.isatty() and select.select([sys.stdin], [], [], 0)[0]:
+            exec(sys.stdin.read())
+            return
+
+        available_shells = [options['interface']] if options['interface'] else self.shells
+
+        for shell in available_shells:
+            try:
+                return getattr(self, shell)(options)
+            except ImportError:
+                pass
+        raise CommandError("Couldn't import {} interface.".format(shell))
Index: venv/Lib/site-packages/django/core/management/commands/showmigrations.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/core/management/commands/showmigrations.py b/venv/Lib/site-packages/django/core/management/commands/showmigrations.py
new file mode 100644
--- /dev/null	(date 1617030485661)
+++ b/venv/Lib/site-packages/django/core/management/commands/showmigrations.py	(date 1617030485661)
@@ -0,0 +1,147 @@
+import sys
+
+from django.apps import apps
+from django.core.management.base import BaseCommand
+from django.db import DEFAULT_DB_ALIAS, connections
+from django.db.migrations.loader import MigrationLoader
+
+
+class Command(BaseCommand):
+    help = "Shows all available migrations for the current project"
+
+    def add_arguments(self, parser):
+        parser.add_argument(
+            'app_label', nargs='*',
+            help='App labels of applications to limit the output to.',
+        )
+        parser.add_argument(
+            '--database', default=DEFAULT_DB_ALIAS,
+            help='Nominates a database to synchronize. Defaults to the "default" database.',
+        )
+
+        formats = parser.add_mutually_exclusive_group()
+        formats.add_argument(
+            '--list', '-l', action='store_const', dest='format', const='list',
+            help=(
+                'Shows a list of all migrations and which are applied. '
+                'With a verbosity level of 2 or above, the applied datetimes '
+                'will be included.'
+            ),
+        )
+        formats.add_argument(
+            '--plan', '-p', action='store_const', dest='format', const='plan',
+            help=(
+                'Shows all migrations in the order they will be applied. '
+                'With a verbosity level of 2 or above all direct migration dependencies '
+                'and reverse dependencies (run_before) will be included.'
+            )
+        )
+
+        parser.set_defaults(format='list')
+
+    def handle(self, *args, **options):
+        self.verbosity = options['verbosity']
+
+        # Get the database we're operating from
+        db = options['database']
+        connection = connections[db]
+
+        if options['format'] == "plan":
+            return self.show_plan(connection, options['app_label'])
+        else:
+            return self.show_list(connection, options['app_label'])
+
+    def _validate_app_names(self, loader, app_names):
+        has_bad_names = False
+        for app_name in app_names:
+            try:
+                apps.get_app_config(app_name)
+            except LookupError as err:
+                self.stderr.write(str(err))
+                has_bad_names = True
+        if has_bad_names:
+            sys.exit(2)
+
+    def show_list(self, connection, app_names=None):
+        """
+        Show a list of all migrations on the system, or only those of
+        some named apps.
+        """
+        # Load migrations from disk/DB
+        loader = MigrationLoader(connection, ignore_no_migrations=True)
+        graph = loader.graph
+        # If we were passed a list of apps, validate it
+        if app_names:
+            self._validate_app_names(loader, app_names)
+        # Otherwise, show all apps in alphabetic order
+        else:
+            app_names = sorted(loader.migrated_apps)
+        # For each app, print its migrations in order from oldest (roots) to
+        # newest (leaves).
+        for app_name in app_names:
+            self.stdout.write(app_name, self.style.MIGRATE_LABEL)
+            shown = set()
+            for node in graph.leaf_nodes(app_name):
+                for plan_node in graph.forwards_plan(node):
+                    if plan_node not in shown and plan_node[0] == app_name:
+                        # Give it a nice title if it's a squashed one
+                        title = plan_node[1]
+                        if graph.nodes[plan_node].replaces:
+                            title += " (%s squashed migrations)" % len(graph.nodes[plan_node].replaces)
+                        applied_migration = loader.applied_migrations.get(plan_node)
+                        # Mark it as applied/unapplied
+                        if applied_migration:
+                            output = ' [X] %s' % title
+                            if self.verbosity >= 2:
+                                output += ' (applied at %s)' % applied_migration.applied.strftime('%Y-%m-%d %H:%M:%S')
+                            self.stdout.write(output)
+                        else:
+                            self.stdout.write(" [ ] %s" % title)
+                        shown.add(plan_node)
+            # If we didn't print anything, then a small message
+            if not shown:
+                self.stdout.write(" (no migrations)", self.style.ERROR)
+
+    def show_plan(self, connection, app_names=None):
+        """
+        Show all known migrations (or only those of the specified app_names)
+        in the order they will be applied.
+        """
+        # Load migrations from disk/DB
+        loader = MigrationLoader(connection)
+        graph = loader.graph
+        if app_names:
+            self._validate_app_names(loader, app_names)
+            targets = [key for key in graph.leaf_nodes() if key[0] in app_names]
+        else:
+            targets = graph.leaf_nodes()
+        plan = []
+        seen = set()
+
+        # Generate the plan
+        for target in targets:
+            for migration in graph.forwards_plan(target):
+                if migration not in seen:
+                    node = graph.node_map[migration]
+                    plan.append(node)
+                    seen.add(migration)
+
+        # Output
+        def print_deps(node):
+            out = []
+            for parent in sorted(node.parents):
+                out.append("%s.%s" % parent.key)
+            if out:
+                return " ... (%s)" % ", ".join(out)
+            return ""
+
+        for node in plan:
+            deps = ""
+            if self.verbosity >= 2:
+                deps = print_deps(node)
+            if node.key in loader.applied_migrations:
+                self.stdout.write("[X]  %s.%s%s" % (node.key[0], node.key[1], deps))
+            else:
+                self.stdout.write("[ ]  %s.%s%s" % (node.key[0], node.key[1], deps))
+        if not plan:
+            self.stdout.write('(no migrations)', self.style.ERROR)
Index: venv/Lib/site-packages/django/core/management/commands/sqlflush.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/core/management/commands/sqlflush.py b/venv/Lib/site-packages/django/core/management/commands/sqlflush.py
new file mode 100644
--- /dev/null	(date 1617030485661)
+++ b/venv/Lib/site-packages/django/core/management/commands/sqlflush.py	(date 1617030485661)
@@ -0,0 +1,25 @@
+from django.core.management.base import BaseCommand
+from django.core.management.sql import sql_flush
+from django.db import DEFAULT_DB_ALIAS, connections
+
+
+class Command(BaseCommand):
+    help = (
+        "Returns a list of the SQL statements required to return all tables in "
+        "the database to the state they were in just after they were installed."
+    )
+
+    output_transaction = True
+
+    def add_arguments(self, parser):
+        super().add_arguments(parser)
+        parser.add_argument(
+            '--database', default=DEFAULT_DB_ALIAS,
+            help='Nominates a database to print the SQL for. Defaults to the "default" database.',
+        )
+
+    def handle(self, **options):
+        sql_statements = sql_flush(self.style, connections[options['database']], only_django=True)
+        if not sql_statements and options['verbosity'] >= 1:
+            self.stderr.write('No tables found.')
+        return '\n'.join(sql_statements)
Index: venv/Lib/site-packages/django/core/management/commands/sqlmigrate.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/core/management/commands/sqlmigrate.py b/venv/Lib/site-packages/django/core/management/commands/sqlmigrate.py
new file mode 100644
--- /dev/null	(date 1617030485661)
+++ b/venv/Lib/site-packages/django/core/management/commands/sqlmigrate.py	(date 1617030485661)
@@ -0,0 +1,68 @@
+from django.apps import apps
+from django.core.management.base import BaseCommand, CommandError
+from django.db import DEFAULT_DB_ALIAS, connections
+from django.db.migrations.loader import AmbiguityError, MigrationLoader
+
+
+class Command(BaseCommand):
+    help = "Prints the SQL statements for the named migration."
+
+    output_transaction = True
+
+    def add_arguments(self, parser):
+        parser.add_argument('app_label', help='App label of the application containing the migration.')
+        parser.add_argument('migration_name', help='Migration name to print the SQL for.')
+        parser.add_argument(
+            '--database', default=DEFAULT_DB_ALIAS,
+            help='Nominates a database to create SQL for. Defaults to the "default" database.',
+        )
+        parser.add_argument(
+            '--backwards', action='store_true',
+            help='Creates SQL to unapply the migration, rather than to apply it',
+        )
+
+    def execute(self, *args, **options):
+        # sqlmigrate doesn't support coloring its output but we need to force
+        # no_color=True so that the BEGIN/COMMIT statements added by
+        # output_transaction don't get colored either.
+        options['no_color'] = True
+        return super().execute(*args, **options)
+
+    def handle(self, *args, **options):
+        # Get the database we're operating from
+        connection = connections[options['database']]
+
+        # Load up an loader to get all the migration data, but don't replace
+        # migrations.
+        loader = MigrationLoader(connection, replace_migrations=False)
+
+        # Resolve command-line arguments into a migration
+        app_label, migration_name = options['app_label'], options['migration_name']
+        # Validate app_label
+        try:
+            apps.get_app_config(app_label)
+        except LookupError as err:
+            raise CommandError(str(err))
+        if app_label not in loader.migrated_apps:
+            raise CommandError("App '%s' does not have migrations" % app_label)
+        try:
+            migration = loader.get_migration_by_prefix(app_label, migration_name)
+        except AmbiguityError:
+            raise CommandError("More than one migration matches '%s' in app '%s'. Please be more specific." % (
+                migration_name, app_label))
+        except KeyError:
+            raise CommandError("Cannot find a migration matching '%s' from app '%s'. Is it in INSTALLED_APPS?" % (
+                migration_name, app_label))
+        target = (app_label, migration.name)
+
+        # Show begin/end around output for atomic migrations, if the database
+        # supports transactional DDL.
+        self.output_transaction = migration.atomic and connection.features.can_rollback_ddl
+
+        # Make a plan that represents just the requested migrations and show SQL
+        # for it
+        plan = [(loader.graph.nodes[target], options['backwards'])]
+        sql_statements = loader.collect_sql(plan)
+        if not sql_statements and options['verbosity'] >= 1:
+            self.stderr.write('No operations found.')
+        return '\n'.join(sql_statements)
Index: venv/Lib/site-packages/django/core/management/commands/sqlsequencereset.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/core/management/commands/sqlsequencereset.py b/venv/Lib/site-packages/django/core/management/commands/sqlsequencereset.py
new file mode 100644
--- /dev/null	(date 1617030485662)
+++ b/venv/Lib/site-packages/django/core/management/commands/sqlsequencereset.py	(date 1617030485662)
@@ -0,0 +1,25 @@
+from django.core.management.base import AppCommand
+from django.db import DEFAULT_DB_ALIAS, connections
+
+
+class Command(AppCommand):
+    help = 'Prints the SQL statements for resetting sequences for the given app name(s).'
+
+    output_transaction = True
+
+    def add_arguments(self, parser):
+        super().add_arguments(parser)
+        parser.add_argument(
+            '--database', default=DEFAULT_DB_ALIAS,
+            help='Nominates a database to print the SQL for. Defaults to the "default" database.',
+        )
+
+    def handle_app_config(self, app_config, **options):
+        if app_config.models_module is None:
+            return
+        connection = connections[options['database']]
+        models = app_config.get_models(include_auto_created=True)
+        statements = connection.ops.sequence_reset_sql(self.style, models)
+        if not statements and options['verbosity'] >= 1:
+            self.stderr.write('No sequences found.')
+        return '\n'.join(statements)
Index: venv/Lib/site-packages/django/core/management/commands/squashmigrations.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/core/management/commands/squashmigrations.py b/venv/Lib/site-packages/django/core/management/commands/squashmigrations.py
new file mode 100644
--- /dev/null	(date 1617030485662)
+++ b/venv/Lib/site-packages/django/core/management/commands/squashmigrations.py	(date 1617030485662)
@@ -0,0 +1,218 @@
+from django.apps import apps
+from django.conf import settings
+from django.core.management.base import BaseCommand, CommandError
+from django.db import DEFAULT_DB_ALIAS, connections, migrations
+from django.db.migrations.loader import AmbiguityError, MigrationLoader
+from django.db.migrations.migration import SwappableTuple
+from django.db.migrations.optimizer import MigrationOptimizer
+from django.db.migrations.writer import MigrationWriter
+from django.utils.version import get_docs_version
+
+
+class Command(BaseCommand):
+    help = "Squashes an existing set of migrations (from first until specified) into a single new one."
+
+    def add_arguments(self, parser):
+        parser.add_argument(
+            'app_label',
+            help='App label of the application to squash migrations for.',
+        )
+        parser.add_argument(
+            'start_migration_name', nargs='?',
+            help='Migrations will be squashed starting from and including this migration.',
+        )
+        parser.add_argument(
+            'migration_name',
+            help='Migrations will be squashed until and including this migration.',
+        )
+        parser.add_argument(
+            '--no-optimize', action='store_true',
+            help='Do not try to optimize the squashed operations.',
+        )
+        parser.add_argument(
+            '--noinput', '--no-input', action='store_false', dest='interactive',
+            help='Tells Django to NOT prompt the user for input of any kind.',
+        )
+        parser.add_argument(
+            '--squashed-name',
+            help='Sets the name of the new squashed migration.',
+        )
+        parser.add_argument(
+            '--no-header', action='store_false', dest='include_header',
+            help='Do not add a header comment to the new squashed migration.',
+        )
+
+    def handle(self, **options):
+
+        self.verbosity = options['verbosity']
+        self.interactive = options['interactive']
+        app_label = options['app_label']
+        start_migration_name = options['start_migration_name']
+        migration_name = options['migration_name']
+        no_optimize = options['no_optimize']
+        squashed_name = options['squashed_name']
+        include_header = options['include_header']
+        # Validate app_label.
+        try:
+            apps.get_app_config(app_label)
+        except LookupError as err:
+            raise CommandError(str(err))
+        # Load the current graph state, check the app and migration they asked for exists
+        loader = MigrationLoader(connections[DEFAULT_DB_ALIAS])
+        if app_label not in loader.migrated_apps:
+            raise CommandError(
+                "App '%s' does not have migrations (so squashmigrations on "
+                "it makes no sense)" % app_label
+            )
+
+        migration = self.find_migration(loader, app_label, migration_name)
+
+        # Work out the list of predecessor migrations
+        migrations_to_squash = [
+            loader.get_migration(al, mn)
+            for al, mn in loader.graph.forwards_plan((migration.app_label, migration.name))
+            if al == migration.app_label
+        ]
+
+        if start_migration_name:
+            start_migration = self.find_migration(loader, app_label, start_migration_name)
+            start = loader.get_migration(start_migration.app_label, start_migration.name)
+            try:
+                start_index = migrations_to_squash.index(start)
+                migrations_to_squash = migrations_to_squash[start_index:]
+            except ValueError:
+                raise CommandError(
+                    "The migration '%s' cannot be found. Maybe it comes after "
+                    "the migration '%s'?\n"
+                    "Have a look at:\n"
+                    "  python manage.py showmigrations %s\n"
+                    "to debug this issue." % (start_migration, migration, app_label)
+                )
+
+        # Tell them what we're doing and optionally ask if we should proceed
+        if self.verbosity > 0 or self.interactive:
+            self.stdout.write(self.style.MIGRATE_HEADING("Will squash the following migrations:"))
+            for migration in migrations_to_squash:
+                self.stdout.write(" - %s" % migration.name)
+
+            if self.interactive:
+                answer = None
+                while not answer or answer not in "yn":
+                    answer = input("Do you wish to proceed? [yN] ")
+                    if not answer:
+                        answer = "n"
+                        break
+                    else:
+                        answer = answer[0].lower()
+                if answer != "y":
+                    return
+
+        # Load the operations from all those migrations and concat together,
+        # along with collecting external dependencies and detecting
+        # double-squashing
+        operations = []
+        dependencies = set()
+        # We need to take all dependencies from the first migration in the list
+        # as it may be 0002 depending on 0001
+        first_migration = True
+        for smigration in migrations_to_squash:
+            if smigration.replaces:
+                raise CommandError(
+                    "You cannot squash squashed migrations! Please transition "
+                    "it to a normal migration first: "
+                    "https://docs.djangoproject.com/en/%s/topics/migrations/#squashing-migrations" % get_docs_version()
+                )
+            operations.extend(smigration.operations)
+            for dependency in smigration.dependencies:
+                if isinstance(dependency, SwappableTuple):
+                    if settings.AUTH_USER_MODEL == dependency.setting:
+                        dependencies.add(("__setting__", "AUTH_USER_MODEL"))
+                    else:
+                        dependencies.add(dependency)
+                elif dependency[0] != smigration.app_label or first_migration:
+                    dependencies.add(dependency)
+            first_migration = False
+
+        if no_optimize:
+            if self.verbosity > 0:
+                self.stdout.write(self.style.MIGRATE_HEADING("(Skipping optimization.)"))
+            new_operations = operations
+        else:
+            if self.verbosity > 0:
+                self.stdout.write(self.style.MIGRATE_HEADING("Optimizing..."))
+
+            optimizer = MigrationOptimizer()
+            new_operations = optimizer.optimize(operations, migration.app_label)
+
+            if self.verbosity > 0:
+                if len(new_operations) == len(operations):
+                    self.stdout.write("  No optimizations possible.")
+                else:
+                    self.stdout.write(
+                        "  Optimized from %s operations to %s operations." %
+                        (len(operations), len(new_operations))
+                    )
+
+        # Work out the value of replaces (any squashed ones we're re-squashing)
+        # need to feed their replaces into ours
+        replaces = []
+        for migration in migrations_to_squash:
+            if migration.replaces:
+                replaces.extend(migration.replaces)
+            else:
+                replaces.append((migration.app_label, migration.name))
+
+        # Make a new migration with those operations
+        subclass = type("Migration", (migrations.Migration,), {
+            "dependencies": dependencies,
+            "operations": new_operations,
+            "replaces": replaces,
+        })
+        if start_migration_name:
+            if squashed_name:
+                # Use the name from --squashed-name.
+                prefix, _ = start_migration.name.split('_', 1)
+                name = '%s_%s' % (prefix, squashed_name)
+            else:
+                # Generate a name.
+                name = '%s_squashed_%s' % (start_migration.name, migration.name)
+            new_migration = subclass(name, app_label)
+        else:
+            name = '0001_%s' % (squashed_name or 'squashed_%s' % migration.name)
+            new_migration = subclass(name, app_label)
+            new_migration.initial = True
+
+        # Write out the new migration file
+        writer = MigrationWriter(new_migration, include_header)
+        with open(writer.path, "w", encoding='utf-8') as fh:
+            fh.write(writer.as_string())
+
+        if self.verbosity > 0:
+            self.stdout.write(
+                self.style.MIGRATE_HEADING('Created new squashed migration %s' % writer.path) + '\n'
+                '  You should commit this migration but leave the old ones in place;\n'
+                '  the new migration will be used for new installs. Once you are sure\n'
+                '  all instances of the codebase have applied the migrations you squashed,\n'
+                '  you can delete them.'
+            )
+            if writer.needs_manual_porting:
+                self.stdout.write(
+                    self.style.MIGRATE_HEADING('Manual porting required') + '\n'
+                    '  Your migrations contained functions that must be manually copied over,\n'
+                    '  as we could not safely copy their implementation.\n'
+                    '  See the comment at the top of the squashed migration for details.'
+                )
+
+    def find_migration(self, loader, app_label, name):
+        try:
+            return loader.get_migration_by_prefix(app_label, name)
+        except AmbiguityError:
+            raise CommandError(
+                "More than one migration matches '%s' in app '%s'. Please be "
+                "more specific." % (name, app_label)
+            )
+        except KeyError:
+            raise CommandError(
+                "Cannot find a migration matching '%s' from app '%s'." %
+                (name, app_label)
+            )
Index: venv/Lib/site-packages/django/core/management/commands/startapp.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/core/management/commands/startapp.py b/venv/Lib/site-packages/django/core/management/commands/startapp.py
new file mode 100644
--- /dev/null	(date 1617030485662)
+++ b/venv/Lib/site-packages/django/core/management/commands/startapp.py	(date 1617030485662)
@@ -0,0 +1,14 @@
+from django.core.management.templates import TemplateCommand
+
+
+class Command(TemplateCommand):
+    help = (
+        "Creates a Django app directory structure for the given app name in "
+        "the current directory or optionally in the given directory."
+    )
+    missing_args_message = "You must provide an application name."
+
+    def handle(self, **options):
+        app_name = options.pop('name')
+        target = options.pop('directory')
+        super().handle('app', app_name, target, **options)
Index: venv/Lib/site-packages/django/core/management/commands/startproject.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/core/management/commands/startproject.py b/venv/Lib/site-packages/django/core/management/commands/startproject.py
new file mode 100644
--- /dev/null	(date 1617030485663)
+++ b/venv/Lib/site-packages/django/core/management/commands/startproject.py	(date 1617030485663)
@@ -0,0 +1,20 @@
+from django.core.management.templates import TemplateCommand
+
+from ..utils import get_random_secret_key
+
+
+class Command(TemplateCommand):
+    help = (
+        "Creates a Django project directory structure for the given project "
+        "name in the current directory or optionally in the given directory."
+    )
+    missing_args_message = "You must provide a project name."
+
+    def handle(self, **options):
+        project_name = options.pop('name')
+        target = options.pop('directory')
+
+        # Create a random SECRET_KEY to put it in the main settings.
+        options['secret_key'] = get_random_secret_key()
+
+        super().handle('project', project_name, target, **options)
Index: venv/Lib/site-packages/django/core/management/commands/test.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/core/management/commands/test.py b/venv/Lib/site-packages/django/core/management/commands/test.py
new file mode 100644
--- /dev/null	(date 1617030485663)
+++ b/venv/Lib/site-packages/django/core/management/commands/test.py	(date 1617030485663)
@@ -0,0 +1,56 @@
+import sys
+
+from django.conf import settings
+from django.core.management.base import BaseCommand
+from django.core.management.utils import get_command_line_option
+from django.test.utils import get_runner
+
+
+class Command(BaseCommand):
+    help = 'Discover and run tests in the specified modules or the current directory.'
+
+    # DiscoverRunner runs the checks after databases are set up.
+    requires_system_checks = False
+    test_runner = None
+
+    def run_from_argv(self, argv):
+        """
+        Pre-parse the command line to extract the value of the --testrunner
+        option. This allows a test runner to define additional command line
+        arguments.
+        """
+        self.test_runner = get_command_line_option(argv, '--testrunner')
+        super().run_from_argv(argv)
+
+    def add_arguments(self, parser):
+        parser.add_argument(
+            'args', metavar='test_label', nargs='*',
+            help='Module paths to test; can be modulename, modulename.TestCase or modulename.TestCase.test_method'
+        )
+        parser.add_argument(
+            '--noinput', '--no-input', action='store_false', dest='interactive',
+            help='Tells Django to NOT prompt the user for input of any kind.',
+        )
+        parser.add_argument(
+            '--failfast', action='store_true',
+            help='Tells Django to stop running the test suite after first failed test.',
+        )
+        parser.add_argument(
+            '--testrunner',
+            help='Tells Django to use specified test runner class instead of '
+                 'the one specified by the TEST_RUNNER setting.',
+        )
+
+        test_runner_class = get_runner(settings, self.test_runner)
+
+        if hasattr(test_runner_class, 'add_arguments'):
+            test_runner_class.add_arguments(parser)
+
+    def handle(self, *test_labels, **options):
+        TestRunner = get_runner(settings, options['testrunner'])
+
+        test_runner = TestRunner(**options)
+        failures = test_runner.run_tests(test_labels)
+
+        if failures:
+            sys.exit(1)
Index: venv/Lib/site-packages/django/core/management/commands/testserver.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/core/management/commands/testserver.py b/venv/Lib/site-packages/django/core/management/commands/testserver.py
new file mode 100644
--- /dev/null	(date 1617030485663)
+++ b/venv/Lib/site-packages/django/core/management/commands/testserver.py	(date 1617030485663)
@@ -0,0 +1,54 @@
+from django.core.management import call_command
+from django.core.management.base import BaseCommand
+from django.db import connection
+
+
+class Command(BaseCommand):
+    help = 'Runs a development server with data from the given fixture(s).'
+
+    requires_system_checks = False
+
+    def add_arguments(self, parser):
+        parser.add_argument(
+            'args', metavar='fixture', nargs='*',
+            help='Path(s) to fixtures to load before running the server.',
+        )
+        parser.add_argument(
+            '--noinput', '--no-input', action='store_false', dest='interactive',
+            help='Tells Django to NOT prompt the user for input of any kind.',
+        )
+        parser.add_argument(
+            '--addrport', default='',
+            help='Port number or ipaddr:port to run the server on.',
+        )
+        parser.add_argument(
+            '--ipv6', '-6', action='store_true', dest='use_ipv6',
+            help='Tells Django to use an IPv6 address.',
+        )
+
+    def handle(self, *fixture_labels, **options):
+        verbosity = options['verbosity']
+        interactive = options['interactive']
+
+        # Create a test database.
+        db_name = connection.creation.create_test_db(verbosity=verbosity, autoclobber=not interactive, serialize=False)
+
+        # Import the fixture data into the test database.
+        call_command('loaddata', *fixture_labels, **{'verbosity': verbosity})
+
+        # Run the development server. Turn off auto-reloading because it causes
+        # a strange error -- it causes this handle() method to be called
+        # multiple times.
+        shutdown_message = (
+            '\nServer stopped.\nNote that the test database, %r, has not been '
+            'deleted. You can explore it on your own.' % db_name
+        )
+        use_threading = connection.features.test_db_allows_multiple_connections
+        call_command(
+            'runserver',
+            addrport=options['addrport'],
+            shutdown_message=shutdown_message,
+            use_reloader=False,
+            use_ipv6=options['use_ipv6'],
+            use_threading=use_threading
+        )
Index: venv/Lib/site-packages/django/contrib/gis/gdal/base.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/gis/gdal/base.py b/venv/Lib/site-packages/django/contrib/gis/gdal/base.py
new file mode 100644
--- /dev/null	(date 1617030484356)
+++ b/venv/Lib/site-packages/django/contrib/gis/gdal/base.py	(date 1617030484356)
@@ -0,0 +1,6 @@
+from django.contrib.gis.gdal.error import GDALException
+from django.contrib.gis.ptr import CPointerBase
+
+
+class GDALBase(CPointerBase):
+    null_ptr_exception_class = GDALException
Index: venv/Lib/site-packages/django/contrib/gis/gdal/datasource.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/gis/gdal/datasource.py b/venv/Lib/site-packages/django/contrib/gis/gdal/datasource.py
new file mode 100644
--- /dev/null	(date 1617030484356)
+++ b/venv/Lib/site-packages/django/contrib/gis/gdal/datasource.py	(date 1617030484356)
@@ -0,0 +1,120 @@
+"""
+ DataSource is a wrapper for the OGR Data Source object, which provides
+ an interface for reading vector geometry data from many different file
+ formats (including ESRI shapefiles).
+
+ When instantiating a DataSource object, use the filename of a
+ GDAL-supported data source.  For example, a SHP file or a
+ TIGER/Line file from the government.
+
+ The ds_driver keyword is used internally when a ctypes pointer
+ is passed in directly.
+
+ Example:
+  ds = DataSource('/home/foo/bar.shp')
+  for layer in ds:
+      for feature in layer:
+          # Getting the geometry for the feature.
+          g = feature.geom
+
+          # Getting the 'description' field for the feature.
+          desc = feature['description']
+
+          # We can also increment through all of the fields
+          #  attached to this feature.
+          for field in feature:
+              # Get the name of the field (e.g. 'description')
+              nm = field.name
+
+              # Get the type (integer) of the field, e.g. 0 => OFTInteger
+              t = field.type
+
+              # Returns the value the field; OFTIntegers return ints,
+              #  OFTReal returns floats, all else returns string.
+              val = field.value
+"""
+from ctypes import byref
+
+from django.contrib.gis.gdal.base import GDALBase
+from django.contrib.gis.gdal.driver import Driver
+from django.contrib.gis.gdal.error import GDALException
+from django.contrib.gis.gdal.layer import Layer
+from django.contrib.gis.gdal.prototypes import ds as capi
+from django.utils.encoding import force_bytes, force_str
+
+
+# For more information, see the OGR C API source code:
+#  https://www.gdal.org/ogr__api_8h.html
+#
+# The OGR_DS_* routines are relevant here.
+class DataSource(GDALBase):
+    "Wraps an OGR Data Source object."
+    destructor = capi.destroy_ds
+
+    def __init__(self, ds_input, ds_driver=False, write=False, encoding='utf-8'):
+        # The write flag.
+        if write:
+            self._write = 1
+        else:
+            self._write = 0
+        # See also https://trac.osgeo.org/gdal/wiki/rfc23_ogr_unicode
+        self.encoding = encoding
+
+        Driver.ensure_registered()
+
+        if isinstance(ds_input, str):
+            # The data source driver is a void pointer.
+            ds_driver = Driver.ptr_type()
+            try:
+                # OGROpen will auto-detect the data source type.
+                ds = capi.open_ds(force_bytes(ds_input), self._write, byref(ds_driver))
+            except GDALException:
+                # Making the error message more clear rather than something
+                # like "Invalid pointer returned from OGROpen".
+                raise GDALException('Could not open the datasource at "%s"' % ds_input)
+        elif isinstance(ds_input, self.ptr_type) and isinstance(ds_driver, Driver.ptr_type):
+            ds = ds_input
+        else:
+            raise GDALException('Invalid data source input type: %s' % type(ds_input))
+
+        if ds:
+            self.ptr = ds
+            self.driver = Driver(ds_driver)
+        else:
+            # Raise an exception if the returned pointer is NULL
+            raise GDALException('Invalid data source file "%s"' % ds_input)
+
+    def __getitem__(self, index):
+        "Allows use of the index [] operator to get a layer at the index."
+        if isinstance(index, str):
+            try:
+                layer = capi.get_layer_by_name(self.ptr, force_bytes(index))
+            except GDALException:
+                raise IndexError('Invalid OGR layer name given: %s.' % index)
+        elif isinstance(index, int):
+            if 0 <= index < self.layer_count:
+                layer = capi.get_layer(self._ptr, index)
+            else:
+                raise IndexError('Index out of range when accessing layers in a datasource: %s.' % index)
+        else:
+            raise TypeError('Invalid index type: %s' % type(index))
+        return Layer(layer, self)
+
+    def __len__(self):
+        "Return the number of layers within the data source."
+        return self.layer_count
+
+    def __str__(self):
+        "Return OGR GetName and Driver for the Data Source."
+        return '%s (%s)' % (self.name, self.driver)
+
+    @property
+    def layer_count(self):
+        "Return the number of layers in the data source."
+        return capi.get_layer_count(self._ptr)
+
+    @property
+    def name(self):
+        "Return the name of the data source."
+        name = capi.get_ds_name(self._ptr)
+        return force_str(name, self.encoding, strings_only=True)
Index: venv/Lib/site-packages/django/contrib/gis/gdal/driver.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/gis/gdal/driver.py b/venv/Lib/site-packages/django/contrib/gis/gdal/driver.py
new file mode 100644
--- /dev/null	(date 1617030484356)
+++ b/venv/Lib/site-packages/django/contrib/gis/gdal/driver.py	(date 1617030484356)
@@ -0,0 +1,97 @@
+from ctypes import c_void_p
+
+from django.contrib.gis.gdal.base import GDALBase
+from django.contrib.gis.gdal.error import GDALException
+from django.contrib.gis.gdal.prototypes import ds as vcapi, raster as rcapi
+from django.utils.encoding import force_bytes, force_str
+
+
+class Driver(GDALBase):
+    """
+    Wrap a GDAL/OGR Data Source Driver.
+    For more information, see the C API source code:
+    https://www.gdal.org/gdal_8h.html - https://www.gdal.org/ogr__api_8h.html
+    """
+
+    # Case-insensitive aliases for some GDAL/OGR Drivers.
+    # For a complete list of original driver names see
+    # https://www.gdal.org/ogr_formats.html (vector)
+    # https://www.gdal.org/formats_list.html (raster)
+    _alias = {
+        # vector
+        'esri': 'ESRI Shapefile',
+        'shp': 'ESRI Shapefile',
+        'shape': 'ESRI Shapefile',
+        'tiger': 'TIGER',
+        'tiger/line': 'TIGER',
+        # raster
+        'tiff': 'GTiff',
+        'tif': 'GTiff',
+        'jpeg': 'JPEG',
+        'jpg': 'JPEG',
+    }
+
+    def __init__(self, dr_input):
+        """
+        Initialize an GDAL/OGR driver on either a string or integer input.
+        """
+        if isinstance(dr_input, str):
+            # If a string name of the driver was passed in
+            self.ensure_registered()
+
+            # Checking the alias dictionary (case-insensitive) to see if an
+            # alias exists for the given driver.
+            if dr_input.lower() in self._alias:
+                name = self._alias[dr_input.lower()]
+            else:
+                name = dr_input
+
+            # Attempting to get the GDAL/OGR driver by the string name.
+            for iface in (vcapi, rcapi):
+                driver = c_void_p(iface.get_driver_by_name(force_bytes(name)))
+                if driver:
+                    break
+        elif isinstance(dr_input, int):
+            self.ensure_registered()
+            for iface in (vcapi, rcapi):
+                driver = iface.get_driver(dr_input)
+                if driver:
+                    break
+        elif isinstance(dr_input, c_void_p):
+            driver = dr_input
+        else:
+            raise GDALException('Unrecognized input type for GDAL/OGR Driver: %s' % type(dr_input))
+
+        # Making sure we get a valid pointer to the OGR Driver
+        if not driver:
+            raise GDALException('Could not initialize GDAL/OGR Driver on input: %s' % dr_input)
+        self.ptr = driver
+
+    def __str__(self):
+        return self.name
+
+    @classmethod
+    def ensure_registered(cls):
+        """
+        Attempt to register all the data source drivers.
+        """
+        # Only register all if the driver counts are 0 (or else all drivers
+        # will be registered over and over again)
+        if not vcapi.get_driver_count():
+            vcapi.register_all()
+        if not rcapi.get_driver_count():
+            rcapi.register_all()
+
+    @classmethod
+    def driver_count(cls):
+        """
+        Return the number of GDAL/OGR data source drivers registered.
+        """
+        return vcapi.get_driver_count() + rcapi.get_driver_count()
+
+    @property
+    def name(self):
+        """
+        Return description/name string for this driver.
+        """
+        return force_str(rcapi.get_driver_description(self.ptr))
Index: venv/Lib/site-packages/django/contrib/gis/gdal/envelope.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/gis/gdal/envelope.py b/venv/Lib/site-packages/django/contrib/gis/gdal/envelope.py
new file mode 100644
--- /dev/null	(date 1617030484357)
+++ b/venv/Lib/site-packages/django/contrib/gis/gdal/envelope.py	(date 1617030484357)
@@ -0,0 +1,178 @@
+"""
+ The GDAL/OGR library uses an Envelope structure to hold the bounding
+ box information for a geometry.  The envelope (bounding box) contains
+ two pairs of coordinates, one for the lower left coordinate and one
+ for the upper right coordinate:
+
+                           +----------o Upper right; (max_x, max_y)
+                           |          |
+                           |          |
+                           |          |
+ Lower left (min_x, min_y) o----------+
+"""
+from ctypes import Structure, c_double
+
+from django.contrib.gis.gdal.error import GDALException
+
+
+# The OGR definition of an Envelope is a C structure containing four doubles.
+#  See the 'ogr_core.h' source file for more information:
+#   https://www.gdal.org/ogr__core_8h_source.html
+class OGREnvelope(Structure):
+    "Represent the OGREnvelope C Structure."
+    _fields_ = [("MinX", c_double),
+                ("MaxX", c_double),
+                ("MinY", c_double),
+                ("MaxY", c_double),
+                ]
+
+
+class Envelope:
+    """
+    The Envelope object is a C structure that contains the minimum and
+    maximum X, Y coordinates for a rectangle bounding box.  The naming
+    of the variables is compatible with the OGR Envelope structure.
+    """
+
+    def __init__(self, *args):
+        """
+        The initialization function may take an OGREnvelope structure, 4-element
+        tuple or list, or 4 individual arguments.
+        """
+
+        if len(args) == 1:
+            if isinstance(args[0], OGREnvelope):
+                # OGREnvelope (a ctypes Structure) was passed in.
+                self._envelope = args[0]
+            elif isinstance(args[0], (tuple, list)):
+                # A tuple was passed in.
+                if len(args[0]) != 4:
+                    raise GDALException('Incorrect number of tuple elements (%d).' % len(args[0]))
+                else:
+                    self._from_sequence(args[0])
+            else:
+                raise TypeError('Incorrect type of argument: %s' % type(args[0]))
+        elif len(args) == 4:
+            # Individual parameters passed in.
+            #  Thanks to ww for the help
+            self._from_sequence([float(a) for a in args])
+        else:
+            raise GDALException('Incorrect number (%d) of arguments.' % len(args))
+
+        # Checking the x,y coordinates
+        if self.min_x > self.max_x:
+            raise GDALException('Envelope minimum X > maximum X.')
+        if self.min_y > self.max_y:
+            raise GDALException('Envelope minimum Y > maximum Y.')
+
+    def __eq__(self, other):
+        """
+        Return True if the envelopes are equivalent; can compare against
+        other Envelopes and 4-tuples.
+        """
+        if isinstance(other, Envelope):
+            return (self.min_x == other.min_x) and (self.min_y == other.min_y) and \
+                   (self.max_x == other.max_x) and (self.max_y == other.max_y)
+        elif isinstance(other, tuple) and len(other) == 4:
+            return (self.min_x == other[0]) and (self.min_y == other[1]) and \
+                   (self.max_x == other[2]) and (self.max_y == other[3])
+        else:
+            raise GDALException('Equivalence testing only works with other Envelopes.')
+
+    def __str__(self):
+        "Return a string representation of the tuple."
+        return str(self.tuple)
+
+    def _from_sequence(self, seq):
+        "Initialize the C OGR Envelope structure from the given sequence."
+        self._envelope = OGREnvelope()
+        self._envelope.MinX = seq[0]
+        self._envelope.MinY = seq[1]
+        self._envelope.MaxX = seq[2]
+        self._envelope.MaxY = seq[3]
+
+    def expand_to_include(self, *args):
+        """
+        Modify the envelope to expand to include the boundaries of
+        the passed-in 2-tuple (a point), 4-tuple (an extent) or
+        envelope.
+        """
+        # We provide a number of different signatures for this method,
+        # and the logic here is all about converting them into a
+        # 4-tuple single parameter which does the actual work of
+        # expanding the envelope.
+        if len(args) == 1:
+            if isinstance(args[0], Envelope):
+                return self.expand_to_include(args[0].tuple)
+            elif hasattr(args[0], 'x') and hasattr(args[0], 'y'):
+                return self.expand_to_include(args[0].x, args[0].y, args[0].x, args[0].y)
+            elif isinstance(args[0], (tuple, list)):
+                # A tuple was passed in.
+                if len(args[0]) == 2:
+                    return self.expand_to_include((args[0][0], args[0][1], args[0][0], args[0][1]))
+                elif len(args[0]) == 4:
+                    (minx, miny, maxx, maxy) = args[0]
+                    if minx < self._envelope.MinX:
+                        self._envelope.MinX = minx
+                    if miny < self._envelope.MinY:
+                        self._envelope.MinY = miny
+                    if maxx > self._envelope.MaxX:
+                        self._envelope.MaxX = maxx
+                    if maxy > self._envelope.MaxY:
+                        self._envelope.MaxY = maxy
+                else:
+                    raise GDALException('Incorrect number of tuple elements (%d).' % len(args[0]))
+            else:
+                raise TypeError('Incorrect type of argument: %s' % type(args[0]))
+        elif len(args) == 2:
+            # An x and an y parameter were passed in
+            return self.expand_to_include((args[0], args[1], args[0], args[1]))
+        elif len(args) == 4:
+            # Individual parameters passed in.
+            return self.expand_to_include(args)
+        else:
+            raise GDALException('Incorrect number (%d) of arguments.' % len(args[0]))
+
+    @property
+    def min_x(self):
+        "Return the value of the minimum X coordinate."
+        return self._envelope.MinX
+
+    @property
+    def min_y(self):
+        "Return the value of the minimum Y coordinate."
+        return self._envelope.MinY
+
+    @property
+    def max_x(self):
+        "Return the value of the maximum X coordinate."
+        return self._envelope.MaxX
+
+    @property
+    def max_y(self):
+        "Return the value of the maximum Y coordinate."
+        return self._envelope.MaxY
+
+    @property
+    def ur(self):
+        "Return the upper-right coordinate."
+        return (self.max_x, self.max_y)
+
+    @property
+    def ll(self):
+        "Return the lower-left coordinate."
+        return (self.min_x, self.min_y)
+
+    @property
+    def tuple(self):
+        "Return a tuple representing the envelope."
+        return (self.min_x, self.min_y, self.max_x, self.max_y)
+
+    @property
+    def wkt(self):
+        "Return WKT representing a Polygon for this envelope."
+        # TODO: Fix significant figures.
+        return 'POLYGON((%s %s,%s %s,%s %s,%s %s,%s %s))' % \
+               (self.min_x, self.min_y, self.min_x, self.max_y,
+                self.max_x, self.max_y, self.max_x, self.min_y,
+                self.min_x, self.min_y)
Index: venv/Lib/site-packages/django/contrib/gis/gdal/error.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/gis/gdal/error.py b/venv/Lib/site-packages/django/contrib/gis/gdal/error.py
new file mode 100644
--- /dev/null	(date 1617030484357)
+++ b/venv/Lib/site-packages/django/contrib/gis/gdal/error.py	(date 1617030484357)
@@ -0,0 +1,61 @@
+"""
+ This module houses the GDAL & SRS Exception objects, and the
+ check_err() routine which checks the status code returned by
+ GDAL/OGR methods.
+"""
+
+
+# #### GDAL & SRS Exceptions ####
+class GDALException(Exception):
+    pass
+
+
+class SRSException(Exception):
+    pass
+
+
+# #### GDAL/OGR error checking codes and routine ####
+
+# OGR Error Codes
+OGRERR_DICT = {
+    1: (GDALException, 'Not enough data.'),
+    2: (GDALException, 'Not enough memory.'),
+    3: (GDALException, 'Unsupported geometry type.'),
+    4: (GDALException, 'Unsupported operation.'),
+    5: (GDALException, 'Corrupt data.'),
+    6: (GDALException, 'OGR failure.'),
+    7: (SRSException, 'Unsupported SRS.'),
+    8: (GDALException, 'Invalid handle.'),
+}
+
+# CPL Error Codes
+# https://www.gdal.org/cpl__error_8h.html
+CPLERR_DICT = {
+    1: (GDALException, 'AppDefined'),
+    2: (GDALException, 'OutOfMemory'),
+    3: (GDALException, 'FileIO'),
+    4: (GDALException, 'OpenFailed'),
+    5: (GDALException, 'IllegalArg'),
+    6: (GDALException, 'NotSupported'),
+    7: (GDALException, 'AssertionFailed'),
+    8: (GDALException, 'NoWriteAccess'),
+    9: (GDALException, 'UserInterrupt'),
+    10: (GDALException, 'ObjectNull'),
+}
+
+ERR_NONE = 0
+
+
+def check_err(code, cpl=False):
+    """
+    Check the given CPL/OGRERR and raise an exception where appropriate.
+    """
+    err_dict = CPLERR_DICT if cpl else OGRERR_DICT
+
+    if code == ERR_NONE:
+        return
+    elif code in err_dict:
+        e, msg = err_dict[code]
+        raise e(msg)
+    else:
+        raise GDALException('Unknown error code: "%s"' % code)
Index: venv/Lib/site-packages/django/contrib/gis/gdal/feature.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/gis/gdal/feature.py b/venv/Lib/site-packages/django/contrib/gis/gdal/feature.py
new file mode 100644
--- /dev/null	(date 1617030484358)
+++ b/venv/Lib/site-packages/django/contrib/gis/gdal/feature.py	(date 1617030484358)
@@ -0,0 +1,115 @@
+from django.contrib.gis.gdal.base import GDALBase
+from django.contrib.gis.gdal.error import GDALException
+from django.contrib.gis.gdal.field import Field
+from django.contrib.gis.gdal.geometries import OGRGeometry, OGRGeomType
+from django.contrib.gis.gdal.prototypes import ds as capi, geom as geom_api
+from django.utils.encoding import force_bytes, force_str
+
+
+# For more information, see the OGR C API source code:
+#  https://www.gdal.org/ogr__api_8h.html
+#
+# The OGR_F_* routines are relevant here.
+class Feature(GDALBase):
+    """
+    This class that wraps an OGR Feature, needs to be instantiated
+    from a Layer object.
+    """
+    destructor = capi.destroy_feature
+
+    def __init__(self, feat, layer):
+        """
+        Initialize Feature from a pointer and its Layer object.
+        """
+        if not feat:
+            raise GDALException('Cannot create OGR Feature, invalid pointer given.')
+        self.ptr = feat
+        self._layer = layer
+
+    def __getitem__(self, index):
+        """
+        Get the Field object at the specified index, which may be either
+        an integer or the Field's string label.  Note that the Field object
+        is not the field's _value_ -- use the `get` method instead to
+        retrieve the value (e.g. an integer) instead of a Field instance.
+        """
+        if isinstance(index, str):
+            i = self.index(index)
+        elif 0 <= index < self.num_fields:
+            i = index
+        else:
+            raise IndexError('Index out of range when accessing field in a feature: %s.' % index)
+        return Field(self, i)
+
+    def __len__(self):
+        "Return the count of fields in this feature."
+        return self.num_fields
+
+    def __str__(self):
+        "The string name of the feature."
+        return 'Feature FID %d in Layer<%s>' % (self.fid, self.layer_name)
+
+    def __eq__(self, other):
+        "Do equivalence testing on the features."
+        return bool(capi.feature_equal(self.ptr, other._ptr))
+
+    # #### Feature Properties ####
+    @property
+    def encoding(self):
+        return self._layer._ds.encoding
+
+    @property
+    def fid(self):
+        "Return the feature identifier."
+        return capi.get_fid(self.ptr)
+
+    @property
+    def layer_name(self):
+        "Return the name of the layer for the feature."
+        name = capi.get_feat_name(self._layer._ldefn)
+        return force_str(name, self.encoding, strings_only=True)
+
+    @property
+    def num_fields(self):
+        "Return the number of fields in the Feature."
+        return capi.get_feat_field_count(self.ptr)
+
+    @property
+    def fields(self):
+        "Return a list of fields in the Feature."
+        return [
+            force_str(
+                capi.get_field_name(capi.get_field_defn(self._layer._ldefn, i)),
+                self.encoding,
+                strings_only=True
+            ) for i in range(self.num_fields)
+        ]
+
+    @property
+    def geom(self):
+        "Return the OGR Geometry for this Feature."
+        # Retrieving the geometry pointer for the feature.
+        geom_ptr = capi.get_feat_geom_ref(self.ptr)
+        return OGRGeometry(geom_api.clone_geom(geom_ptr))
+
+    @property
+    def geom_type(self):
+        "Return the OGR Geometry Type for this Feature."
+        return OGRGeomType(capi.get_fd_geom_type(self._layer._ldefn))
+
+    # #### Feature Methods ####
+    def get(self, field):
+        """
+        Return the value of the field, instead of an instance of the Field
+        object.  May take a string of the field name or a Field object as
+        parameters.
+        """
+        field_name = getattr(field, 'name', field)
+        return self[field_name].value
+
+    def index(self, field_name):
+        "Return the index of the given field name."
+        i = capi.get_field_index(self.ptr, force_bytes(field_name))
+        if i < 0:
+            raise IndexError('Invalid OFT field name given: %s.' % field_name)
+        return i
Index: venv/Lib/site-packages/django/contrib/gis/gdal/field.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/gis/gdal/field.py b/venv/Lib/site-packages/django/contrib/gis/gdal/field.py
new file mode 100644
--- /dev/null	(date 1617030484358)
+++ b/venv/Lib/site-packages/django/contrib/gis/gdal/field.py	(date 1617030484358)
@@ -0,0 +1,232 @@
+from ctypes import byref, c_int
+from datetime import date, datetime, time
+
+from django.contrib.gis.gdal.base import GDALBase
+from django.contrib.gis.gdal.error import GDALException
+from django.contrib.gis.gdal.prototypes import ds as capi
+from django.utils.encoding import force_str
+
+
+# For more information, see the OGR C API source code:
+#  https://www.gdal.org/ogr__api_8h.html
+#
+# The OGR_Fld_* routines are relevant here.
+class Field(GDALBase):
+    """
+    Wrap an OGR Field. Needs to be instantiated from a Feature object.
+    """
+
+    def __init__(self, feat, index):
+        """
+        Initialize on the feature object and the integer index of
+        the field within the feature.
+        """
+        # Setting the feature pointer and index.
+        self._feat = feat
+        self._index = index
+
+        # Getting the pointer for this field.
+        fld_ptr = capi.get_feat_field_defn(feat.ptr, index)
+        if not fld_ptr:
+            raise GDALException('Cannot create OGR Field, invalid pointer given.')
+        self.ptr = fld_ptr
+
+        # Setting the class depending upon the OGR Field Type (OFT)
+        self.__class__ = OGRFieldTypes[self.type]
+
+    def __str__(self):
+        "Return the string representation of the Field."
+        return str(self.value).strip()
+
+    # #### Field Methods ####
+    def as_double(self):
+        "Retrieve the Field's value as a double (float)."
+        return capi.get_field_as_double(self._feat.ptr, self._index) if self.is_set else None
+
+    def as_int(self, is_64=False):
+        "Retrieve the Field's value as an integer."
+        if is_64:
+            return capi.get_field_as_integer64(self._feat.ptr, self._index) if self.is_set else None
+        else:
+            return capi.get_field_as_integer(self._feat.ptr, self._index) if self.is_set else None
+
+    def as_string(self):
+        "Retrieve the Field's value as a string."
+        if not self.is_set:
+            return None
+        string = capi.get_field_as_string(self._feat.ptr, self._index)
+        return force_str(string, encoding=self._feat.encoding, strings_only=True)
+
+    def as_datetime(self):
+        "Retrieve the Field's value as a tuple of date & time components."
+        if not self.is_set:
+            return None
+        yy, mm, dd, hh, mn, ss, tz = [c_int() for i in range(7)]
+        status = capi.get_field_as_datetime(
+            self._feat.ptr, self._index, byref(yy), byref(mm), byref(dd),
+            byref(hh), byref(mn), byref(ss), byref(tz))
+        if status:
+            return (yy, mm, dd, hh, mn, ss, tz)
+        else:
+            raise GDALException('Unable to retrieve date & time information from the field.')
+
+    # #### Field Properties ####
+    @property
+    def is_set(self):
+        "Return True if the value of this field isn't null, False otherwise."
+        return capi.is_field_set(self._feat.ptr, self._index)
+
+    @property
+    def name(self):
+        "Return the name of this Field."
+        name = capi.get_field_name(self.ptr)
+        return force_str(name, encoding=self._feat.encoding, strings_only=True)
+
+    @property
+    def precision(self):
+        "Return the precision of this Field."
+        return capi.get_field_precision(self.ptr)
+
+    @property
+    def type(self):
+        "Return the OGR type of this Field."
+        return capi.get_field_type(self.ptr)
+
+    @property
+    def type_name(self):
+        "Return the OGR field type name for this Field."
+        return capi.get_field_type_name(self.type)
+
+    @property
+    def value(self):
+        "Return the value of this Field."
+        # Default is to get the field as a string.
+        return self.as_string()
+
+    @property
+    def width(self):
+        "Return the width of this Field."
+        return capi.get_field_width(self.ptr)
+
+
+# ### The Field sub-classes for each OGR Field type. ###
+class OFTInteger(Field):
+    _bit64 = False
+
+    @property
+    def value(self):
+        "Return an integer contained in this field."
+        return self.as_int(self._bit64)
+
+    @property
+    def type(self):
+        """
+        GDAL uses OFTReals to represent OFTIntegers in created
+        shapefiles -- forcing the type here since the underlying field
+        type may actually be OFTReal.
+        """
+        return 0
+
+
+class OFTReal(Field):
+    @property
+    def value(self):
+        "Return a float contained in this field."
+        return self.as_double()
+
+
+# String & Binary fields, just subclasses
+class OFTString(Field):
+    pass
+
+
+class OFTWideString(Field):
+    pass
+
+
+class OFTBinary(Field):
+    pass
+
+
+# OFTDate, OFTTime, OFTDateTime fields.
+class OFTDate(Field):
+    @property
+    def value(self):
+        "Return a Python `date` object for the OFTDate field."
+        try:
+            yy, mm, dd, hh, mn, ss, tz = self.as_datetime()
+            return date(yy.value, mm.value, dd.value)
+        except (TypeError, ValueError, GDALException):
+            return None
+
+
+class OFTDateTime(Field):
+    @property
+    def value(self):
+        "Return a Python `datetime` object for this OFTDateTime field."
+        # TODO: Adapt timezone information.
+        #  See https://lists.osgeo.org/pipermail/gdal-dev/2006-February/007990.html
+        #  The `tz` variable has values of: 0=unknown, 1=localtime (ambiguous),
+        #  100=GMT, 104=GMT+1, 80=GMT-5, etc.
+        try:
+            yy, mm, dd, hh, mn, ss, tz = self.as_datetime()
+            return datetime(yy.value, mm.value, dd.value, hh.value, mn.value, ss.value)
+        except (TypeError, ValueError, GDALException):
+            return None
+
+
+class OFTTime(Field):
+    @property
+    def value(self):
+        "Return a Python `time` object for this OFTTime field."
+        try:
+            yy, mm, dd, hh, mn, ss, tz = self.as_datetime()
+            return time(hh.value, mn.value, ss.value)
+        except (ValueError, GDALException):
+            return None
+
+
+class OFTInteger64(OFTInteger):
+    _bit64 = True
+
+
+# List fields are also just subclasses
+class OFTIntegerList(Field):
+    pass
+
+
+class OFTRealList(Field):
+    pass
+
+
+class OFTStringList(Field):
+    pass
+
+
+class OFTWideStringList(Field):
+    pass
+
+
+class OFTInteger64List(Field):
+    pass
+
+
+# Class mapping dictionary for OFT Types and reverse mapping.
+OGRFieldTypes = {
+    0: OFTInteger,
+    1: OFTIntegerList,
+    2: OFTReal,
+    3: OFTRealList,
+    4: OFTString,
+    5: OFTStringList,
+    6: OFTWideString,
+    7: OFTWideStringList,
+    8: OFTBinary,
+    9: OFTDate,
+    10: OFTTime,
+    11: OFTDateTime,
+    # New 64-bit integer types in GDAL 2
+    12: OFTInteger64,
+    13: OFTInteger64List,
+}
+ROGRFieldTypes = {cls: num for num, cls in OGRFieldTypes.items()}
Index: venv/Lib/site-packages/django/contrib/gis/gdal/geometries.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/gis/gdal/geometries.py b/venv/Lib/site-packages/django/contrib/gis/gdal/geometries.py
new file mode 100644
--- /dev/null	(date 1617030484358)
+++ b/venv/Lib/site-packages/django/contrib/gis/gdal/geometries.py	(date 1617030484358)
@@ -0,0 +1,707 @@
+"""
+ The OGRGeometry is a wrapper for using the OGR Geometry class
+ (see https://www.gdal.org/classOGRGeometry.html).  OGRGeometry
+ may be instantiated when reading geometries from OGR Data Sources
+ (e.g. SHP files), or when given OGC WKT (a string).
+
+ While the 'full' API is not present yet, the API is "pythonic" unlike
+ the traditional and "next-generation" OGR Python bindings.  One major
+ advantage OGR Geometries have over their GEOS counterparts is support
+ for spatial reference systems and their transformation.
+
+ Example:
+  >>> from django.contrib.gis.gdal import OGRGeometry, OGRGeomType, SpatialReference
+  >>> wkt1, wkt2 = 'POINT(-90 30)', 'POLYGON((0 0, 5 0, 5 5, 0 5)'
+  >>> pnt = OGRGeometry(wkt1)
+  >>> print(pnt)
+  POINT (-90 30)
+  >>> mpnt = OGRGeometry(OGRGeomType('MultiPoint'), SpatialReference('WGS84'))
+  >>> mpnt.add(wkt1)
+  >>> mpnt.add(wkt1)
+  >>> print(mpnt)
+  MULTIPOINT (-90 30,-90 30)
+  >>> print(mpnt.srs.name)
+  WGS 84
+  >>> print(mpnt.srs.proj)
+  +proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs
+  >>> mpnt.transform(SpatialReference('NAD27'))
+  >>> print(mpnt.proj)
+  +proj=longlat +ellps=clrk66 +datum=NAD27 +no_defs
+  >>> print(mpnt)
+  MULTIPOINT (-89.999930378602485 29.999797886557641,-89.999930378602485 29.999797886557641)
+
+  The OGRGeomType class is to make it easy to specify an OGR geometry type:
+  >>> from django.contrib.gis.gdal import OGRGeomType
+  >>> gt1 = OGRGeomType(3) # Using an integer for the type
+  >>> gt2 = OGRGeomType('Polygon') # Using a string
+  >>> gt3 = OGRGeomType('POLYGON') # It's case-insensitive
+  >>> print(gt1 == 3, gt1 == 'Polygon') # Equivalence works w/non-OGRGeomType objects
+  True True
+"""
+import sys
+from binascii import b2a_hex
+from ctypes import byref, c_char_p, c_double, c_ubyte, c_void_p, string_at
+
+from django.contrib.gis.gdal.base import GDALBase
+from django.contrib.gis.gdal.envelope import Envelope, OGREnvelope
+from django.contrib.gis.gdal.error import GDALException, SRSException
+from django.contrib.gis.gdal.geomtype import OGRGeomType
+from django.contrib.gis.gdal.prototypes import geom as capi, srs as srs_api
+from django.contrib.gis.gdal.srs import CoordTransform, SpatialReference
+from django.contrib.gis.geometry import hex_regex, json_regex, wkt_regex
+from django.utils.encoding import force_bytes
+
+
+# For more information, see the OGR C API source code:
+#  https://www.gdal.org/ogr__api_8h.html
+#
+# The OGR_G_* routines are relevant here.
+class OGRGeometry(GDALBase):
+    """Encapsulate an OGR geometry."""
+    destructor = capi.destroy_geom
+
+    def __init__(self, geom_input, srs=None):
+        """Initialize Geometry on either WKT or an OGR pointer as input."""
+        str_instance = isinstance(geom_input, str)
+
+        # If HEX, unpack input to a binary buffer.
+        if str_instance and hex_regex.match(geom_input):
+            geom_input = memoryview(bytes.fromhex(geom_input))
+            str_instance = False
+
+        # Constructing the geometry,
+        if str_instance:
+            wkt_m = wkt_regex.match(geom_input)
+            json_m = json_regex.match(geom_input)
+            if wkt_m:
+                if wkt_m['srid']:
+                    # If there's EWKT, set the SRS w/value of the SRID.
+                    srs = int(wkt_m['srid'])
+                if wkt_m['type'].upper() == 'LINEARRING':
+                    # OGR_G_CreateFromWkt doesn't work with LINEARRING WKT.
+                    #  See https://trac.osgeo.org/gdal/ticket/1992.
+                    g = capi.create_geom(OGRGeomType(wkt_m['type']).num)
+                    capi.import_wkt(g, byref(c_char_p(wkt_m['wkt'].encode())))
+                else:
+                    g = capi.from_wkt(byref(c_char_p(wkt_m['wkt'].encode())), None, byref(c_void_p()))
+            elif json_m:
+                g = self._from_json(geom_input.encode())
+            else:
+                # Seeing if the input is a valid short-hand string
+                # (e.g., 'Point', 'POLYGON').
+                OGRGeomType(geom_input)
+                g = capi.create_geom(OGRGeomType(geom_input).num)
+        elif isinstance(geom_input, memoryview):
+            # WKB was passed in
+            g = self._from_wkb(geom_input)
+        elif isinstance(geom_input, OGRGeomType):
+            # OGRGeomType was passed in, an empty geometry will be created.
+            g = capi.create_geom(geom_input.num)
+        elif isinstance(geom_input, self.ptr_type):
+            # OGR pointer (c_void_p) was the input.
+            g = geom_input
+        else:
+            raise GDALException('Invalid input type for OGR Geometry construction: %s' % type(geom_input))
+
+        # Now checking the Geometry pointer before finishing initialization
+        # by setting the pointer for the object.
+        if not g:
+            raise GDALException('Cannot create OGR Geometry from input: %s' % geom_input)
+        self.ptr = g
+
+        # Assigning the SpatialReference object to the geometry, if valid.
+        if srs:
+            self.srs = srs
+
+        # Setting the class depending upon the OGR Geometry Type
+        self.__class__ = GEO_CLASSES[self.geom_type.num]
+
+    # Pickle routines
+    def __getstate__(self):
+        srs = self.srs
+        if srs:
+            srs = srs.wkt
+        else:
+            srs = None
+        return bytes(self.wkb), srs
+
+    def __setstate__(self, state):
+        wkb, srs = state
+        ptr = capi.from_wkb(wkb, None, byref(c_void_p()), len(wkb))
+        if not ptr:
+            raise GDALException('Invalid OGRGeometry loaded from pickled state.')
+        self.ptr = ptr
+        self.srs = srs
+
+    @classmethod
+    def _from_wkb(cls, geom_input):
+        return capi.from_wkb(bytes(geom_input), None, byref(c_void_p()), len(geom_input))
+
+    @staticmethod
+    def _from_json(geom_input):
+        return capi.from_json(geom_input)
+
+    @classmethod
+    def from_bbox(cls, bbox):
+        "Construct a Polygon from a bounding box (4-tuple)."
+        x0, y0, x1, y1 = bbox
+        return OGRGeometry('POLYGON((%s %s, %s %s, %s %s, %s %s, %s %s))' % (
+            x0, y0, x0, y1, x1, y1, x1, y0, x0, y0))
+
+    @staticmethod
+    def from_json(geom_input):
+        return OGRGeometry(OGRGeometry._from_json(force_bytes(geom_input)))
+
+    @classmethod
+    def from_gml(cls, gml_string):
+        return cls(capi.from_gml(force_bytes(gml_string)))
+
+    # ### Geometry set-like operations ###
+    # g = g1 | g2
+    def __or__(self, other):
+        "Return the union of the two geometries."
+        return self.union(other)
+
+    # g = g1 & g2
+    def __and__(self, other):
+        "Return the intersection of this Geometry and the other."
+        return self.intersection(other)
+
+    # g = g1 - g2
+    def __sub__(self, other):
+        "Return the difference this Geometry and the other."
+        return self.difference(other)
+
+    # g = g1 ^ g2
+    def __xor__(self, other):
+        "Return the symmetric difference of this Geometry and the other."
+        return self.sym_difference(other)
+
+    def __eq__(self, other):
+        "Is this Geometry equal to the other?"
+        return isinstance(other, OGRGeometry) and self.equals(other)
+
+    def __str__(self):
+        "WKT is used for the string representation."
+        return self.wkt
+
+    # #### Geometry Properties ####
+    @property
+    def dimension(self):
+        "Return 0 for points, 1 for lines, and 2 for surfaces."
+        return capi.get_dims(self.ptr)
+
+    def _get_coord_dim(self):
+        "Return the coordinate dimension of the Geometry."
+        return capi.get_coord_dim(self.ptr)
+
+    def _set_coord_dim(self, dim):
+        "Set the coordinate dimension of this Geometry."
+        if dim not in (2, 3):
+            raise ValueError('Geometry dimension must be either 2 or 3')
+        capi.set_coord_dim(self.ptr, dim)
+
+    coord_dim = property(_get_coord_dim, _set_coord_dim)
+
+    @property
+    def geom_count(self):
+        "Return the number of elements in this Geometry."
+        return capi.get_geom_count(self.ptr)
+
+    @property
+    def point_count(self):
+        "Return the number of Points in this Geometry."
+        return capi.get_point_count(self.ptr)
+
+    @property
+    def num_points(self):
+        "Alias for `point_count` (same name method in GEOS API.)"
+        return self.point_count
+
+    @property
+    def num_coords(self):
+        "Alias for `point_count`."
+        return self.point_count
+
+    @property
+    def geom_type(self):
+        "Return the Type for this Geometry."
+        return OGRGeomType(capi.get_geom_type(self.ptr))
+
+    @property
+    def geom_name(self):
+        "Return the Name of this Geometry."
+        return capi.get_geom_name(self.ptr)
+
+    @property
+    def area(self):
+        "Return the area for a LinearRing, Polygon, or MultiPolygon; 0 otherwise."
+        return capi.get_area(self.ptr)
+
+    @property
+    def envelope(self):
+        "Return the envelope for this Geometry."
+        # TODO: Fix Envelope() for Point geometries.
+        return Envelope(capi.get_envelope(self.ptr, byref(OGREnvelope())))
+
+    @property
+    def empty(self):
+        return capi.is_empty(self.ptr)
+
+    @property
+    def extent(self):
+        "Return the envelope as a 4-tuple, instead of as an Envelope object."
+        return self.envelope.tuple
+
+    # #### SpatialReference-related Properties ####
+
+    # The SRS property
+    def _get_srs(self):
+        "Return the Spatial Reference for this Geometry."
+        try:
+            srs_ptr = capi.get_geom_srs(self.ptr)
+            return SpatialReference(srs_api.clone_srs(srs_ptr))
+        except SRSException:
+            return None
+
+    def _set_srs(self, srs):
+        "Set the SpatialReference for this geometry."
+        # Do not have to clone the `SpatialReference` object pointer because
+        # when it is assigned to this `OGRGeometry` it's internal OGR
+        # reference count is incremented, and will likewise be released
+        # (decremented) when this geometry's destructor is called.
+        if isinstance(srs, SpatialReference):
+            srs_ptr = srs.ptr
+        elif isinstance(srs, (int, str)):
+            sr = SpatialReference(srs)
+            srs_ptr = sr.ptr
+        elif srs is None:
+            srs_ptr = None
+        else:
+            raise TypeError('Cannot assign spatial reference with object of type: %s' % type(srs))
+        capi.assign_srs(self.ptr, srs_ptr)
+
+    srs = property(_get_srs, _set_srs)
+
+    # The SRID property
+    def _get_srid(self):
+        srs = self.srs
+        if srs:
+            return srs.srid
+        return None
+
+    def _set_srid(self, srid):
+        if isinstance(srid, int) or srid is None:
+            self.srs = srid
+        else:
+            raise TypeError('SRID must be set with an integer.')
+
+    srid = property(_get_srid, _set_srid)
+
+    # #### Output Methods ####
+    def _geos_ptr(self):
+        from django.contrib.gis.geos import GEOSGeometry
+        return GEOSGeometry._from_wkb(self.wkb)
+
+    @property
+    def geos(self):
+        "Return a GEOSGeometry object from this OGRGeometry."
+        from django.contrib.gis.geos import GEOSGeometry
+        return GEOSGeometry(self._geos_ptr(), self.srid)
+
+    @property
+    def gml(self):
+        "Return the GML representation of the Geometry."
+        return capi.to_gml(self.ptr)
+
+    @property
+    def hex(self):
+        "Return the hexadecimal representation of the WKB (a string)."
+        return b2a_hex(self.wkb).upper()
+
+    @property
+    def json(self):
+        """
+        Return the GeoJSON representation of this Geometry.
+        """
+        return capi.to_json(self.ptr)
+    geojson = json
+
+    @property
+    def kml(self):
+        "Return the KML representation of the Geometry."
+        return capi.to_kml(self.ptr, None)
+
+    @property
+    def wkb_size(self):
+        "Return the size of the WKB buffer."
+        return capi.get_wkbsize(self.ptr)
+
+    @property
+    def wkb(self):
+        "Return the WKB representation of the Geometry."
+        if sys.byteorder == 'little':
+            byteorder = 1  # wkbNDR (from ogr_core.h)
+        else:
+            byteorder = 0  # wkbXDR
+        sz = self.wkb_size
+        # Creating the unsigned character buffer, and passing it in by reference.
+        buf = (c_ubyte * sz)()
+        capi.to_wkb(self.ptr, byteorder, byref(buf))
+        # Returning a buffer of the string at the pointer.
+        return memoryview(string_at(buf, sz))
+
+    @property
+    def wkt(self):
+        "Return the WKT representation of the Geometry."
+        return capi.to_wkt(self.ptr, byref(c_char_p()))
+
+    @property
+    def ewkt(self):
+        "Return the EWKT representation of the Geometry."
+        srs = self.srs
+        if srs and srs.srid:
+            return 'SRID=%s;%s' % (srs.srid, self.wkt)
+        else:
+            return self.wkt
+
+    # #### Geometry Methods ####
+    def clone(self):
+        "Clone this OGR Geometry."
+        return OGRGeometry(capi.clone_geom(self.ptr), self.srs)
+
+    def close_rings(self):
+        """
+        If there are any rings within this geometry that have not been
+        closed, this routine will do so by adding the starting point at the
+        end.
+        """
+        # Closing the open rings.
+        capi.geom_close_rings(self.ptr)
+
+    def transform(self, coord_trans, clone=False):
+        """
+        Transform this geometry to a different spatial reference system.
+        May take a CoordTransform object, a SpatialReference object, string
+        WKT or PROJ.4, and/or an integer SRID.  By default, return nothing
+        and transform the geometry in-place. However, if the `clone` keyword is
+        set, return a transformed clone of this geometry.
+        """
+        if clone:
+            klone = self.clone()
+            klone.transform(coord_trans)
+            return klone
+
+        # Depending on the input type, use the appropriate OGR routine
+        # to perform the transformation.
+        if isinstance(coord_trans, CoordTransform):
+            capi.geom_transform(self.ptr, coord_trans.ptr)
+        elif isinstance(coord_trans, SpatialReference):
+            capi.geom_transform_to(self.ptr, coord_trans.ptr)
+        elif isinstance(coord_trans, (int, str)):
+            sr = SpatialReference(coord_trans)
+            capi.geom_transform_to(self.ptr, sr.ptr)
+        else:
+            raise TypeError('Transform only accepts CoordTransform, '
+                            'SpatialReference, string, and integer objects.')
+
+    # #### Topology Methods ####
+    def _topology(self, func, other):
+        """A generalized function for topology operations, takes a GDAL function and
+        the other geometry to perform the operation on."""
+        if not isinstance(other, OGRGeometry):
+            raise TypeError('Must use another OGRGeometry object for topology operations!')
+
+        # Returning the output of the given function with the other geometry's
+        # pointer.
+        return func(self.ptr, other.ptr)
+
+    def intersects(self, other):
+        "Return True if this geometry intersects with the other."
+        return self._topology(capi.ogr_intersects, other)
+
+    def equals(self, other):
+        "Return True if this geometry is equivalent to the other."
+        return self._topology(capi.ogr_equals, other)
+
+    def disjoint(self, other):
+        "Return True if this geometry and the other are spatially disjoint."
+        return self._topology(capi.ogr_disjoint, other)
+
+    def touches(self, other):
+        "Return True if this geometry touches the other."
+        return self._topology(capi.ogr_touches, other)
+
+    def crosses(self, other):
+        "Return True if this geometry crosses the other."
+        return self._topology(capi.ogr_crosses, other)
+
+    def within(self, other):
+        "Return True if this geometry is within the other."
+        return self._topology(capi.ogr_within, other)
+
+    def contains(self, other):
+        "Return True if this geometry contains the other."
+        return self._topology(capi.ogr_contains, other)
+
+    def overlaps(self, other):
+        "Return True if this geometry overlaps the other."
+        return self._topology(capi.ogr_overlaps, other)
+
+    # #### Geometry-generation Methods ####
+    def _geomgen(self, gen_func, other=None):
+        "A helper routine for the OGR routines that generate geometries."
+        if isinstance(other, OGRGeometry):
+            return OGRGeometry(gen_func(self.ptr, other.ptr), self.srs)
+        else:
+            return OGRGeometry(gen_func(self.ptr), self.srs)
+
+    @property
+    def boundary(self):
+        "Return the boundary of this geometry."
+        return self._geomgen(capi.get_boundary)
+
+    @property
+    def convex_hull(self):
+        """
+        Return the smallest convex Polygon that contains all the points in
+        this Geometry.
+        """
+        return self._geomgen(capi.geom_convex_hull)
+
+    def difference(self, other):
+        """
+        Return a new geometry consisting of the region which is the difference
+        of this geometry and the other.
+        """
+        return self._geomgen(capi.geom_diff, other)
+
+    def intersection(self, other):
+        """
+        Return a new geometry consisting of the region of intersection of this
+        geometry and the other.
+        """
+        return self._geomgen(capi.geom_intersection, other)
+
+    def sym_difference(self, other):
+        """
+        Return a new geometry which is the symmetric difference of this
+        geometry and the other.
+        """
+        return self._geomgen(capi.geom_sym_diff, other)
+
+    def union(self, other):
+        """
+        Return a new geometry consisting of the region which is the union of
+        this geometry and the other.
+        """
+        return self._geomgen(capi.geom_union, other)
+
+
+# The subclasses for OGR Geometry.
+class Point(OGRGeometry):
+
+    def _geos_ptr(self):
+        from django.contrib.gis import geos
+        return geos.Point._create_empty() if self.empty else super()._geos_ptr()
+
+    @classmethod
+    def _create_empty(cls):
+        return capi.create_geom(OGRGeomType('point').num)
+
+    @property
+    def x(self):
+        "Return the X coordinate for this Point."
+        return capi.getx(self.ptr, 0)
+
+    @property
+    def y(self):
+        "Return the Y coordinate for this Point."
+        return capi.gety(self.ptr, 0)
+
+    @property
+    def z(self):
+        "Return the Z coordinate for this Point."
+        if self.coord_dim == 3:
+            return capi.getz(self.ptr, 0)
+
+    @property
+    def tuple(self):
+        "Return the tuple of this point."
+        if self.coord_dim == 2:
+            return (self.x, self.y)
+        elif self.coord_dim == 3:
+            return (self.x, self.y, self.z)
+    coords = tuple
+
+
+class LineString(OGRGeometry):
+
+    def __getitem__(self, index):
+        "Return the Point at the given index."
+        if 0 <= index < self.point_count:
+            x, y, z = c_double(), c_double(), c_double()
+            capi.get_point(self.ptr, index, byref(x), byref(y), byref(z))
+            dim = self.coord_dim
+            if dim == 1:
+                return (x.value,)
+            elif dim == 2:
+                return (x.value, y.value)
+            elif dim == 3:
+                return (x.value, y.value, z.value)
+        else:
+            raise IndexError('Index out of range when accessing points of a line string: %s.' % index)
+
+    def __len__(self):
+        "Return the number of points in the LineString."
+        return self.point_count
+
+    @property
+    def tuple(self):
+        "Return the tuple representation of this LineString."
+        return tuple(self[i] for i in range(len(self)))
+    coords = tuple
+
+    def _listarr(self, func):
+        """
+        Internal routine that returns a sequence (list) corresponding with
+        the given function.
+        """
+        return [func(self.ptr, i) for i in range(len(self))]
+
+    @property
+    def x(self):
+        "Return the X coordinates in a list."
+        return self._listarr(capi.getx)
+
+    @property
+    def y(self):
+        "Return the Y coordinates in a list."
+        return self._listarr(capi.gety)
+
+    @property
+    def z(self):
+        "Return the Z coordinates in a list."
+        if self.coord_dim == 3:
+            return self._listarr(capi.getz)
+
+
+# LinearRings are used in Polygons.
+class LinearRing(LineString):
+    pass
+
+
+class Polygon(OGRGeometry):
+
+    def __len__(self):
+        "Return the number of interior rings in this Polygon."
+        return self.geom_count
+
+    def __getitem__(self, index):
+        "Get the ring at the specified index."
+        if 0 <= index < self.geom_count:
+            return OGRGeometry(capi.clone_geom(capi.get_geom_ref(self.ptr, index)), self.srs)
+        else:
+            raise IndexError('Index out of range when accessing rings of a polygon: %s.' % index)
+
+    # Polygon Properties
+    @property
+    def shell(self):
+        "Return the shell of this Polygon."
+        return self[0]  # First ring is the shell
+    exterior_ring = shell
+
+    @property
+    def tuple(self):
+        "Return a tuple of LinearRing coordinate tuples."
+        return tuple(self[i].tuple for i in range(self.geom_count))
+    coords = tuple
+
+    @property
+    def point_count(self):
+        "Return the number of Points in this Polygon."
+        # Summing up the number of points in each ring of the Polygon.
+        return sum(self[i].point_count for i in range(self.geom_count))
+
+    @property
+    def centroid(self):
+        "Return the centroid (a Point) of this Polygon."
+        # The centroid is a Point, create a geometry for this.
+        p = OGRGeometry(OGRGeomType('Point'))
+        capi.get_centroid(self.ptr, p.ptr)
+        return p
+
+
+# Geometry Collection base class.
+class GeometryCollection(OGRGeometry):
+    "The Geometry Collection class."
+
+    def __getitem__(self, index):
+        "Get the Geometry at the specified index."
+        if 0 <= index < self.geom_count:
+            return OGRGeometry(capi.clone_geom(capi.get_geom_ref(self.ptr, index)), self.srs)
+        else:
+            raise IndexError('Index out of range when accessing geometry in a collection: %s.' % index)
+
+    def __len__(self):
+        "Return the number of geometries in this Geometry Collection."
+        return self.geom_count
+
+    def add(self, geom):
+        "Add the geometry to this Geometry Collection."
+        if isinstance(geom, OGRGeometry):
+            if isinstance(geom, self.__class__):
+                for g in geom:
+                    capi.add_geom(self.ptr, g.ptr)
+            else:
+                capi.add_geom(self.ptr, geom.ptr)
+        elif isinstance(geom, str):
+            tmp = OGRGeometry(geom)
+            capi.add_geom(self.ptr, tmp.ptr)
+        else:
+            raise GDALException('Must add an OGRGeometry.')
+
+    @property
+    def point_count(self):
+        "Return the number of Points in this Geometry Collection."
+        # Summing up the number of points in each geometry in this collection
+        return sum(self[i].point_count for i in range(self.geom_count))
+
+    @property
+    def tuple(self):
+        "Return a tuple representation of this Geometry Collection."
+        return tuple(self[i].tuple for i in range(self.geom_count))
+    coords = tuple
+
+
+# Multiple Geometry types.
+class MultiPoint(GeometryCollection):
+    pass
+
+
+class MultiLineString(GeometryCollection):
+    pass
+
+
+class MultiPolygon(GeometryCollection):
+    pass
+
+
+# Class mapping dictionary (using the OGRwkbGeometryType as the key)
+GEO_CLASSES = {
+    1: Point,
+    2: LineString,
+    3: Polygon,
+    4: MultiPoint,
+    5: MultiLineString,
+    6: MultiPolygon,
+    7: GeometryCollection,
+    101: LinearRing,
+    1 + OGRGeomType.wkb25bit: Point,
+    2 + OGRGeomType.wkb25bit: LineString,
+    3 + OGRGeomType.wkb25bit: Polygon,
+    4 + OGRGeomType.wkb25bit: MultiPoint,
+    5 + OGRGeomType.wkb25bit: MultiLineString,
+    6 + OGRGeomType.wkb25bit: MultiPolygon,
+    7 + OGRGeomType.wkb25bit: GeometryCollection,
+}
Index: venv/Lib/site-packages/django/contrib/sites/migrations/0001_initial.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/sites/migrations/0001_initial.py b/venv/Lib/site-packages/django/contrib/sites/migrations/0001_initial.py
new file mode 100644
--- /dev/null	(date 1617030485622)
+++ b/venv/Lib/site-packages/django/contrib/sites/migrations/0001_initial.py	(date 1617030485622)
@@ -0,0 +1,31 @@
+import django.contrib.sites.models
+from django.contrib.sites.models import _simple_domain_name_validator
+from django.db import migrations, models
+
+
+class Migration(migrations.Migration):
+
+    dependencies = []
+
+    operations = [
+        migrations.CreateModel(
+            name='Site',
+            fields=[
+                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),
+                ('domain', models.CharField(
+                    max_length=100, verbose_name='domain name', validators=[_simple_domain_name_validator]
+                )),
+                ('name', models.CharField(max_length=50, verbose_name='display name')),
+            ],
+            options={
+                'ordering': ['domain'],
+                'db_table': 'django_site',
+                'verbose_name': 'site',
+                'verbose_name_plural': 'sites',
+            },
+            bases=(models.Model,),
+            managers=[
+                ('objects', django.contrib.sites.models.SiteManager()),
+            ],
+        ),
+    ]
Index: venv/Lib/site-packages/django/contrib/gis/gdal/geomtype.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/gis/gdal/geomtype.py b/venv/Lib/site-packages/django/contrib/gis/gdal/geomtype.py
new file mode 100644
--- /dev/null	(date 1617030484359)
+++ b/venv/Lib/site-packages/django/contrib/gis/gdal/geomtype.py	(date 1617030484359)
@@ -0,0 +1,95 @@
+from django.contrib.gis.gdal.error import GDALException
+
+
+class OGRGeomType:
+    "Encapsulate OGR Geometry Types."
+
+    wkb25bit = -2147483648
+
+    # Dictionary of acceptable OGRwkbGeometryType s and their string names.
+    _types = {
+        0: 'Unknown',
+        1: 'Point',
+        2: 'LineString',
+        3: 'Polygon',
+        4: 'MultiPoint',
+        5: 'MultiLineString',
+        6: 'MultiPolygon',
+        7: 'GeometryCollection',
+        100: 'None',
+        101: 'LinearRing',
+        102: 'PointZ',
+        1 + wkb25bit: 'Point25D',
+        2 + wkb25bit: 'LineString25D',
+        3 + wkb25bit: 'Polygon25D',
+        4 + wkb25bit: 'MultiPoint25D',
+        5 + wkb25bit: 'MultiLineString25D',
+        6 + wkb25bit: 'MultiPolygon25D',
+        7 + wkb25bit: 'GeometryCollection25D',
+    }
+    # Reverse type dictionary, keyed by lowercase of the name.
+    _str_types = {v.lower(): k for k, v in _types.items()}
+
+    def __init__(self, type_input):
+        "Figure out the correct OGR Type based upon the input."
+        if isinstance(type_input, OGRGeomType):
+            num = type_input.num
+        elif isinstance(type_input, str):
+            type_input = type_input.lower()
+            if type_input == 'geometry':
+                type_input = 'unknown'
+            num = self._str_types.get(type_input)
+            if num is None:
+                raise GDALException('Invalid OGR String Type "%s"' % type_input)
+        elif isinstance(type_input, int):
+            if type_input not in self._types:
+                raise GDALException('Invalid OGR Integer Type: %d' % type_input)
+            num = type_input
+        else:
+            raise TypeError('Invalid OGR input type given.')
+
+        # Setting the OGR geometry type number.
+        self.num = num
+
+    def __str__(self):
+        "Return the value of the name property."
+        return self.name
+
+    def __eq__(self, other):
+        """
+        Do an equivalence test on the OGR type with the given
+        other OGRGeomType, the short-hand string, or the integer.
+        """
+        if isinstance(other, OGRGeomType):
+            return self.num == other.num
+        elif isinstance(other, str):
+            return self.name.lower() == other.lower()
+        elif isinstance(other, int):
+            return self.num == other
+        else:
+            return False
+
+    @property
+    def name(self):
+        "Return a short-hand string form of the OGR Geometry type."
+        return self._types[self.num]
+
+    @property
+    def django(self):
+        "Return the Django GeometryField for this OGR Type."
+        s = self.name.replace('25D', '')
+        if s in ('LinearRing', 'None'):
+            return None
+        elif s == 'Unknown':
+            s = 'Geometry'
+        elif s == 'PointZ':
+            s = 'Point'
+        return s + 'Field'
+
+    def to_multi(self):
+        """
+        Transform Point, LineString, Polygon, and their 25D equivalents
+        to their Multi... counterpart.
+        """
+        if self.name.startswith(('Point', 'LineString', 'Polygon')):
+            self.num += 3
Index: venv/Lib/site-packages/django/contrib/gis/gdal/layer.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/gis/gdal/layer.py b/venv/Lib/site-packages/django/contrib/gis/gdal/layer.py
new file mode 100644
--- /dev/null	(date 1617030484359)
+++ b/venv/Lib/site-packages/django/contrib/gis/gdal/layer.py	(date 1617030484359)
@@ -0,0 +1,215 @@
+from ctypes import byref, c_double
+
+from django.contrib.gis.gdal.base import GDALBase
+from django.contrib.gis.gdal.envelope import Envelope, OGREnvelope
+from django.contrib.gis.gdal.error import GDALException, SRSException
+from django.contrib.gis.gdal.feature import Feature
+from django.contrib.gis.gdal.field import OGRFieldTypes
+from django.contrib.gis.gdal.geometries import OGRGeometry
+from django.contrib.gis.gdal.geomtype import OGRGeomType
+from django.contrib.gis.gdal.prototypes import (
+    ds as capi, geom as geom_api, srs as srs_api,
+)
+from django.contrib.gis.gdal.srs import SpatialReference
+from django.utils.encoding import force_bytes, force_str
+
+
+# For more information, see the OGR C API source code:
+#  https://www.gdal.org/ogr__api_8h.html
+#
+# The OGR_L_* routines are relevant here.
+class Layer(GDALBase):
+    "A class that wraps an OGR Layer, needs to be instantiated from a DataSource object."
+
+    def __init__(self, layer_ptr, ds):
+        """
+        Initialize on an OGR C pointer to the Layer and the `DataSource` object
+        that owns this layer.  The `DataSource` object is required so that a
+        reference to it is kept with this Layer.  This prevents garbage
+        collection of the `DataSource` while this Layer is still active.
+        """
+        if not layer_ptr:
+            raise GDALException('Cannot create Layer, invalid pointer given')
+        self.ptr = layer_ptr
+        self._ds = ds
+        self._ldefn = capi.get_layer_defn(self._ptr)
+        # Does the Layer support random reading?
+        self._random_read = self.test_capability(b'RandomRead')
+
+    def __getitem__(self, index):
+        "Get the Feature at the specified index."
+        if isinstance(index, int):
+            # An integer index was given -- we cannot do a check based on the
+            # number of features because the beginning and ending feature IDs
+            # are not guaranteed to be 0 and len(layer)-1, respectively.
+            if index < 0:
+                raise IndexError('Negative indices are not allowed on OGR Layers.')
+            return self._make_feature(index)
+        elif isinstance(index, slice):
+            # A slice was given
+            start, stop, stride = index.indices(self.num_feat)
+            return [self._make_feature(fid) for fid in range(start, stop, stride)]
+        else:
+            raise TypeError('Integers and slices may only be used when indexing OGR Layers.')
+
+    def __iter__(self):
+        "Iterate over each Feature in the Layer."
+        # ResetReading() must be called before iteration is to begin.
+        capi.reset_reading(self._ptr)
+        for i in range(self.num_feat):
+            yield Feature(capi.get_next_feature(self._ptr), self)
+
+    def __len__(self):
+        "The length is the number of features."
+        return self.num_feat
+
+    def __str__(self):
+        "The string name of the layer."
+        return self.name
+
+    def _make_feature(self, feat_id):
+        """
+        Helper routine for __getitem__ that constructs a Feature from the given
+        Feature ID.  If the OGR Layer does not support random-access reading,
+        then each feature of the layer will be incremented through until the
+        a Feature is found matching the given feature ID.
+        """
+        if self._random_read:
+            # If the Layer supports random reading, return.
+            try:
+                return Feature(capi.get_feature(self.ptr, feat_id), self)
+            except GDALException:
+                pass
+        else:
+            # Random access isn't supported, have to increment through
+            # each feature until the given feature ID is encountered.
+            for feat in self:
+                if feat.fid == feat_id:
+                    return feat
+        # Should have returned a Feature, raise an IndexError.
+        raise IndexError('Invalid feature id: %s.' % feat_id)
+
+    # #### Layer properties ####
+    @property
+    def extent(self):
+        "Return the extent (an Envelope) of this layer."
+        env = OGREnvelope()
+        capi.get_extent(self.ptr, byref(env), 1)
+        return Envelope(env)
+
+    @property
+    def name(self):
+        "Return the name of this layer in the Data Source."
+        name = capi.get_fd_name(self._ldefn)
+        return force_str(name, self._ds.encoding, strings_only=True)
+
+    @property
+    def num_feat(self, force=1):
+        "Return the number of features in the Layer."
+        return capi.get_feature_count(self.ptr, force)
+
+    @property
+    def num_fields(self):
+        "Return the number of fields in the Layer."
+        return capi.get_field_count(self._ldefn)
+
+    @property
+    def geom_type(self):
+        "Return the geometry type (OGRGeomType) of the Layer."
+        return OGRGeomType(capi.get_fd_geom_type(self._ldefn))
+
+    @property
+    def srs(self):
+        "Return the Spatial Reference used in this Layer."
+        try:
+            ptr = capi.get_layer_srs(self.ptr)
+            return SpatialReference(srs_api.clone_srs(ptr))
+        except SRSException:
+            return None
+
+    @property
+    def fields(self):
+        """
+        Return a list of string names corresponding to each of the Fields
+        available in this Layer.
+        """
+        return [force_str(
+            capi.get_field_name(capi.get_field_defn(self._ldefn, i)),
+            self._ds.encoding, strings_only=True,
+        ) for i in range(self.num_fields)]
+
+    @property
+    def field_types(self):
+        """
+        Return a list of the types of fields in this Layer.  For example,
+        return the list [OFTInteger, OFTReal, OFTString] for an OGR layer that
+        has an integer, a floating-point, and string fields.
+        """
+        return [OGRFieldTypes[capi.get_field_type(capi.get_field_defn(self._ldefn, i))]
+                for i in range(self.num_fields)]
+
+    @property
+    def field_widths(self):
+        "Return a list of the maximum field widths for the features."
+        return [capi.get_field_width(capi.get_field_defn(self._ldefn, i))
+                for i in range(self.num_fields)]
+
+    @property
+    def field_precisions(self):
+        "Return the field precisions for the features."
+        return [capi.get_field_precision(capi.get_field_defn(self._ldefn, i))
+                for i in range(self.num_fields)]
+
+    def _get_spatial_filter(self):
+        try:
+            return OGRGeometry(geom_api.clone_geom(capi.get_spatial_filter(self.ptr)))
+        except GDALException:
+            return None
+
+    def _set_spatial_filter(self, filter):
+        if isinstance(filter, OGRGeometry):
+            capi.set_spatial_filter(self.ptr, filter.ptr)
+        elif isinstance(filter, (tuple, list)):
+            if not len(filter) == 4:
+                raise ValueError('Spatial filter list/tuple must have 4 elements.')
+            # Map c_double onto params -- if a bad type is passed in it
+            # will be caught here.
+            xmin, ymin, xmax, ymax = map(c_double, filter)
+            capi.set_spatial_filter_rect(self.ptr, xmin, ymin, xmax, ymax)
+        elif filter is None:
+            capi.set_spatial_filter(self.ptr, None)
+        else:
+            raise TypeError('Spatial filter must be either an OGRGeometry instance, a 4-tuple, or None.')
+
+    spatial_filter = property(_get_spatial_filter, _set_spatial_filter)
+
+    # #### Layer Methods ####
+    def get_fields(self, field_name):
+        """
+        Return a list containing the given field name for every Feature
+        in the Layer.
+        """
+        if field_name not in self.fields:
+            raise GDALException('invalid field name: %s' % field_name)
+        return [feat.get(field_name) for feat in self]
+
+    def get_geoms(self, geos=False):
+        """
+        Return a list containing the OGRGeometry for every Feature in
+        the Layer.
+        """
+        if geos:
+            from django.contrib.gis.geos import GEOSGeometry
+            return [GEOSGeometry(feat.geom.wkb) for feat in self]
+        else:
+            return [feat.geom for feat in self]
+
+    def test_capability(self, capability):
+        """
+        Return a bool indicating whether the this Layer supports the given
+        capability (a string).  Valid capability strings include:
+          'RandomRead', 'SequentialWrite', 'RandomWrite', 'FastSpatialFilter',
+          'FastFeatureCount', 'FastGetExtent', 'CreateField', 'Transactions',
+          'DeleteFeature', and 'FastSetNextByIndex'.
+        """
+        return bool(capi.test_capability(self.ptr, force_bytes(capability)))
Index: venv/Lib/site-packages/django/contrib/gis/gdal/libgdal.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/gis/gdal/libgdal.py b/venv/Lib/site-packages/django/contrib/gis/gdal/libgdal.py
new file mode 100644
--- /dev/null	(date 1617030484360)
+++ b/venv/Lib/site-packages/django/contrib/gis/gdal/libgdal.py	(date 1617030484360)
@@ -0,0 +1,120 @@
+import logging
+import os
+import re
+from ctypes import CDLL, CFUNCTYPE, c_char_p, c_int
+from ctypes.util import find_library
+
+from django.contrib.gis.gdal.error import GDALException
+from django.core.exceptions import ImproperlyConfigured
+
+logger = logging.getLogger('django.contrib.gis')
+
+# Custom library path set?
+try:
+    from django.conf import settings
+    lib_path = settings.GDAL_LIBRARY_PATH
+except (AttributeError, ImportError, ImproperlyConfigured, OSError):
+    lib_path = None
+
+if lib_path:
+    lib_names = None
+elif os.name == 'nt':
+    # Windows NT shared libraries
+    lib_names = ['gdal301', 'gdal300', 'gdal204', 'gdal203', 'gdal202', 'gdal201', 'gdal20']
+elif os.name == 'posix':
+    # *NIX library names.
+    lib_names = [
+        'gdal', 'GDAL',
+        'gdal3.1.0', 'gdal3.0.0',
+        'gdal2.4.0', 'gdal2.3.0', 'gdal2.2.0', 'gdal2.1.0', 'gdal2.0.0',
+    ]
+else:
+    raise ImproperlyConfigured('GDAL is unsupported on OS "%s".' % os.name)
+
+# Using the ctypes `find_library` utility  to find the
+# path to the GDAL library from the list of library names.
+if lib_names:
+    for lib_name in lib_names:
+        lib_path = find_library(lib_name)
+        if lib_path is not None:
+            break
+
+if lib_path is None:
+    raise ImproperlyConfigured(
+        'Could not find the GDAL library (tried "%s"). Is GDAL installed? '
+        'If it is, try setting GDAL_LIBRARY_PATH in your settings.'
+        % '", "'.join(lib_names)
+    )
+
+# This loads the GDAL/OGR C library
+lgdal = CDLL(lib_path)
+
+# On Windows, the GDAL binaries have some OSR routines exported with
+# STDCALL, while others are not.  Thus, the library will also need to
+# be loaded up as WinDLL for said OSR functions that require the
+# different calling convention.
+if os.name == 'nt':
+    from ctypes import WinDLL
+    lwingdal = WinDLL(lib_path)
+
+
+def std_call(func):
+    """
+    Return the correct STDCALL function for certain OSR routines on Win32
+    platforms.
+    """
+    if os.name == 'nt':
+        return lwingdal[func]
+    else:
+        return lgdal[func]
+
+
+# #### Version-information functions. ####
+
+# Return GDAL library version information with the given key.
+_version_info = std_call('GDALVersionInfo')
+_version_info.argtypes = [c_char_p]
+_version_info.restype = c_char_p
+
+
+def gdal_version():
+    "Return only the GDAL version number information."
+    return _version_info(b'RELEASE_NAME')
+
+
+def gdal_full_version():
+    "Return the full GDAL version information."
+    return _version_info(b'')
+
+
+def gdal_version_info():
+    ver = gdal_version()
+    m = re.match(br'^(?P<major>\d+)\.(?P<minor>\d+)(?:\.(?P<subminor>\d+))?', ver)
+    if not m:
+        raise GDALException('Could not parse GDAL version string "%s"' % ver)
+    major, minor, subminor = m.groups()
+    return (int(major), int(minor), subminor and int(subminor))
+
+
+GDAL_VERSION = gdal_version_info()
+
+# Set library error handling so as errors are logged
+CPLErrorHandler = CFUNCTYPE(None, c_int, c_int, c_char_p)
+
+
+def err_handler(error_class, error_number, message):
+    logger.error('GDAL_ERROR %d: %s', error_number, message)
+
+
+err_handler = CPLErrorHandler(err_handler)
+
+
+def function(name, args, restype):
+    func = std_call(name)
+    func.argtypes = args
+    func.restype = restype
+    return func
+
+
+set_error_handler = function('CPLSetErrorHandler', [CPLErrorHandler], CPLErrorHandler)
+set_error_handler(err_handler)
Index: venv/Lib/site-packages/django/contrib/gis/gdal/LICENSE
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/gis/gdal/LICENSE b/venv/Lib/site-packages/django/contrib/gis/gdal/LICENSE
new file mode 100644
--- /dev/null	(date 1617030484355)
+++ b/venv/Lib/site-packages/django/contrib/gis/gdal/LICENSE	(date 1617030484355)
@@ -0,0 +1,28 @@
+Copyright (c) 2007-2009, Justin Bronn
+All rights reserved.
+
+Redistribution and use in source and binary forms, with or without modification,
+are permitted provided that the following conditions are met:
+
+    1. Redistributions of source code must retain the above copyright notice,
+       this list of conditions and the following disclaimer.
+
+    2. Redistributions in binary form must reproduce the above copyright
+       notice, this list of conditions and the following disclaimer in the
+       documentation and/or other materials provided with the distribution.
+
+    3. Neither the name of OGRGeometry nor the names of its contributors may be used
+       to endorse or promote products derived from this software without
+       specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
+ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
+ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
Index: venv/Lib/site-packages/django/contrib/gis/gdal/srs.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/gis/gdal/srs.py b/venv/Lib/site-packages/django/contrib/gis/gdal/srs.py
new file mode 100644
--- /dev/null	(date 1617030484360)
+++ b/venv/Lib/site-packages/django/contrib/gis/gdal/srs.py	(date 1617030484360)
@@ -0,0 +1,354 @@
+"""
+  The Spatial Reference class, represents OGR Spatial Reference objects.
+
+  Example:
+  >>> from django.contrib.gis.gdal import SpatialReference
+  >>> srs = SpatialReference('WGS84')
+  >>> print(srs)
+  GEOGCS["WGS 84",
+      DATUM["WGS_1984",
+          SPHEROID["WGS 84",6378137,298.257223563,
+              AUTHORITY["EPSG","7030"]],
+          TOWGS84[0,0,0,0,0,0,0],
+          AUTHORITY["EPSG","6326"]],
+      PRIMEM["Greenwich",0,
+          AUTHORITY["EPSG","8901"]],
+      UNIT["degree",0.01745329251994328,
+          AUTHORITY["EPSG","9122"]],
+      AUTHORITY["EPSG","4326"]]
+  >>> print(srs.proj)
+  +proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs
+  >>> print(srs.ellipsoid)
+  (6378137.0, 6356752.3142451793, 298.25722356300003)
+  >>> print(srs.projected, srs.geographic)
+  False True
+  >>> srs.import_epsg(32140)
+  >>> print(srs.name)
+  NAD83 / Texas South Central
+"""
+from ctypes import byref, c_char_p, c_int
+from enum import IntEnum
+
+from django.contrib.gis.gdal.base import GDALBase
+from django.contrib.gis.gdal.error import SRSException
+from django.contrib.gis.gdal.libgdal import GDAL_VERSION
+from django.contrib.gis.gdal.prototypes import srs as capi
+from django.utils.encoding import force_bytes, force_str
+
+
+class AxisOrder(IntEnum):
+    TRADITIONAL = 0
+    AUTHORITY = 1
+
+
+class SpatialReference(GDALBase):
+    """
+    A wrapper for the OGRSpatialReference object.  According to the GDAL Web site,
+    the SpatialReference object "provide[s] services to represent coordinate
+    systems (projections and datums) and to transform between them."
+    """
+    destructor = capi.release_srs
+
+    def __init__(self, srs_input='', srs_type='user', axis_order=None):
+        """
+        Create a GDAL OSR Spatial Reference object from the given input.
+        The input may be string of OGC Well Known Text (WKT), an integer
+        EPSG code, a PROJ.4 string, and/or a projection "well known" shorthand
+        string (one of 'WGS84', 'WGS72', 'NAD27', 'NAD83').
+        """
+        if not isinstance(axis_order, (type(None), AxisOrder)):
+            raise ValueError(
+                'SpatialReference.axis_order must be an AxisOrder instance.'
+            )
+        self.axis_order = axis_order or AxisOrder.TRADITIONAL
+        if srs_type == 'wkt':
+            self.ptr = capi.new_srs(c_char_p(b''))
+            self.import_wkt(srs_input)
+            if self.axis_order == AxisOrder.TRADITIONAL and GDAL_VERSION >= (3, 0):
+                capi.set_axis_strategy(self.ptr, self.axis_order)
+            elif self.axis_order != AxisOrder.TRADITIONAL and GDAL_VERSION < (3, 0):
+                raise ValueError('%s is not supported in GDAL < 3.0.' % self.axis_order)
+            return
+        elif isinstance(srs_input, str):
+            try:
+                # If SRID is a string, e.g., '4326', then make acceptable
+                # as user input.
+                srid = int(srs_input)
+                srs_input = 'EPSG:%d' % srid
+            except ValueError:
+                pass
+        elif isinstance(srs_input, int):
+            # EPSG integer code was input.
+            srs_type = 'epsg'
+        elif isinstance(srs_input, self.ptr_type):
+            srs = srs_input
+            srs_type = 'ogr'
+        else:
+            raise TypeError('Invalid SRS type "%s"' % srs_type)
+
+        if srs_type == 'ogr':
+            # Input is already an SRS pointer.
+            srs = srs_input
+        else:
+            # Creating a new SRS pointer, using the string buffer.
+            buf = c_char_p(b'')
+            srs = capi.new_srs(buf)
+
+        # If the pointer is NULL, throw an exception.
+        if not srs:
+            raise SRSException('Could not create spatial reference from: %s' % srs_input)
+        else:
+            self.ptr = srs
+
+        if self.axis_order == AxisOrder.TRADITIONAL and GDAL_VERSION >= (3, 0):
+            capi.set_axis_strategy(self.ptr, self.axis_order)
+        elif self.axis_order != AxisOrder.TRADITIONAL and GDAL_VERSION < (3, 0):
+            raise ValueError('%s is not supported in GDAL < 3.0.' % self.axis_order)
+        # Importing from either the user input string or an integer SRID.
+        if srs_type == 'user':
+            self.import_user_input(srs_input)
+        elif srs_type == 'epsg':
+            self.import_epsg(srs_input)
+
+    def __getitem__(self, target):
+        """
+        Return the value of the given string attribute node, None if the node
+        doesn't exist.  Can also take a tuple as a parameter, (target, child),
+        where child is the index of the attribute in the WKT.  For example:
+
+        >>> wkt = 'GEOGCS["WGS 84", DATUM["WGS_1984, ... AUTHORITY["EPSG","4326"]]'
+        >>> srs = SpatialReference(wkt) # could also use 'WGS84', or 4326
+        >>> print(srs['GEOGCS'])
+        WGS 84
+        >>> print(srs['DATUM'])
+        WGS_1984
+        >>> print(srs['AUTHORITY'])
+        EPSG
+        >>> print(srs['AUTHORITY', 1]) # The authority value
+        4326
+        >>> print(srs['TOWGS84', 4]) # the fourth value in this wkt
+        0
+        >>> print(srs['UNIT|AUTHORITY']) # For the units authority, have to use the pipe symbole.
+        EPSG
+        >>> print(srs['UNIT|AUTHORITY', 1]) # The authority value for the units
+        9122
+        """
+        if isinstance(target, tuple):
+            return self.attr_value(*target)
+        else:
+            return self.attr_value(target)
+
+    def __str__(self):
+        "Use 'pretty' WKT."
+        return self.pretty_wkt
+
+    # #### SpatialReference Methods ####
+    def attr_value(self, target, index=0):
+        """
+        The attribute value for the given target node (e.g. 'PROJCS'). The index
+        keyword specifies an index of the child node to return.
+        """
+        if not isinstance(target, str) or not isinstance(index, int):
+            raise TypeError
+        return capi.get_attr_value(self.ptr, force_bytes(target), index)
+
+    def auth_name(self, target):
+        "Return the authority name for the given string target node."
+        return capi.get_auth_name(self.ptr, force_bytes(target))
+
+    def auth_code(self, target):
+        "Return the authority code for the given string target node."
+        return capi.get_auth_code(self.ptr, force_bytes(target))
+
+    def clone(self):
+        "Return a clone of this SpatialReference object."
+        return SpatialReference(capi.clone_srs(self.ptr), axis_order=self.axis_order)
+
+    def from_esri(self):
+        "Morph this SpatialReference from ESRI's format to EPSG."
+        capi.morph_from_esri(self.ptr)
+
+    def identify_epsg(self):
+        """
+        This method inspects the WKT of this SpatialReference, and will
+        add EPSG authority nodes where an EPSG identifier is applicable.
+        """
+        capi.identify_epsg(self.ptr)
+
+    def to_esri(self):
+        "Morph this SpatialReference to ESRI's format."
+        capi.morph_to_esri(self.ptr)
+
+    def validate(self):
+        "Check to see if the given spatial reference is valid."
+        capi.srs_validate(self.ptr)
+
+    # #### Name & SRID properties ####
+    @property
+    def name(self):
+        "Return the name of this Spatial Reference."
+        if self.projected:
+            return self.attr_value('PROJCS')
+        elif self.geographic:
+            return self.attr_value('GEOGCS')
+        elif self.local:
+            return self.attr_value('LOCAL_CS')
+        else:
+            return None
+
+    @property
+    def srid(self):
+        "Return the SRID of top-level authority, or None if undefined."
+        try:
+            return int(self.attr_value('AUTHORITY', 1))
+        except (TypeError, ValueError):
+            return None
+
+    # #### Unit Properties ####
+    @property
+    def linear_name(self):
+        "Return the name of the linear units."
+        units, name = capi.linear_units(self.ptr, byref(c_char_p()))
+        return name
+
+    @property
+    def linear_units(self):
+        "Return the value of the linear units."
+        units, name = capi.linear_units(self.ptr, byref(c_char_p()))
+        return units
+
+    @property
+    def angular_name(self):
+        "Return the name of the angular units."
+        units, name = capi.angular_units(self.ptr, byref(c_char_p()))
+        return name
+
+    @property
+    def angular_units(self):
+        "Return the value of the angular units."
+        units, name = capi.angular_units(self.ptr, byref(c_char_p()))
+        return units
+
+    @property
+    def units(self):
+        """
+        Return a 2-tuple of the units value and the units name. Automatically
+        determine whether to return the linear or angular units.
+        """
+        units, name = None, None
+        if self.projected or self.local:
+            units, name = capi.linear_units(self.ptr, byref(c_char_p()))
+        elif self.geographic:
+            units, name = capi.angular_units(self.ptr, byref(c_char_p()))
+        if name is not None:
+            name = force_str(name)
+        return (units, name)
+
+    # #### Spheroid/Ellipsoid Properties ####
+    @property
+    def ellipsoid(self):
+        """
+        Return a tuple of the ellipsoid parameters:
+         (semimajor axis, semiminor axis, and inverse flattening)
+        """
+        return (self.semi_major, self.semi_minor, self.inverse_flattening)
+
+    @property
+    def semi_major(self):
+        "Return the Semi Major Axis for this Spatial Reference."
+        return capi.semi_major(self.ptr, byref(c_int()))
+
+    @property
+    def semi_minor(self):
+        "Return the Semi Minor Axis for this Spatial Reference."
+        return capi.semi_minor(self.ptr, byref(c_int()))
+
+    @property
+    def inverse_flattening(self):
+        "Return the Inverse Flattening for this Spatial Reference."
+        return capi.invflattening(self.ptr, byref(c_int()))
+
+    # #### Boolean Properties ####
+    @property
+    def geographic(self):
+        """
+        Return True if this SpatialReference is geographic
+         (root node is GEOGCS).
+        """
+        return bool(capi.isgeographic(self.ptr))
+
+    @property
+    def local(self):
+        "Return True if this SpatialReference is local (root node is LOCAL_CS)."
+        return bool(capi.islocal(self.ptr))
+
+    @property
+    def projected(self):
+        """
+        Return True if this SpatialReference is a projected coordinate system
+         (root node is PROJCS).
+        """
+        return bool(capi.isprojected(self.ptr))
+
+    # #### Import Routines #####
+    def import_epsg(self, epsg):
+        "Import the Spatial Reference from the EPSG code (an integer)."
+        capi.from_epsg(self.ptr, epsg)
+
+    def import_proj(self, proj):
+        "Import the Spatial Reference from a PROJ.4 string."
+        capi.from_proj(self.ptr, proj)
+
+    def import_user_input(self, user_input):
+        "Import the Spatial Reference from the given user input string."
+        capi.from_user_input(self.ptr, force_bytes(user_input))
+
+    def import_wkt(self, wkt):
+        "Import the Spatial Reference from OGC WKT (string)"
+        capi.from_wkt(self.ptr, byref(c_char_p(force_bytes(wkt))))
+
+    def import_xml(self, xml):
+        "Import the Spatial Reference from an XML string."
+        capi.from_xml(self.ptr, xml)
+
+    # #### Export Properties ####
+    @property
+    def wkt(self):
+        "Return the WKT representation of this Spatial Reference."
+        return capi.to_wkt(self.ptr, byref(c_char_p()))
+
+    @property
+    def pretty_wkt(self, simplify=0):
+        "Return the 'pretty' representation of the WKT."
+        return capi.to_pretty_wkt(self.ptr, byref(c_char_p()), simplify)
+
+    @property
+    def proj(self):
+        "Return the PROJ.4 representation for this Spatial Reference."
+        return capi.to_proj(self.ptr, byref(c_char_p()))
+
+    @property
+    def proj4(self):
+        "Alias for proj()."
+        return self.proj
+
+    @property
+    def xml(self, dialect=''):
+        "Return the XML representation of this Spatial Reference."
+        return capi.to_xml(self.ptr, byref(c_char_p()), force_bytes(dialect))
+
+
+class CoordTransform(GDALBase):
+    "The coordinate system transformation object."
+    destructor = capi.destroy_ct
+
+    def __init__(self, source, target):
+        "Initialize on a source and target SpatialReference objects."
+        if not isinstance(source, SpatialReference) or not isinstance(target, SpatialReference):
+            raise TypeError('source and target must be of type SpatialReference')
+        self.ptr = capi.new_ct(source._ptr, target._ptr)
+        self._srs1_name = source.name
+        self._srs2_name = target.name
+
+    def __str__(self):
+        return 'Transform from "%s" to "%s"' % (self._srs1_name, self._srs2_name)
Index: venv/Lib/site-packages/django/contrib/gis/gdal/__init__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/gis/gdal/__init__.py b/venv/Lib/site-packages/django/contrib/gis/gdal/__init__.py
new file mode 100644
--- /dev/null	(date 1617030484355)
+++ b/venv/Lib/site-packages/django/contrib/gis/gdal/__init__.py	(date 1617030484355)
@@ -0,0 +1,49 @@
+"""
+ This module houses ctypes interfaces for GDAL objects.  The following GDAL
+ objects are supported:
+
+ CoordTransform: Used for coordinate transformations from one spatial
+  reference system to another.
+
+ Driver: Wraps an OGR data source driver.
+
+ DataSource: Wrapper for the OGR data source object, supports
+  OGR-supported data sources.
+
+ Envelope: A ctypes structure for bounding boxes (GDAL library
+  not required).
+
+ OGRGeometry: Object for accessing OGR Geometry functionality.
+
+ OGRGeomType: A class for representing the different OGR Geometry
+  types (GDAL library not required).
+
+ SpatialReference: Represents OSR Spatial Reference objects.
+
+ The GDAL library will be imported from the system path using the default
+ library name for the current OS. The default library path may be overridden
+ by setting `GDAL_LIBRARY_PATH` in your settings with the path to the GDAL C
+ library on your system.
+"""
+from django.contrib.gis.gdal.datasource import DataSource
+from django.contrib.gis.gdal.driver import Driver
+from django.contrib.gis.gdal.envelope import Envelope
+from django.contrib.gis.gdal.error import (
+    GDALException, SRSException, check_err,
+)
+from django.contrib.gis.gdal.geometries import OGRGeometry
+from django.contrib.gis.gdal.geomtype import OGRGeomType
+from django.contrib.gis.gdal.libgdal import (
+    GDAL_VERSION, gdal_full_version, gdal_version,
+)
+from django.contrib.gis.gdal.raster.source import GDALRaster
+from django.contrib.gis.gdal.srs import (
+    AxisOrder, CoordTransform, SpatialReference,
+)
+
+__all__ = (
+    'AxisOrder', 'Driver', 'DataSource', 'CoordTransform', 'Envelope',
+    'GDALException', 'GDALRaster', 'GDAL_VERSION', 'OGRGeometry',
+    'OGRGeomType', 'SpatialReference', 'SRSException', 'check_err',
+    'gdal_version', 'gdal_full_version',
+)
Index: venv/Lib/site-packages/django/contrib/gis/geos/base.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/gis/geos/base.py b/venv/Lib/site-packages/django/contrib/gis/geos/base.py
new file mode 100644
--- /dev/null	(date 1617030484367)
+++ b/venv/Lib/site-packages/django/contrib/gis/geos/base.py	(date 1617030484367)
@@ -0,0 +1,6 @@
+from django.contrib.gis.geos.error import GEOSException
+from django.contrib.gis.ptr import CPointerBase
+
+
+class GEOSBase(CPointerBase):
+    null_ptr_exception_class = GEOSException
Index: venv/Lib/site-packages/django/contrib/gis/geos/collections.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/gis/geos/collections.py b/venv/Lib/site-packages/django/contrib/gis/geos/collections.py
new file mode 100644
--- /dev/null	(date 1617030484367)
+++ b/venv/Lib/site-packages/django/contrib/gis/geos/collections.py	(date 1617030484367)
@@ -0,0 +1,108 @@
+"""
+ This module houses the Geometry Collection objects:
+ GeometryCollection, MultiPoint, MultiLineString, and MultiPolygon
+"""
+from ctypes import byref, c_int, c_uint
+
+from django.contrib.gis.geos import prototypes as capi
+from django.contrib.gis.geos.geometry import GEOSGeometry, LinearGeometryMixin
+from django.contrib.gis.geos.libgeos import GEOM_PTR
+from django.contrib.gis.geos.linestring import LinearRing, LineString
+from django.contrib.gis.geos.point import Point
+from django.contrib.gis.geos.polygon import Polygon
+
+
+class GeometryCollection(GEOSGeometry):
+    _typeid = 7
+
+    def __init__(self, *args, **kwargs):
+        "Initialize a Geometry Collection from a sequence of Geometry objects."
+        # Checking the arguments
+        if len(args) == 1:
+            # If only one geometry provided or a list of geometries is provided
+            #  in the first argument.
+            if isinstance(args[0], (tuple, list)):
+                init_geoms = args[0]
+            else:
+                init_geoms = args
+        else:
+            init_geoms = args
+
+        # Ensuring that only the permitted geometries are allowed in this collection
+        # this is moved to list mixin super class
+        self._check_allowed(init_geoms)
+
+        # Creating the geometry pointer array.
+        collection = self._create_collection(len(init_geoms), init_geoms)
+        super().__init__(collection, **kwargs)
+
+    def __iter__(self):
+        "Iterate over each Geometry in the Collection."
+        for i in range(len(self)):
+            yield self[i]
+
+    def __len__(self):
+        "Return the number of geometries in this Collection."
+        return self.num_geom
+
+    # ### Methods for compatibility with ListMixin ###
+    def _create_collection(self, length, items):
+        # Creating the geometry pointer array.
+        geoms = (GEOM_PTR * length)(*[
+            # this is a little sloppy, but makes life easier
+            # allow GEOSGeometry types (python wrappers) or pointer types
+            capi.geom_clone(getattr(g, 'ptr', g)) for g in items
+        ])
+        return capi.create_collection(c_int(self._typeid), byref(geoms), c_uint(length))
+
+    def _get_single_internal(self, index):
+        return capi.get_geomn(self.ptr, index)
+
+    def _get_single_external(self, index):
+        "Return the Geometry from this Collection at the given index (0-based)."
+        # Checking the index and returning the corresponding GEOS geometry.
+        return GEOSGeometry(capi.geom_clone(self._get_single_internal(index)), srid=self.srid)
+
+    def _set_list(self, length, items):
+        "Create a new collection, and destroy the contents of the previous pointer."
+        prev_ptr = self.ptr
+        srid = self.srid
+        self.ptr = self._create_collection(length, items)
+        if srid:
+            self.srid = srid
+        capi.destroy_geom(prev_ptr)
+
+    _set_single = GEOSGeometry._set_single_rebuild
+    _assign_extended_slice = GEOSGeometry._assign_extended_slice_rebuild
+
+    @property
+    def kml(self):
+        "Return the KML for this Geometry Collection."
+        return '<MultiGeometry>%s</MultiGeometry>' % ''.join(g.kml for g in self)
+
+    @property
+    def tuple(self):
+        "Return a tuple of all the coordinates in this Geometry Collection"
+        return tuple(g.tuple for g in self)
+    coords = tuple
+
+
+# MultiPoint, MultiLineString, and MultiPolygon class definitions.
+class MultiPoint(GeometryCollection):
+    _allowed = Point
+    _typeid = 4
+
+
+class MultiLineString(LinearGeometryMixin, GeometryCollection):
+    _allowed = (LineString, LinearRing)
+    _typeid = 5
+
+
+class MultiPolygon(GeometryCollection):
+    _allowed = Polygon
+    _typeid = 6
+
+
+# Setting the allowed types here since GeometryCollection is defined before
+# its subclasses.
+GeometryCollection._allowed = (Point, LineString, LinearRing, Polygon, MultiPoint, MultiLineString, MultiPolygon)
Index: venv/Lib/site-packages/django/contrib/gis/geos/coordseq.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/gis/geos/coordseq.py b/venv/Lib/site-packages/django/contrib/gis/geos/coordseq.py
new file mode 100644
--- /dev/null	(date 1617030484367)
+++ b/venv/Lib/site-packages/django/contrib/gis/geos/coordseq.py	(date 1617030484367)
@@ -0,0 +1,216 @@
+"""
+ This module houses the GEOSCoordSeq object, which is used internally
+ by GEOSGeometry to house the actual coordinates of the Point,
+ LineString, and LinearRing geometries.
+"""
+from ctypes import byref, c_byte, c_double, c_uint
+
+from django.contrib.gis.geos import prototypes as capi
+from django.contrib.gis.geos.base import GEOSBase
+from django.contrib.gis.geos.error import GEOSException
+from django.contrib.gis.geos.libgeos import CS_PTR, geos_version_tuple
+from django.contrib.gis.shortcuts import numpy
+
+
+class GEOSCoordSeq(GEOSBase):
+    "The internal representation of a list of coordinates inside a Geometry."
+
+    ptr_type = CS_PTR
+
+    def __init__(self, ptr, z=False):
+        "Initialize from a GEOS pointer."
+        if not isinstance(ptr, CS_PTR):
+            raise TypeError('Coordinate sequence should initialize with a CS_PTR.')
+        self._ptr = ptr
+        self._z = z
+
+    def __iter__(self):
+        "Iterate over each point in the coordinate sequence."
+        for i in range(self.size):
+            yield self[i]
+
+    def __len__(self):
+        "Return the number of points in the coordinate sequence."
+        return self.size
+
+    def __str__(self):
+        "Return the string representation of the coordinate sequence."
+        return str(self.tuple)
+
+    def __getitem__(self, index):
+        "Return the coordinate sequence value at the given index."
+        self._checkindex(index)
+        return self._point_getter(index)
+
+    def __setitem__(self, index, value):
+        "Set the coordinate sequence value at the given index."
+        # Checking the input value
+        if isinstance(value, (list, tuple)):
+            pass
+        elif numpy and isinstance(value, numpy.ndarray):
+            pass
+        else:
+            raise TypeError('Must set coordinate with a sequence (list, tuple, or numpy array).')
+        # Checking the dims of the input
+        if self.dims == 3 and self._z:
+            n_args = 3
+            point_setter = self._set_point_3d
+        else:
+            n_args = 2
+            point_setter = self._set_point_2d
+        if len(value) != n_args:
+            raise TypeError('Dimension of value does not match.')
+        self._checkindex(index)
+        point_setter(index, value)
+
+    # #### Internal Routines ####
+    def _checkindex(self, index):
+        "Check the given index."
+        if not (0 <= index < self.size):
+            raise IndexError('invalid GEOS Geometry index: %s' % index)
+
+    def _checkdim(self, dim):
+        "Check the given dimension."
+        if dim < 0 or dim > 2:
+            raise GEOSException('invalid ordinate dimension "%d"' % dim)
+
+    def _get_x(self, index):
+        return capi.cs_getx(self.ptr, index, byref(c_double()))
+
+    def _get_y(self, index):
+        return capi.cs_gety(self.ptr, index, byref(c_double()))
+
+    def _get_z(self, index):
+        return capi.cs_getz(self.ptr, index, byref(c_double()))
+
+    def _set_x(self, index, value):
+        capi.cs_setx(self.ptr, index, value)
+
+    def _set_y(self, index, value):
+        capi.cs_sety(self.ptr, index, value)
+
+    def _set_z(self, index, value):
+        capi.cs_setz(self.ptr, index, value)
+
+    @property
+    def _point_getter(self):
+        return self._get_point_3d if self.dims == 3 and self._z else self._get_point_2d
+
+    def _get_point_2d(self, index):
+        return (self._get_x(index), self._get_y(index))
+
+    def _get_point_3d(self, index):
+        return (self._get_x(index), self._get_y(index), self._get_z(index))
+
+    def _set_point_2d(self, index, value):
+        x, y = value
+        self._set_x(index, x)
+        self._set_y(index, y)
+
+    def _set_point_3d(self, index, value):
+        x, y, z = value
+        self._set_x(index, x)
+        self._set_y(index, y)
+        self._set_z(index, z)
+
+    # #### Ordinate getting and setting routines ####
+    def getOrdinate(self, dimension, index):
+        "Return the value for the given dimension and index."
+        self._checkindex(index)
+        self._checkdim(dimension)
+        return capi.cs_getordinate(self.ptr, index, dimension, byref(c_double()))
+
+    def setOrdinate(self, dimension, index, value):
+        "Set the value for the given dimension and index."
+        self._checkindex(index)
+        self._checkdim(dimension)
+        capi.cs_setordinate(self.ptr, index, dimension, value)
+
+    def getX(self, index):
+        "Get the X value at the index."
+        return self.getOrdinate(0, index)
+
+    def setX(self, index, value):
+        "Set X with the value at the given index."
+        self.setOrdinate(0, index, value)
+
+    def getY(self, index):
+        "Get the Y value at the given index."
+        return self.getOrdinate(1, index)
+
+    def setY(self, index, value):
+        "Set Y with the value at the given index."
+        self.setOrdinate(1, index, value)
+
+    def getZ(self, index):
+        "Get Z with the value at the given index."
+        return self.getOrdinate(2, index)
+
+    def setZ(self, index, value):
+        "Set Z with the value at the given index."
+        self.setOrdinate(2, index, value)
+
+    # ### Dimensions ###
+    @property
+    def size(self):
+        "Return the size of this coordinate sequence."
+        return capi.cs_getsize(self.ptr, byref(c_uint()))
+
+    @property
+    def dims(self):
+        "Return the dimensions of this coordinate sequence."
+        return capi.cs_getdims(self.ptr, byref(c_uint()))
+
+    @property
+    def hasz(self):
+        """
+        Return whether this coordinate sequence is 3D. This property value is
+        inherited from the parent Geometry.
+        """
+        return self._z
+
+    # ### Other Methods ###
+    def clone(self):
+        "Clone this coordinate sequence."
+        return GEOSCoordSeq(capi.cs_clone(self.ptr), self.hasz)
+
+    @property
+    def kml(self):
+        "Return the KML representation for the coordinates."
+        # Getting the substitution string depending on whether the coordinates have
+        #  a Z dimension.
+        if self.hasz:
+            substr = '%s,%s,%s '
+        else:
+            substr = '%s,%s,0 '
+        return '<coordinates>%s</coordinates>' % \
+            ''.join(substr % self[i] for i in range(len(self))).strip()
+
+    @property
+    def tuple(self):
+        "Return a tuple version of this coordinate sequence."
+        n = self.size
+        get_point = self._point_getter
+        if n == 1:
+            return get_point(0)
+        return tuple(get_point(i) for i in range(n))
+
+    @property
+    def is_counterclockwise(self):
+        """Return whether this coordinate sequence is counterclockwise."""
+        if geos_version_tuple() < (3, 7):
+            # A modified shoelace algorithm to determine polygon orientation.
+            # See https://en.wikipedia.org/wiki/Shoelace_formula.
+            area = 0.0
+            n = len(self)
+            for i in range(n):
+                j = (i + 1) % n
+                area += self[i][0] * self[j][1]
+                area -= self[j][0] * self[i][1]
+            return area > 0.0
+        ret = c_byte()
+        if not capi.cs_is_ccw(self.ptr, byref(ret)):
+            raise GEOSException(
+                'Error encountered in GEOS C function "%s".' % capi.cs_is_ccw.func_name
+            )
+        return ret.value == 1
Index: venv/Lib/site-packages/django/contrib/gis/geos/error.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/gis/geos/error.py b/venv/Lib/site-packages/django/contrib/gis/geos/error.py
new file mode 100644
--- /dev/null	(date 1617030484368)
+++ b/venv/Lib/site-packages/django/contrib/gis/geos/error.py	(date 1617030484368)
@@ -0,0 +1,3 @@
+class GEOSException(Exception):
+    "The base GEOS exception, indicates a GEOS-related error."
+    pass
Index: venv/Lib/site-packages/django/contrib/gis/geos/factory.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/gis/geos/factory.py b/venv/Lib/site-packages/django/contrib/gis/geos/factory.py
new file mode 100644
--- /dev/null	(date 1617030484368)
+++ b/venv/Lib/site-packages/django/contrib/gis/geos/factory.py	(date 1617030484368)
@@ -0,0 +1,33 @@
+from django.contrib.gis.geos.geometry import GEOSGeometry, hex_regex, wkt_regex
+
+
+def fromfile(file_h):
+    """
+    Given a string file name, returns a GEOSGeometry. The file may contain WKB,
+    WKT, or HEX.
+    """
+    # If given a file name, get a real handle.
+    if isinstance(file_h, str):
+        with open(file_h, 'rb') as file_h:
+            buf = file_h.read()
+    else:
+        buf = file_h.read()
+
+    # If we get WKB need to wrap in memoryview(), so run through regexes.
+    if isinstance(buf, bytes):
+        try:
+            decoded = buf.decode()
+        except UnicodeDecodeError:
+            pass
+        else:
+            if wkt_regex.match(decoded) or hex_regex.match(decoded):
+                return GEOSGeometry(decoded)
+    else:
+        return GEOSGeometry(buf)
+
+    return GEOSGeometry(memoryview(buf))
+
+
+def fromstr(string, **kwargs):
+    "Given a string value, return a GEOSGeometry object."
+    return GEOSGeometry(string, **kwargs)
Index: venv/Lib/site-packages/django/contrib/gis/geos/geometry.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/gis/geos/geometry.py b/venv/Lib/site-packages/django/contrib/gis/geos/geometry.py
new file mode 100644
--- /dev/null	(date 1617030484369)
+++ b/venv/Lib/site-packages/django/contrib/gis/geos/geometry.py	(date 1617030484369)
@@ -0,0 +1,739 @@
+"""
+ This module contains the 'base' GEOSGeometry object -- all GEOS Geometries
+ inherit from this object.
+"""
+import re
+from ctypes import addressof, byref, c_double
+
+from django.contrib.gis import gdal
+from django.contrib.gis.geometry import hex_regex, json_regex, wkt_regex
+from django.contrib.gis.geos import prototypes as capi
+from django.contrib.gis.geos.base import GEOSBase
+from django.contrib.gis.geos.coordseq import GEOSCoordSeq
+from django.contrib.gis.geos.error import GEOSException
+from django.contrib.gis.geos.libgeos import GEOM_PTR
+from django.contrib.gis.geos.mutable_list import ListMixin
+from django.contrib.gis.geos.prepared import PreparedGeometry
+from django.contrib.gis.geos.prototypes.io import (
+    ewkb_w, wkb_r, wkb_w, wkt_r, wkt_w,
+)
+from django.utils.deconstruct import deconstructible
+from django.utils.encoding import force_bytes, force_str
+
+
+class GEOSGeometryBase(GEOSBase):
+
+    _GEOS_CLASSES = None
+
+    ptr_type = GEOM_PTR
+    destructor = capi.destroy_geom
+    has_cs = False  # Only Point, LineString, LinearRing have coordinate sequences
+
+    def __init__(self, ptr, cls):
+        self._ptr = ptr
+
+        # Setting the class type (e.g., Point, Polygon, etc.)
+        if type(self) in (GEOSGeometryBase, GEOSGeometry):
+            if cls is None:
+                if GEOSGeometryBase._GEOS_CLASSES is None:
+                    # Inner imports avoid import conflicts with GEOSGeometry.
+                    from .collections import (
+                        GeometryCollection, MultiLineString, MultiPoint,
+                        MultiPolygon,
+                    )
+                    from .linestring import LinearRing, LineString
+                    from .point import Point
+                    from .polygon import Polygon
+                    GEOSGeometryBase._GEOS_CLASSES = {
+                        0: Point,
+                        1: LineString,
+                        2: LinearRing,
+                        3: Polygon,
+                        4: MultiPoint,
+                        5: MultiLineString,
+                        6: MultiPolygon,
+                        7: GeometryCollection,
+                    }
+                cls = GEOSGeometryBase._GEOS_CLASSES[self.geom_typeid]
+            self.__class__ = cls
+        self._post_init()
+
+    def _post_init(self):
+        "Perform post-initialization setup."
+        # Setting the coordinate sequence for the geometry (will be None on
+        # geometries that do not have coordinate sequences)
+        self._cs = GEOSCoordSeq(capi.get_cs(self.ptr), self.hasz) if self.has_cs else None
+
+    def __copy__(self):
+        """
+        Return a clone because the copy of a GEOSGeometry may contain an
+        invalid pointer location if the original is garbage collected.
+        """
+        return self.clone()
+
+    def __deepcopy__(self, memodict):
+        """
+        The `deepcopy` routine is used by the `Node` class of django.utils.tree;
+        thus, the protocol routine needs to be implemented to return correct
+        copies (clones) of these GEOS objects, which use C pointers.
+        """
+        return self.clone()
+
+    def __str__(self):
+        "EWKT is used for the string representation."
+        return self.ewkt
+
+    def __repr__(self):
+        "Short-hand representation because WKT may be very large."
+        return '<%s object at %s>' % (self.geom_type, hex(addressof(self.ptr)))
+
+    # Pickling support
+    def _to_pickle_wkb(self):
+        return bytes(self.wkb)
+
+    def _from_pickle_wkb(self, wkb):
+        return wkb_r().read(memoryview(wkb))
+
+    def __getstate__(self):
+        # The pickled state is simply a tuple of the WKB (in string form)
+        # and the SRID.
+        return self._to_pickle_wkb(), self.srid
+
+    def __setstate__(self, state):
+        # Instantiating from the tuple state that was pickled.
+        wkb, srid = state
+        ptr = self._from_pickle_wkb(wkb)
+        if not ptr:
+            raise GEOSException('Invalid Geometry loaded from pickled state.')
+        self.ptr = ptr
+        self._post_init()
+        self.srid = srid
+
+    @classmethod
+    def _from_wkb(cls, wkb):
+        return wkb_r().read(wkb)
+
+    @staticmethod
+    def from_ewkt(ewkt):
+        ewkt = force_bytes(ewkt)
+        srid = None
+        parts = ewkt.split(b';', 1)
+        if len(parts) == 2:
+            srid_part, wkt = parts
+            match = re.match(br'SRID=(?P<srid>\-?\d+)', srid_part)
+            if not match:
+                raise ValueError('EWKT has invalid SRID part.')
+            srid = int(match['srid'])
+        else:
+            wkt = ewkt
+        if not wkt:
+            raise ValueError('Expected WKT but got an empty string.')
+        return GEOSGeometry(GEOSGeometry._from_wkt(wkt), srid=srid)
+
+    @staticmethod
+    def _from_wkt(wkt):
+        return wkt_r().read(wkt)
+
+    @classmethod
+    def from_gml(cls, gml_string):
+        return gdal.OGRGeometry.from_gml(gml_string).geos
+
+    # Comparison operators
+    def __eq__(self, other):
+        """
+        Equivalence testing, a Geometry may be compared with another Geometry
+        or an EWKT representation.
+        """
+        if isinstance(other, str):
+            try:
+                other = GEOSGeometry.from_ewkt(other)
+            except (ValueError, GEOSException):
+                return False
+        return isinstance(other, GEOSGeometry) and self.srid == other.srid and self.equals_exact(other)
+
+    def __hash__(self):
+        return hash((self.srid, self.wkt))
+
+    # ### Geometry set-like operations ###
+    # Thanks to Sean Gillies for inspiration:
+    #  http://lists.gispython.org/pipermail/community/2007-July/001034.html
+    # g = g1 | g2
+    def __or__(self, other):
+        "Return the union of this Geometry and the other."
+        return self.union(other)
+
+    # g = g1 & g2
+    def __and__(self, other):
+        "Return the intersection of this Geometry and the other."
+        return self.intersection(other)
+
+    # g = g1 - g2
+    def __sub__(self, other):
+        "Return the difference this Geometry and the other."
+        return self.difference(other)
+
+    # g = g1 ^ g2
+    def __xor__(self, other):
+        "Return the symmetric difference of this Geometry and the other."
+        return self.sym_difference(other)
+
+    # #### Coordinate Sequence Routines ####
+    @property
+    def coord_seq(self):
+        "Return a clone of the coordinate sequence for this Geometry."
+        if self.has_cs:
+            return self._cs.clone()
+
+    # #### Geometry Info ####
+    @property
+    def geom_type(self):
+        "Return a string representing the Geometry type, e.g. 'Polygon'"
+        return capi.geos_type(self.ptr).decode()
+
+    @property
+    def geom_typeid(self):
+        "Return an integer representing the Geometry type."
+        return capi.geos_typeid(self.ptr)
+
+    @property
+    def num_geom(self):
+        "Return the number of geometries in the Geometry."
+        return capi.get_num_geoms(self.ptr)
+
+    @property
+    def num_coords(self):
+        "Return the number of coordinates in the Geometry."
+        return capi.get_num_coords(self.ptr)
+
+    @property
+    def num_points(self):
+        "Return the number points, or coordinates, in the Geometry."
+        return self.num_coords
+
+    @property
+    def dims(self):
+        "Return the dimension of this Geometry (0=point, 1=line, 2=surface)."
+        return capi.get_dims(self.ptr)
+
+    def normalize(self):
+        "Convert this Geometry to normal form (or canonical form)."
+        capi.geos_normalize(self.ptr)
+
+    # #### Unary predicates ####
+    @property
+    def empty(self):
+        """
+        Return a boolean indicating whether the set of points in this Geometry
+        are empty.
+        """
+        return capi.geos_isempty(self.ptr)
+
+    @property
+    def hasz(self):
+        "Return whether the geometry has a 3D dimension."
+        return capi.geos_hasz(self.ptr)
+
+    @property
+    def ring(self):
+        "Return whether or not the geometry is a ring."
+        return capi.geos_isring(self.ptr)
+
+    @property
+    def simple(self):
+        "Return false if the Geometry isn't simple."
+        return capi.geos_issimple(self.ptr)
+
+    @property
+    def valid(self):
+        "Test the validity of this Geometry."
+        return capi.geos_isvalid(self.ptr)
+
+    @property
+    def valid_reason(self):
+        """
+        Return a string containing the reason for any invalidity.
+        """
+        return capi.geos_isvalidreason(self.ptr).decode()
+
+    # #### Binary predicates. ####
+    def contains(self, other):
+        "Return true if other.within(this) returns true."
+        return capi.geos_contains(self.ptr, other.ptr)
+
+    def covers(self, other):
+        """
+        Return True if the DE-9IM Intersection Matrix for the two geometries is
+        T*****FF*, *T****FF*, ***T**FF*, or ****T*FF*. If either geometry is
+        empty, return False.
+        """
+        return capi.geos_covers(self.ptr, other.ptr)
+
+    def crosses(self, other):
+        """
+        Return true if the DE-9IM intersection matrix for the two Geometries
+        is T*T****** (for a point and a curve,a point and an area or a line and
+        an area) 0******** (for two curves).
+        """
+        return capi.geos_crosses(self.ptr, other.ptr)
+
+    def disjoint(self, other):
+        """
+        Return true if the DE-9IM intersection matrix for the two Geometries
+        is FF*FF****.
+        """
+        return capi.geos_disjoint(self.ptr, other.ptr)
+
+    def equals(self, other):
+        """
+        Return true if the DE-9IM intersection matrix for the two Geometries
+        is T*F**FFF*.
+        """
+        return capi.geos_equals(self.ptr, other.ptr)
+
+    def equals_exact(self, other, tolerance=0):
+        """
+        Return true if the two Geometries are exactly equal, up to a
+        specified tolerance.
+        """
+        return capi.geos_equalsexact(self.ptr, other.ptr, float(tolerance))
+
+    def intersects(self, other):
+        "Return true if disjoint return false."
+        return capi.geos_intersects(self.ptr, other.ptr)
+
+    def overlaps(self, other):
+        """
+        Return true if the DE-9IM intersection matrix for the two Geometries
+        is T*T***T** (for two points or two surfaces) 1*T***T** (for two curves).
+        """
+        return capi.geos_overlaps(self.ptr, other.ptr)
+
+    def relate_pattern(self, other, pattern):
+        """
+        Return true if the elements in the DE-9IM intersection matrix for the
+        two Geometries match the elements in pattern.
+        """
+        if not isinstance(pattern, str) or len(pattern) > 9:
+            raise GEOSException('invalid intersection matrix pattern')
+        return capi.geos_relatepattern(self.ptr, other.ptr, force_bytes(pattern))
+
+    def touches(self, other):
+        """
+        Return true if the DE-9IM intersection matrix for the two Geometries
+        is FT*******, F**T***** or F***T****.
+        """
+        return capi.geos_touches(self.ptr, other.ptr)
+
+    def within(self, other):
+        """
+        Return true if the DE-9IM intersection matrix for the two Geometries
+        is T*F**F***.
+        """
+        return capi.geos_within(self.ptr, other.ptr)
+
+    # #### SRID Routines ####
+    @property
+    def srid(self):
+        "Get the SRID for the geometry. Return None if no SRID is set."
+        s = capi.geos_get_srid(self.ptr)
+        if s == 0:
+            return None
+        else:
+            return s
+
+    @srid.setter
+    def srid(self, srid):
+        "Set the SRID for the geometry."
+        capi.geos_set_srid(self.ptr, 0 if srid is None else srid)
+
+    # #### Output Routines ####
+    @property
+    def ewkt(self):
+        """
+        Return the EWKT (SRID + WKT) of the Geometry.
+        """
+        srid = self.srid
+        return 'SRID=%s;%s' % (srid, self.wkt) if srid else self.wkt
+
+    @property
+    def wkt(self):
+        "Return the WKT (Well-Known Text) representation of this Geometry."
+        return wkt_w(dim=3 if self.hasz else 2, trim=True).write(self).decode()
+
+    @property
+    def hex(self):
+        """
+        Return the WKB of this Geometry in hexadecimal form. Please note
+        that the SRID is not included in this representation because it is not
+        a part of the OGC specification (use the `hexewkb` property instead).
+        """
+        # A possible faster, all-python, implementation:
+        #  str(self.wkb).encode('hex')
+        return wkb_w(dim=3 if self.hasz else 2).write_hex(self)
+
+    @property
+    def hexewkb(self):
+        """
+        Return the EWKB of this Geometry in hexadecimal form. This is an
+        extension of the WKB specification that includes SRID value that are
+        a part of this geometry.
+        """
+        return ewkb_w(dim=3 if self.hasz else 2).write_hex(self)
+
+    @property
+    def json(self):
+        """
+        Return GeoJSON representation of this Geometry.
+        """
+        return self.ogr.json
+    geojson = json
+
+    @property
+    def wkb(self):
+        """
+        Return the WKB (Well-Known Binary) representation of this Geometry
+        as a Python buffer.  SRID and Z values are not included, use the
+        `ewkb` property instead.
+        """
+        return wkb_w(3 if self.hasz else 2).write(self)
+
+    @property
+    def ewkb(self):
+        """
+        Return the EWKB representation of this Geometry as a Python buffer.
+        This is an extension of the WKB specification that includes any SRID
+        value that are a part of this geometry.
+        """
+        return ewkb_w(3 if self.hasz else 2).write(self)
+
+    @property
+    def kml(self):
+        "Return the KML representation of this Geometry."
+        gtype = self.geom_type
+        return '<%s>%s</%s>' % (gtype, self.coord_seq.kml, gtype)
+
+    @property
+    def prepared(self):
+        """
+        Return a PreparedGeometry corresponding to this geometry -- it is
+        optimized for the contains, intersects, and covers operations.
+        """
+        return PreparedGeometry(self)
+
+    # #### GDAL-specific output routines ####
+    def _ogr_ptr(self):
+        return gdal.OGRGeometry._from_wkb(self.wkb)
+
+    @property
+    def ogr(self):
+        "Return the OGR Geometry for this Geometry."
+        return gdal.OGRGeometry(self._ogr_ptr(), self.srs)
+
+    @property
+    def srs(self):
+        "Return the OSR SpatialReference for SRID of this Geometry."
+        if self.srid:
+            try:
+                return gdal.SpatialReference(self.srid)
+            except (gdal.GDALException, gdal.SRSException):
+                pass
+        return None
+
+    @property
+    def crs(self):
+        "Alias for `srs` property."
+        return self.srs
+
+    def transform(self, ct, clone=False):
+        """
+        Requires GDAL. Transform the geometry according to the given
+        transformation object, which may be an integer SRID, and WKT or
+        PROJ.4 string. By default, transform the geometry in-place and return
+        nothing. However if the `clone` keyword is set, don't modify the
+        geometry and return a transformed clone instead.
+        """
+        srid = self.srid
+
+        if ct == srid:
+            # short-circuit where source & dest SRIDs match
+            if clone:
+                return self.clone()
+            else:
+                return
+
+        if isinstance(ct, gdal.CoordTransform):
+            # We don't care about SRID because CoordTransform presupposes
+            # source SRS.
+            srid = None
+        elif srid is None or srid < 0:
+            raise GEOSException("Calling transform() with no SRID set is not supported")
+
+        # Creating an OGR Geometry, which is then transformed.
+        g = gdal.OGRGeometry(self._ogr_ptr(), srid)
+        g.transform(ct)
+        # Getting a new GEOS pointer
+        ptr = g._geos_ptr()
+        if clone:
+            # User wants a cloned transformed geometry returned.
+            return GEOSGeometry(ptr, srid=g.srid)
+        if ptr:
+            # Reassigning pointer, and performing post-initialization setup
+            # again due to the reassignment.
+            capi.destroy_geom(self.ptr)
+            self.ptr = ptr
+            self._post_init()
+            self.srid = g.srid
+        else:
+            raise GEOSException('Transformed WKB was invalid.')
+
+    # #### Topology Routines ####
+    def _topology(self, gptr):
+        "Return Geometry from the given pointer."
+        return GEOSGeometry(gptr, srid=self.srid)
+
+    @property
+    def boundary(self):
+        "Return the boundary as a newly allocated Geometry object."
+        return self._topology(capi.geos_boundary(self.ptr))
+
+    def buffer(self, width, quadsegs=8):
+        """
+        Return a geometry that represents all points whose distance from this
+        Geometry is less than or equal to distance. Calculations are in the
+        Spatial Reference System of this Geometry. The optional third parameter sets
+        the number of segment used to approximate a quarter circle (defaults to 8).
+        (Text from PostGIS documentation at ch. 6.1.3)
+        """
+        return self._topology(capi.geos_buffer(self.ptr, width, quadsegs))
+
+    def buffer_with_style(self, width, quadsegs=8, end_cap_style=1, join_style=1, mitre_limit=5.0):
+        """
+        Same as buffer() but allows customizing the style of the buffer.
+
+        End cap style can be round (1), flat (2), or square (3).
+        Join style can be round (1), mitre (2), or bevel (3).
+        Mitre ratio limit only affects mitered join style.
+        """
+        return self._topology(
+            capi.geos_bufferwithstyle(self.ptr, width, quadsegs, end_cap_style, join_style, mitre_limit),
+        )
+
+    @property
+    def centroid(self):
+        """
+        The centroid is equal to the centroid of the set of component Geometries
+        of highest dimension (since the lower-dimension geometries contribute zero
+        "weight" to the centroid).
+        """
+        return self._topology(capi.geos_centroid(self.ptr))
+
+    @property
+    def convex_hull(self):
+        """
+        Return the smallest convex Polygon that contains all the points
+        in the Geometry.
+        """
+        return self._topology(capi.geos_convexhull(self.ptr))
+
+    def difference(self, other):
+        """
+        Return a Geometry representing the points making up this Geometry
+        that do not make up other.
+        """
+        return self._topology(capi.geos_difference(self.ptr, other.ptr))
+
+    @property
+    def envelope(self):
+        "Return the envelope for this geometry (a polygon)."
+        return self._topology(capi.geos_envelope(self.ptr))
+
+    def intersection(self, other):
+        "Return a Geometry representing the points shared by this Geometry and other."
+        return self._topology(capi.geos_intersection(self.ptr, other.ptr))
+
+    @property
+    def point_on_surface(self):
+        "Compute an interior point of this Geometry."
+        return self._topology(capi.geos_pointonsurface(self.ptr))
+
+    def relate(self, other):
+        "Return the DE-9IM intersection matrix for this Geometry and the other."
+        return capi.geos_relate(self.ptr, other.ptr).decode()
+
+    def simplify(self, tolerance=0.0, preserve_topology=False):
+        """
+        Return the Geometry, simplified using the Douglas-Peucker algorithm
+        to the specified tolerance (higher tolerance => less points).  If no
+        tolerance provided, defaults to 0.
+
+        By default, don't preserve topology - e.g. polygons can be split,
+        collapse to lines or disappear holes can be created or disappear, and
+        lines can cross. By specifying preserve_topology=True, the result will
+        have the same dimension and number of components as the input. This is
+        significantly slower.
+        """
+        if preserve_topology:
+            return self._topology(capi.geos_preservesimplify(self.ptr, tolerance))
+        else:
+            return self._topology(capi.geos_simplify(self.ptr, tolerance))
+
+    def sym_difference(self, other):
+        """
+        Return a set combining the points in this Geometry not in other,
+        and the points in other not in this Geometry.
+        """
+        return self._topology(capi.geos_symdifference(self.ptr, other.ptr))
+
+    @property
+    def unary_union(self):
+        "Return the union of all the elements of this geometry."
+        return self._topology(capi.geos_unary_union(self.ptr))
+
+    def union(self, other):
+        "Return a Geometry representing all the points in this Geometry and other."
+        return self._topology(capi.geos_union(self.ptr, other.ptr))
+
+    # #### Other Routines ####
+    @property
+    def area(self):
+        "Return the area of the Geometry."
+        return capi.geos_area(self.ptr, byref(c_double()))
+
+    def distance(self, other):
+        """
+        Return the distance between the closest points on this Geometry
+        and the other. Units will be in those of the coordinate system of
+        the Geometry.
+        """
+        if not isinstance(other, GEOSGeometry):
+            raise TypeError('distance() works only on other GEOS Geometries.')
+        return capi.geos_distance(self.ptr, other.ptr, byref(c_double()))
+
+    @property
+    def extent(self):
+        """
+        Return the extent of this geometry as a 4-tuple, consisting of
+        (xmin, ymin, xmax, ymax).
+        """
+        from .point import Point
+        env = self.envelope
+        if isinstance(env, Point):
+            xmin, ymin = env.tuple
+            xmax, ymax = xmin, ymin
+        else:
+            xmin, ymin = env[0][0]
+            xmax, ymax = env[0][2]
+        return (xmin, ymin, xmax, ymax)
+
+    @property
+    def length(self):
+        """
+        Return the length of this Geometry (e.g., 0 for point, or the
+        circumference of a Polygon).
+        """
+        return capi.geos_length(self.ptr, byref(c_double()))
+
+    def clone(self):
+        "Clone this Geometry."
+        return GEOSGeometry(capi.geom_clone(self.ptr))
+
+
+class LinearGeometryMixin:
+    """
+    Used for LineString and MultiLineString.
+    """
+    def interpolate(self, distance):
+        return self._topology(capi.geos_interpolate(self.ptr, distance))
+
+    def interpolate_normalized(self, distance):
+        return self._topology(capi.geos_interpolate_normalized(self.ptr, distance))
+
+    def project(self, point):
+        from .point import Point
+        if not isinstance(point, Point):
+            raise TypeError('locate_point argument must be a Point')
+        return capi.geos_project(self.ptr, point.ptr)
+
+    def project_normalized(self, point):
+        from .point import Point
+        if not isinstance(point, Point):
+            raise TypeError('locate_point argument must be a Point')
+        return capi.geos_project_normalized(self.ptr, point.ptr)
+
+    @property
+    def merged(self):
+        """
+        Return the line merge of this Geometry.
+        """
+        return self._topology(capi.geos_linemerge(self.ptr))
+
+    @property
+    def closed(self):
+        """
+        Return whether or not this Geometry is closed.
+        """
+        return capi.geos_isclosed(self.ptr)
+
+
+@deconstructible
+class GEOSGeometry(GEOSGeometryBase, ListMixin):
+    "A class that, generally, encapsulates a GEOS geometry."
+
+    def __init__(self, geo_input, srid=None):
+        """
+        The base constructor for GEOS geometry objects. It may take the
+        following inputs:
+
+         * strings:
+            - WKT
+            - HEXEWKB (a PostGIS-specific canonical form)
+            - GeoJSON (requires GDAL)
+         * buffer:
+            - WKB
+
+        The `srid` keyword specifies the Source Reference Identifier (SRID)
+        number for this Geometry. If not provided, it defaults to None.
+        """
+        input_srid = None
+        if isinstance(geo_input, bytes):
+            geo_input = force_str(geo_input)
+        if isinstance(geo_input, str):
+            wkt_m = wkt_regex.match(geo_input)
+            if wkt_m:
+                # Handle WKT input.
+                if wkt_m['srid']:
+                    input_srid = int(wkt_m['srid'])
+                g = self._from_wkt(force_bytes(wkt_m['wkt']))
+            elif hex_regex.match(geo_input):
+                # Handle HEXEWKB input.
+                g = wkb_r().read(force_bytes(geo_input))
+            elif json_regex.match(geo_input):
+                # Handle GeoJSON input.
+                ogr = gdal.OGRGeometry.from_json(geo_input)
+                g = ogr._geos_ptr()
+                input_srid = ogr.srid
+            else:
+                raise ValueError('String input unrecognized as WKT EWKT, and HEXEWKB.')
+        elif isinstance(geo_input, GEOM_PTR):
+            # When the input is a pointer to a geometry (GEOM_PTR).
+            g = geo_input
+        elif isinstance(geo_input, memoryview):
+            # When the input is a buffer (WKB).
+            g = wkb_r().read(geo_input)
+        elif isinstance(geo_input, GEOSGeometry):
+            g = capi.geom_clone(geo_input.ptr)
+        else:
+            raise TypeError('Improper geometry input type: %s' % type(geo_input))
+
+        if not g:
+            raise GEOSException('Could not initialize GEOS Geometry with given input.')
+
+        input_srid = input_srid or capi.geos_get_srid(g) or None
+        if input_srid and srid and input_srid != srid:
+            raise ValueError('Input geometry already has SRID: %d.' % input_srid)
+
+        super().__init__(g, None)
+        # Set the SRID, if given.
+        srid = input_srid or srid
+        if srid and isinstance(srid, int):
+            self.srid = srid
Index: venv/Lib/site-packages/django/contrib/gis/geos/io.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/gis/geos/io.py b/venv/Lib/site-packages/django/contrib/gis/geos/io.py
new file mode 100644
--- /dev/null	(date 1617030484369)
+++ b/venv/Lib/site-packages/django/contrib/gis/geos/io.py	(date 1617030484369)
@@ -0,0 +1,24 @@
+"""
+Module that holds classes for performing I/O operations on GEOS geometry
+objects.  Specifically, this has Python implementations of WKB/WKT
+reader and writer classes.
+"""
+from django.contrib.gis.geos.geometry import GEOSGeometry
+from django.contrib.gis.geos.prototypes.io import (
+    WKBWriter, WKTWriter, _WKBReader, _WKTReader,
+)
+
+__all__ = ['WKBWriter', 'WKTWriter', 'WKBReader', 'WKTReader']
+
+
+# Public classes for (WKB|WKT)Reader, which return GEOSGeometry
+class WKBReader(_WKBReader):
+    def read(self, wkb):
+        "Return a GEOSGeometry for the given WKB buffer."
+        return GEOSGeometry(super().read(wkb))
+
+
+class WKTReader(_WKTReader):
+    def read(self, wkt):
+        "Return a GEOSGeometry for the given WKT string."
+        return GEOSGeometry(super().read(wkt))
Index: venv/Lib/site-packages/django/contrib/gis/geos/libgeos.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/gis/geos/libgeos.py b/venv/Lib/site-packages/django/contrib/gis/geos/libgeos.py
new file mode 100644
--- /dev/null	(date 1617030484369)
+++ b/venv/Lib/site-packages/django/contrib/gis/geos/libgeos.py	(date 1617030484369)
@@ -0,0 +1,172 @@
+"""
+ This module houses the ctypes initialization procedures, as well
+ as the notice and error handler function callbacks (get called
+ when an error occurs in GEOS).
+
+ This module also houses GEOS Pointer utilities, including
+ get_pointer_arr(), and GEOM_PTR.
+"""
+import logging
+import os
+from ctypes import CDLL, CFUNCTYPE, POINTER, Structure, c_char_p
+from ctypes.util import find_library
+
+from django.core.exceptions import ImproperlyConfigured
+from django.utils.functional import SimpleLazyObject, cached_property
+from django.utils.version import get_version_tuple
+
+logger = logging.getLogger('django.contrib.gis')
+
+
+def load_geos():
+    # Custom library path set?
+    try:
+        from django.conf import settings
+        lib_path = settings.GEOS_LIBRARY_PATH
+    except (AttributeError, ImportError, ImproperlyConfigured, OSError):
+        lib_path = None
+
+    # Setting the appropriate names for the GEOS-C library.
+    if lib_path:
+        lib_names = None
+    elif os.name == 'nt':
+        # Windows NT libraries
+        lib_names = ['geos_c', 'libgeos_c-1']
+    elif os.name == 'posix':
+        # *NIX libraries
+        lib_names = ['geos_c', 'GEOS']
+    else:
+        raise ImportError('Unsupported OS "%s"' % os.name)
+
+    # Using the ctypes `find_library` utility to find the path to the GEOS
+    # shared library.  This is better than manually specifying each library name
+    # and extension (e.g., libgeos_c.[so|so.1|dylib].).
+    if lib_names:
+        for lib_name in lib_names:
+            lib_path = find_library(lib_name)
+            if lib_path is not None:
+                break
+
+    # No GEOS library could be found.
+    if lib_path is None:
+        raise ImportError(
+            'Could not find the GEOS library (tried "%s"). '
+            'Try setting GEOS_LIBRARY_PATH in your settings.' %
+            '", "'.join(lib_names)
+        )
+    # Getting the GEOS C library.  The C interface (CDLL) is used for
+    # both *NIX and Windows.
+    # See the GEOS C API source code for more details on the library function calls:
+    # https://geos.osgeo.org/doxygen/geos__c_8h_source.html
+    _lgeos = CDLL(lib_path)
+    # Here we set up the prototypes for the initGEOS_r and finishGEOS_r
+    # routines.  These functions aren't actually called until they are
+    # attached to a GEOS context handle -- this actually occurs in
+    # geos/prototypes/threadsafe.py.
+    _lgeos.initGEOS_r.restype = CONTEXT_PTR
+    _lgeos.finishGEOS_r.argtypes = [CONTEXT_PTR]
+    # Set restype for compatibility across 32 and 64-bit platforms.
+    _lgeos.GEOSversion.restype = c_char_p
+    return _lgeos
+
+
+# The notice and error handler C function callback definitions.
+# Supposed to mimic the GEOS message handler (C below):
+#  typedef void (*GEOSMessageHandler)(const char *fmt, ...);
+NOTICEFUNC = CFUNCTYPE(None, c_char_p, c_char_p)
+
+
+def notice_h(fmt, lst):
+    fmt, lst = fmt.decode(), lst.decode()
+    try:
+        warn_msg = fmt % lst
+    except TypeError:
+        warn_msg = fmt
+    logger.warning('GEOS_NOTICE: %s\n', warn_msg)
+
+
+notice_h = NOTICEFUNC(notice_h)
+
+ERRORFUNC = CFUNCTYPE(None, c_char_p, c_char_p)
+
+
+def error_h(fmt, lst):
+    fmt, lst = fmt.decode(), lst.decode()
+    try:
+        err_msg = fmt % lst
+    except TypeError:
+        err_msg = fmt
+    logger.error('GEOS_ERROR: %s\n', err_msg)
+
+
+error_h = ERRORFUNC(error_h)
+
+# #### GEOS Geometry C data structures, and utility functions. ####
+
+
+# Opaque GEOS geometry structures, used for GEOM_PTR and CS_PTR
+class GEOSGeom_t(Structure):
+    pass
+
+
+class GEOSPrepGeom_t(Structure):
+    pass
+
+
+class GEOSCoordSeq_t(Structure):
+    pass
+
+
+class GEOSContextHandle_t(Structure):
+    pass
+
+
+# Pointers to opaque GEOS geometry structures.
+GEOM_PTR = POINTER(GEOSGeom_t)
+PREPGEOM_PTR = POINTER(GEOSPrepGeom_t)
+CS_PTR = POINTER(GEOSCoordSeq_t)
+CONTEXT_PTR = POINTER(GEOSContextHandle_t)
+
+
+lgeos = SimpleLazyObject(load_geos)
+
+
+class GEOSFuncFactory:
+    """
+    Lazy loading of GEOS functions.
+    """
+    argtypes = None
+    restype = None
+    errcheck = None
+
+    def __init__(self, func_name, *, restype=None, errcheck=None, argtypes=None):
+        self.func_name = func_name
+        if restype is not None:
+            self.restype = restype
+        if errcheck is not None:
+            self.errcheck = errcheck
+        if argtypes is not None:
+            self.argtypes = argtypes
+
+    def __call__(self, *args):
+        return self.func(*args)
+
+    @cached_property
+    def func(self):
+        from django.contrib.gis.geos.prototypes.threadsafe import GEOSFunc
+        func = GEOSFunc(self.func_name)
+        func.argtypes = self.argtypes or []
+        func.restype = self.restype
+        if self.errcheck:
+            func.errcheck = self.errcheck
+        return func
+
+
+def geos_version():
+    """Return the string version of the GEOS library."""
+    return lgeos.GEOSversion()
+
+
+def geos_version_tuple():
+    """Return the GEOS version as a tuple (major, minor, subminor)."""
+    return get_version_tuple(geos_version().decode())
Index: venv/Lib/site-packages/django/contrib/gis/geos/LICENSE
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/gis/geos/LICENSE b/venv/Lib/site-packages/django/contrib/gis/geos/LICENSE
new file mode 100644
--- /dev/null	(date 1617030484366)
+++ b/venv/Lib/site-packages/django/contrib/gis/geos/LICENSE	(date 1617030484366)
@@ -0,0 +1,27 @@
+Copyright (c) 2007-2009 Justin Bronn
+All rights reserved.
+
+Redistribution and use in source and binary forms, with or without modification,
+are permitted provided that the following conditions are met:
+
+    1. Redistributions of source code must retain the above copyright notice, 
+       this list of conditions and the following disclaimer.
+   
+    2. Redistributions in binary form must reproduce the above copyright 
+       notice, this list of conditions and the following disclaimer in the
+       documentation and/or other materials provided with the distribution.
+
+    3. Neither the name of GEOSGeometry nor the names of its contributors may be used
+       to endorse or promote products derived from this software without
+       specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
+ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
+ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
Index: venv/Lib/site-packages/django/contrib/gis/geos/linestring.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/gis/geos/linestring.py b/venv/Lib/site-packages/django/contrib/gis/geos/linestring.py
new file mode 100644
--- /dev/null	(date 1617030484370)
+++ b/venv/Lib/site-packages/django/contrib/gis/geos/linestring.py	(date 1617030484370)
@@ -0,0 +1,187 @@
+from django.contrib.gis.geos import prototypes as capi
+from django.contrib.gis.geos.coordseq import GEOSCoordSeq
+from django.contrib.gis.geos.error import GEOSException
+from django.contrib.gis.geos.geometry import GEOSGeometry, LinearGeometryMixin
+from django.contrib.gis.geos.point import Point
+from django.contrib.gis.shortcuts import numpy
+
+
+class LineString(LinearGeometryMixin, GEOSGeometry):
+    _init_func = capi.create_linestring
+    _minlength = 2
+    has_cs = True
+
+    def __init__(self, *args, **kwargs):
+        """
+        Initialize on the given sequence -- may take lists, tuples, NumPy arrays
+        of X,Y pairs, or Point objects.  If Point objects are used, ownership is
+        _not_ transferred to the LineString object.
+
+        Examples:
+         ls = LineString((1, 1), (2, 2))
+         ls = LineString([(1, 1), (2, 2)])
+         ls = LineString(array([(1, 1), (2, 2)]))
+         ls = LineString(Point(1, 1), Point(2, 2))
+        """
+        # If only one argument provided, set the coords array appropriately
+        if len(args) == 1:
+            coords = args[0]
+        else:
+            coords = args
+
+        if not (isinstance(coords, (tuple, list)) or numpy and isinstance(coords, numpy.ndarray)):
+            raise TypeError('Invalid initialization input for LineStrings.')
+
+        # If SRID was passed in with the keyword arguments
+        srid = kwargs.get('srid')
+
+        ncoords = len(coords)
+        if not ncoords:
+            super().__init__(self._init_func(None), srid=srid)
+            return
+
+        if ncoords < self._minlength:
+            raise ValueError(
+                '%s requires at least %d points, got %s.' % (
+                    self.__class__.__name__,
+                    self._minlength,
+                    ncoords,
+                )
+            )
+
+        numpy_coords = not isinstance(coords, (tuple, list))
+        if numpy_coords:
+            shape = coords.shape  # Using numpy's shape.
+            if len(shape) != 2:
+                raise TypeError('Too many dimensions.')
+            self._checkdim(shape[1])
+            ndim = shape[1]
+        else:
+            # Getting the number of coords and the number of dimensions -- which
+            #  must stay the same, e.g., no LineString((1, 2), (1, 2, 3)).
+            ndim = None
+            # Incrementing through each of the coordinates and verifying
+            for coord in coords:
+                if not isinstance(coord, (tuple, list, Point)):
+                    raise TypeError('Each coordinate should be a sequence (list or tuple)')
+
+                if ndim is None:
+                    ndim = len(coord)
+                    self._checkdim(ndim)
+                elif len(coord) != ndim:
+                    raise TypeError('Dimension mismatch.')
+
+        # Creating a coordinate sequence object because it is easier to
+        # set the points using its methods.
+        cs = GEOSCoordSeq(capi.create_cs(ncoords, ndim), z=bool(ndim == 3))
+        point_setter = cs._set_point_3d if ndim == 3 else cs._set_point_2d
+
+        for i in range(ncoords):
+            if numpy_coords:
+                point_coords = coords[i, :]
+            elif isinstance(coords[i], Point):
+                point_coords = coords[i].tuple
+            else:
+                point_coords = coords[i]
+            point_setter(i, point_coords)
+
+        # Calling the base geometry initialization with the returned pointer
+        #  from the function.
+        super().__init__(self._init_func(cs.ptr), srid=srid)
+
+    def __iter__(self):
+        "Allow iteration over this LineString."
+        for i in range(len(self)):
+            yield self[i]
+
+    def __len__(self):
+        "Return the number of points in this LineString."
+        return len(self._cs)
+
+    def _get_single_external(self, index):
+        return self._cs[index]
+
+    _get_single_internal = _get_single_external
+
+    def _set_list(self, length, items):
+        ndim = self._cs.dims
+        hasz = self._cs.hasz  # I don't understand why these are different
+        srid = self.srid
+
+        # create a new coordinate sequence and populate accordingly
+        cs = GEOSCoordSeq(capi.create_cs(length, ndim), z=hasz)
+        for i, c in enumerate(items):
+            cs[i] = c
+
+        ptr = self._init_func(cs.ptr)
+        if ptr:
+            capi.destroy_geom(self.ptr)
+            self.ptr = ptr
+            if srid is not None:
+                self.srid = srid
+            self._post_init()
+        else:
+            # can this happen?
+            raise GEOSException('Geometry resulting from slice deletion was invalid.')
+
+    def _set_single(self, index, value):
+        self._cs[index] = value
+
+    def _checkdim(self, dim):
+        if dim not in (2, 3):
+            raise TypeError('Dimension mismatch.')
+
+    # #### Sequence Properties ####
+    @property
+    def tuple(self):
+        "Return a tuple version of the geometry from the coordinate sequence."
+        return self._cs.tuple
+    coords = tuple
+
+    def _listarr(self, func):
+        """
+        Return a sequence (list) corresponding with the given function.
+        Return a numpy array if possible.
+        """
+        lst = [func(i) for i in range(len(self))]
+        if numpy:
+            return numpy.array(lst)  # ARRRR!
+        else:
+            return lst
+
+    @property
+    def array(self):
+        "Return a numpy array for the LineString."
+        return self._listarr(self._cs.__getitem__)
+
+    @property
+    def x(self):
+        "Return a list or numpy array of the X variable."
+        return self._listarr(self._cs.getX)
+
+    @property
+    def y(self):
+        "Return a list or numpy array of the Y variable."
+        return self._listarr(self._cs.getY)
+
+    @property
+    def z(self):
+        "Return a list or numpy array of the Z variable."
+        if not self.hasz:
+            return None
+        else:
+            return self._listarr(self._cs.getZ)
+
+
+# LinearRings are LineStrings used within Polygons.
+class LinearRing(LineString):
+    _minlength = 4
+    _init_func = capi.create_linearring
+
+    @property
+    def is_counterclockwise(self):
+        if self.empty:
+            raise ValueError(
+                'Orientation of an empty LinearRing cannot be determined.'
+            )
+        return self._cs.is_counterclockwise
Index: venv/Lib/site-packages/django/contrib/gis/geos/mutable_list.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/gis/geos/mutable_list.py b/venv/Lib/site-packages/django/contrib/gis/geos/mutable_list.py
new file mode 100644
--- /dev/null	(date 1617030484370)
+++ b/venv/Lib/site-packages/django/contrib/gis/geos/mutable_list.py	(date 1617030484370)
@@ -0,0 +1,310 @@
+# Copyright (c) 2008-2009 Aryeh Leib Taurog, all rights reserved.
+# Released under the New BSD license.
+"""
+This module contains a base type which provides list-style mutations
+without specific data storage methods.
+
+See also http://static.aryehleib.com/oldsite/MutableLists.html
+
+Author: Aryeh Leib Taurog.
+"""
+from functools import total_ordering
+
+
+@total_ordering
+class ListMixin:
+    """
+    A base class which provides complete list interface.
+    Derived classes must call ListMixin's __init__() function
+    and implement the following:
+
+    function _get_single_external(self, i):
+        Return single item with index i for general use.
+        The index i will always satisfy 0 <= i < len(self).
+
+    function _get_single_internal(self, i):
+        Same as above, but for use within the class [Optional]
+        Note that if _get_single_internal and _get_single_internal return
+        different types of objects, _set_list must distinguish
+        between the two and handle each appropriately.
+
+    function _set_list(self, length, items):
+        Recreate the entire object.
+
+        NOTE: items may be a generator which calls _get_single_internal.
+        Therefore, it is necessary to cache the values in a temporary:
+            temp = list(items)
+        before clobbering the original storage.
+
+    function _set_single(self, i, value):
+        Set the single item at index i to value [Optional]
+        If left undefined, all mutations will result in rebuilding
+        the object using _set_list.
+
+    function __len__(self):
+        Return the length
+
+    int _minlength:
+        The minimum legal length [Optional]
+
+    int _maxlength:
+        The maximum legal length [Optional]
+
+    type or tuple _allowed:
+        A type or tuple of allowed item types [Optional]
+    """
+
+    _minlength = 0
+    _maxlength = None
+
+    # ### Python initialization and special list interface methods ###
+
+    def __init__(self, *args, **kwargs):
+        if not hasattr(self, '_get_single_internal'):
+            self._get_single_internal = self._get_single_external
+
+        if not hasattr(self, '_set_single'):
+            self._set_single = self._set_single_rebuild
+            self._assign_extended_slice = self._assign_extended_slice_rebuild
+
+        super().__init__(*args, **kwargs)
+
+    def __getitem__(self, index):
+        "Get the item(s) at the specified index/slice."
+        if isinstance(index, slice):
+            return [self._get_single_external(i) for i in range(*index.indices(len(self)))]
+        else:
+            index = self._checkindex(index)
+            return self._get_single_external(index)
+
+    def __delitem__(self, index):
+        "Delete the item(s) at the specified index/slice."
+        if not isinstance(index, (int, slice)):
+            raise TypeError("%s is not a legal index" % index)
+
+        # calculate new length and dimensions
+        origLen = len(self)
+        if isinstance(index, int):
+            index = self._checkindex(index)
+            indexRange = [index]
+        else:
+            indexRange = range(*index.indices(origLen))
+
+        newLen = origLen - len(indexRange)
+        newItems = (self._get_single_internal(i)
+                    for i in range(origLen)
+                    if i not in indexRange)
+
+        self._rebuild(newLen, newItems)
+
+    def __setitem__(self, index, val):
+        "Set the item(s) at the specified index/slice."
+        if isinstance(index, slice):
+            self._set_slice(index, val)
+        else:
+            index = self._checkindex(index)
+            self._check_allowed((val,))
+            self._set_single(index, val)
+
+    # ### Special methods for arithmetic operations ###
+    def __add__(self, other):
+        'add another list-like object'
+        return self.__class__([*self, *other])
+
+    def __radd__(self, other):
+        'add to another list-like object'
+        return other.__class__([*other, *self])
+
+    def __iadd__(self, other):
+        'add another list-like object to self'
+        self.extend(other)
+        return self
+
+    def __mul__(self, n):
+        'multiply'
+        return self.__class__(list(self) * n)
+
+    def __rmul__(self, n):
+        'multiply'
+        return self.__class__(list(self) * n)
+
+    def __imul__(self, n):
+        'multiply'
+        if n <= 0:
+            del self[:]
+        else:
+            cache = list(self)
+            for i in range(n - 1):
+                self.extend(cache)
+        return self
+
+    def __eq__(self, other):
+        olen = len(other)
+        for i in range(olen):
+            try:
+                c = self[i] == other[i]
+            except IndexError:
+                # self must be shorter
+                return False
+            if not c:
+                return False
+        return len(self) == olen
+
+    def __lt__(self, other):
+        olen = len(other)
+        for i in range(olen):
+            try:
+                c = self[i] < other[i]
+            except IndexError:
+                # self must be shorter
+                return True
+            if c:
+                return c
+            elif other[i] < self[i]:
+                return False
+        return len(self) < olen
+
+    # ### Public list interface Methods ###
+    # ## Non-mutating ##
+    def count(self, val):
+        "Standard list count method"
+        count = 0
+        for i in self:
+            if val == i:
+                count += 1
+        return count
+
+    def index(self, val):
+        "Standard list index method"
+        for i in range(0, len(self)):
+            if self[i] == val:
+                return i
+        raise ValueError('%s not found in object' % val)
+
+    # ## Mutating ##
+    def append(self, val):
+        "Standard list append method"
+        self[len(self):] = [val]
+
+    def extend(self, vals):
+        "Standard list extend method"
+        self[len(self):] = vals
+
+    def insert(self, index, val):
+        "Standard list insert method"
+        if not isinstance(index, int):
+            raise TypeError("%s is not a legal index" % index)
+        self[index:index] = [val]
+
+    def pop(self, index=-1):
+        "Standard list pop method"
+        result = self[index]
+        del self[index]
+        return result
+
+    def remove(self, val):
+        "Standard list remove method"
+        del self[self.index(val)]
+
+    def reverse(self):
+        "Standard list reverse method"
+        self[:] = self[-1::-1]
+
+    def sort(self, key=None, reverse=False):
+        "Standard list sort method"
+        self[:] = sorted(self, key=key, reverse=reverse)
+
+    # ### Private routines ###
+    def _rebuild(self, newLen, newItems):
+        if newLen and newLen < self._minlength:
+            raise ValueError('Must have at least %d items' % self._minlength)
+        if self._maxlength is not None and newLen > self._maxlength:
+            raise ValueError('Cannot have more than %d items' % self._maxlength)
+
+        self._set_list(newLen, newItems)
+
+    def _set_single_rebuild(self, index, value):
+        self._set_slice(slice(index, index + 1, 1), [value])
+
+    def _checkindex(self, index):
+        length = len(self)
+        if 0 <= index < length:
+            return index
+        if -length <= index < 0:
+            return index + length
+        raise IndexError('invalid index: %s' % index)
+
+    def _check_allowed(self, items):
+        if hasattr(self, '_allowed'):
+            if False in [isinstance(val, self._allowed) for val in items]:
+                raise TypeError('Invalid type encountered in the arguments.')
+
+    def _set_slice(self, index, values):
+        "Assign values to a slice of the object"
+        try:
+            valueList = list(values)
+        except TypeError:
+            raise TypeError('can only assign an iterable to a slice')
+
+        self._check_allowed(valueList)
+
+        origLen = len(self)
+        start, stop, step = index.indices(origLen)
+
+        # CAREFUL: index.step and step are not the same!
+        # step will never be None
+        if index.step is None:
+            self._assign_simple_slice(start, stop, valueList)
+        else:
+            self._assign_extended_slice(start, stop, step, valueList)
+
+    def _assign_extended_slice_rebuild(self, start, stop, step, valueList):
+        'Assign an extended slice by rebuilding entire list'
+        indexList = range(start, stop, step)
+        # extended slice, only allow assigning slice of same size
+        if len(valueList) != len(indexList):
+            raise ValueError('attempt to assign sequence of size %d '
+                             'to extended slice of size %d'
+                             % (len(valueList), len(indexList)))
+
+        # we're not changing the length of the sequence
+        newLen = len(self)
+        newVals = dict(zip(indexList, valueList))
+
+        def newItems():
+            for i in range(newLen):
+                if i in newVals:
+                    yield newVals[i]
+                else:
+                    yield self._get_single_internal(i)
+
+        self._rebuild(newLen, newItems())
+
+    def _assign_extended_slice(self, start, stop, step, valueList):
+        'Assign an extended slice by re-assigning individual items'
+        indexList = range(start, stop, step)
+        # extended slice, only allow assigning slice of same size
+        if len(valueList) != len(indexList):
+            raise ValueError('attempt to assign sequence of size %d '
+                             'to extended slice of size %d'
+                             % (len(valueList), len(indexList)))
+
+        for i, val in zip(indexList, valueList):
+            self._set_single(i, val)
+
+    def _assign_simple_slice(self, start, stop, valueList):
+        'Assign a simple slice; Can assign slice of any length'
+        origLen = len(self)
+        stop = max(start, stop)
+        newLen = origLen - stop + start + len(valueList)
+
+        def newItems():
+            for i in range(origLen + 1):
+                if i == start:
+                    yield from valueList
+
+                if i < origLen:
+                    if i < start or i >= stop:
+                        yield self._get_single_internal(i)
+
+        self._rebuild(newLen, newItems())
Index: venv/Lib/site-packages/django/contrib/gis/geos/point.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/gis/geos/point.py b/venv/Lib/site-packages/django/contrib/gis/geos/point.py
new file mode 100644
--- /dev/null	(date 1617030484371)
+++ b/venv/Lib/site-packages/django/contrib/gis/geos/point.py	(date 1617030484371)
@@ -0,0 +1,160 @@
+from ctypes import c_uint
+
+from django.contrib.gis import gdal
+from django.contrib.gis.geos import prototypes as capi
+from django.contrib.gis.geos.error import GEOSException
+from django.contrib.gis.geos.geometry import GEOSGeometry
+
+
+class Point(GEOSGeometry):
+    _minlength = 2
+    _maxlength = 3
+    has_cs = True
+
+    def __init__(self, x=None, y=None, z=None, srid=None):
+        """
+        The Point object may be initialized with either a tuple, or individual
+        parameters.
+
+        For example:
+        >>> p = Point((5, 23))  # 2D point, passed in as a tuple
+        >>> p = Point(5, 23, 8)  # 3D point, passed in with individual parameters
+        """
+        if x is None:
+            coords = []
+        elif isinstance(x, (tuple, list)):
+            # Here a tuple or list was passed in under the `x` parameter.
+            coords = x
+        elif isinstance(x, (float, int)) and isinstance(y, (float, int)):
+            # Here X, Y, and (optionally) Z were passed in individually, as parameters.
+            if isinstance(z, (float, int)):
+                coords = [x, y, z]
+            else:
+                coords = [x, y]
+        else:
+            raise TypeError('Invalid parameters given for Point initialization.')
+
+        point = self._create_point(len(coords), coords)
+
+        # Initializing using the address returned from the GEOS
+        #  createPoint factory.
+        super().__init__(point, srid=srid)
+
+    def _to_pickle_wkb(self):
+        return None if self.empty else super()._to_pickle_wkb()
+
+    def _from_pickle_wkb(self, wkb):
+        return self._create_empty() if wkb is None else super()._from_pickle_wkb(wkb)
+
+    def _ogr_ptr(self):
+        return gdal.geometries.Point._create_empty() if self.empty else super()._ogr_ptr()
+
+    @classmethod
+    def _create_empty(cls):
+        return cls._create_point(None, None)
+
+    @classmethod
+    def _create_point(cls, ndim, coords):
+        """
+        Create a coordinate sequence, set X, Y, [Z], and create point
+        """
+        if not ndim:
+            return capi.create_point(None)
+
+        if ndim < 2 or ndim > 3:
+            raise TypeError('Invalid point dimension: %s' % ndim)
+
+        cs = capi.create_cs(c_uint(1), c_uint(ndim))
+        i = iter(coords)
+        capi.cs_setx(cs, 0, next(i))
+        capi.cs_sety(cs, 0, next(i))
+        if ndim == 3:
+            capi.cs_setz(cs, 0, next(i))
+
+        return capi.create_point(cs)
+
+    def _set_list(self, length, items):
+        ptr = self._create_point(length, items)
+        if ptr:
+            srid = self.srid
+            capi.destroy_geom(self.ptr)
+            self._ptr = ptr
+            if srid is not None:
+                self.srid = srid
+            self._post_init()
+        else:
+            # can this happen?
+            raise GEOSException('Geometry resulting from slice deletion was invalid.')
+
+    def _set_single(self, index, value):
+        self._cs.setOrdinate(index, 0, value)
+
+    def __iter__(self):
+        "Iterate over coordinates of this Point."
+        for i in range(len(self)):
+            yield self[i]
+
+    def __len__(self):
+        "Return the number of dimensions for this Point (either 0, 2 or 3)."
+        if self.empty:
+            return 0
+        if self.hasz:
+            return 3
+        else:
+            return 2
+
+    def _get_single_external(self, index):
+        if index == 0:
+            return self.x
+        elif index == 1:
+            return self.y
+        elif index == 2:
+            return self.z
+
+    _get_single_internal = _get_single_external
+
+    @property
+    def x(self):
+        "Return the X component of the Point."
+        return self._cs.getOrdinate(0, 0)
+
+    @x.setter
+    def x(self, value):
+        "Set the X component of the Point."
+        self._cs.setOrdinate(0, 0, value)
+
+    @property
+    def y(self):
+        "Return the Y component of the Point."
+        return self._cs.getOrdinate(1, 0)
+
+    @y.setter
+    def y(self, value):
+        "Set the Y component of the Point."
+        self._cs.setOrdinate(1, 0, value)
+
+    @property
+    def z(self):
+        "Return the Z component of the Point."
+        return self._cs.getOrdinate(2, 0) if self.hasz else None
+
+    @z.setter
+    def z(self, value):
+        "Set the Z component of the Point."
+        if not self.hasz:
+            raise GEOSException('Cannot set Z on 2D Point.')
+        self._cs.setOrdinate(2, 0, value)
+
+    # ### Tuple setting and retrieval routines. ###
+    @property
+    def tuple(self):
+        "Return a tuple of the point."
+        return self._cs.tuple
+
+    @tuple.setter
+    def tuple(self, tup):
+        "Set the coordinates of the point with the given tuple."
+        self._cs[0] = tup
+
+    # The tuple and coords properties
+    coords = tuple
Index: venv/Lib/site-packages/django/contrib/gis/geos/polygon.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/gis/geos/polygon.py b/venv/Lib/site-packages/django/contrib/gis/geos/polygon.py
new file mode 100644
--- /dev/null	(date 1617030484371)
+++ b/venv/Lib/site-packages/django/contrib/gis/geos/polygon.py	(date 1617030484371)
@@ -0,0 +1,178 @@
+from ctypes import byref, c_uint
+
+from django.contrib.gis.geos import prototypes as capi
+from django.contrib.gis.geos.geometry import GEOSGeometry
+from django.contrib.gis.geos.libgeos import GEOM_PTR
+from django.contrib.gis.geos.linestring import LinearRing
+
+
+class Polygon(GEOSGeometry):
+    _minlength = 1
+
+    def __init__(self, *args, **kwargs):
+        """
+        Initialize on an exterior ring and a sequence of holes (both
+        instances may be either LinearRing instances, or a tuple/list
+        that may be constructed into a LinearRing).
+
+        Examples of initialization, where shell, hole1, and hole2 are
+        valid LinearRing geometries:
+        >>> from django.contrib.gis.geos import LinearRing, Polygon
+        >>> shell = hole1 = hole2 = LinearRing()
+        >>> poly = Polygon(shell, hole1, hole2)
+        >>> poly = Polygon(shell, (hole1, hole2))
+
+        >>> # Example where a tuple parameters are used:
+        >>> poly = Polygon(((0, 0), (0, 10), (10, 10), (0, 10), (0, 0)),
+        ...                ((4, 4), (4, 6), (6, 6), (6, 4), (4, 4)))
+        """
+        if not args:
+            super().__init__(self._create_polygon(0, None), **kwargs)
+            return
+
+        # Getting the ext_ring and init_holes parameters from the argument list
+        ext_ring, *init_holes = args
+        n_holes = len(init_holes)
+
+        # If initialized as Polygon(shell, (LinearRing, LinearRing)) [for backward-compatibility]
+        if n_holes == 1 and isinstance(init_holes[0], (tuple, list)):
+            if not init_holes[0]:
+                init_holes = ()
+                n_holes = 0
+            elif isinstance(init_holes[0][0], LinearRing):
+                init_holes = init_holes[0]
+                n_holes = len(init_holes)
+
+        polygon = self._create_polygon(n_holes + 1, [ext_ring, *init_holes])
+        super().__init__(polygon, **kwargs)
+
+    def __iter__(self):
+        "Iterate over each ring in the polygon."
+        for i in range(len(self)):
+            yield self[i]
+
+    def __len__(self):
+        "Return the number of rings in this Polygon."
+        return self.num_interior_rings + 1
+
+    @classmethod
+    def from_bbox(cls, bbox):
+        "Construct a Polygon from a bounding box (4-tuple)."
+        x0, y0, x1, y1 = bbox
+        for z in bbox:
+            if not isinstance(z, (float, int)):
+                return GEOSGeometry('POLYGON((%s %s, %s %s, %s %s, %s %s, %s %s))' %
+                                    (x0, y0, x0, y1, x1, y1, x1, y0, x0, y0))
+        return Polygon(((x0, y0), (x0, y1), (x1, y1), (x1, y0), (x0, y0)))
+
+    # ### These routines are needed for list-like operation w/ListMixin ###
+    def _create_polygon(self, length, items):
+        # Instantiate LinearRing objects if necessary, but don't clone them yet
+        # _construct_ring will throw a TypeError if a parameter isn't a valid ring
+        # If we cloned the pointers here, we wouldn't be able to clean up
+        # in case of error.
+        if not length:
+            return capi.create_empty_polygon()
+
+        rings = []
+        for r in items:
+            if isinstance(r, GEOM_PTR):
+                rings.append(r)
+            else:
+                rings.append(self._construct_ring(r))
+
+        shell = self._clone(rings.pop(0))
+
+        n_holes = length - 1
+        if n_holes:
+            holes = (GEOM_PTR * n_holes)(*[self._clone(r) for r in rings])
+            holes_param = byref(holes)
+        else:
+            holes_param = None
+
+        return capi.create_polygon(shell, holes_param, c_uint(n_holes))
+
+    def _clone(self, g):
+        if isinstance(g, GEOM_PTR):
+            return capi.geom_clone(g)
+        else:
+            return capi.geom_clone(g.ptr)
+
+    def _construct_ring(self, param, msg=(
+            'Parameter must be a sequence of LinearRings or objects that can initialize to LinearRings')):
+        "Try to construct a ring from the given parameter."
+        if isinstance(param, LinearRing):
+            return param
+        try:
+            ring = LinearRing(param)
+            return ring
+        except TypeError:
+            raise TypeError(msg)
+
+    def _set_list(self, length, items):
+        # Getting the current pointer, replacing with the newly constructed
+        # geometry, and destroying the old geometry.
+        prev_ptr = self.ptr
+        srid = self.srid
+        self.ptr = self._create_polygon(length, items)
+        if srid:
+            self.srid = srid
+        capi.destroy_geom(prev_ptr)
+
+    def _get_single_internal(self, index):
+        """
+        Return the ring at the specified index. The first index, 0, will
+        always return the exterior ring.  Indices > 0 will return the
+        interior ring at the given index (e.g., poly[1] and poly[2] would
+        return the first and second interior ring, respectively).
+
+        CAREFUL: Internal/External are not the same as Interior/Exterior!
+        Return a pointer from the existing geometries for use internally by the
+        object's methods. _get_single_external() returns a clone of the same
+        geometry for use by external code.
+        """
+        if index == 0:
+            return capi.get_extring(self.ptr)
+        else:
+            # Getting the interior ring, have to subtract 1 from the index.
+            return capi.get_intring(self.ptr, index - 1)
+
+    def _get_single_external(self, index):
+        return GEOSGeometry(capi.geom_clone(self._get_single_internal(index)), srid=self.srid)
+
+    _set_single = GEOSGeometry._set_single_rebuild
+    _assign_extended_slice = GEOSGeometry._assign_extended_slice_rebuild
+
+    # #### Polygon Properties ####
+    @property
+    def num_interior_rings(self):
+        "Return the number of interior rings."
+        # Getting the number of rings
+        return capi.get_nrings(self.ptr)
+
+    def _get_ext_ring(self):
+        "Get the exterior ring of the Polygon."
+        return self[0]
+
+    def _set_ext_ring(self, ring):
+        "Set the exterior ring of the Polygon."
+        self[0] = ring
+
+    # Properties for the exterior ring/shell.
+    exterior_ring = property(_get_ext_ring, _set_ext_ring)
+    shell = exterior_ring
+
+    @property
+    def tuple(self):
+        "Get the tuple for each ring in this Polygon."
+        return tuple(self[i].tuple for i in range(len(self)))
+    coords = tuple
+
+    @property
+    def kml(self):
+        "Return the KML representation of this Polygon."
+        inner_kml = ''.join(
+            "<innerBoundaryIs>%s</innerBoundaryIs>" % self[i + 1].kml
+            for i in range(self.num_interior_rings)
+        )
+        return "<Polygon><outerBoundaryIs>%s</outerBoundaryIs>%s</Polygon>" % (self[0].kml, inner_kml)
Index: venv/Lib/site-packages/django/contrib/gis/geos/prepared.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/gis/geos/prepared.py b/venv/Lib/site-packages/django/contrib/gis/geos/prepared.py
new file mode 100644
--- /dev/null	(date 1617030484371)
+++ b/venv/Lib/site-packages/django/contrib/gis/geos/prepared.py	(date 1617030484371)
@@ -0,0 +1,49 @@
+from .base import GEOSBase
+from .prototypes import prepared as capi
+
+
+class PreparedGeometry(GEOSBase):
+    """
+    A geometry that is prepared for performing certain operations.
+    At the moment this includes the contains covers, and intersects
+    operations.
+    """
+    ptr_type = capi.PREPGEOM_PTR
+    destructor = capi.prepared_destroy
+
+    def __init__(self, geom):
+        # Keeping a reference to the original geometry object to prevent it
+        # from being garbage collected which could then crash the prepared one
+        # See #21662
+        self._base_geom = geom
+        from .geometry import GEOSGeometry
+        if not isinstance(geom, GEOSGeometry):
+            raise TypeError
+        self.ptr = capi.geos_prepare(geom.ptr)
+
+    def contains(self, other):
+        return capi.prepared_contains(self.ptr, other.ptr)
+
+    def contains_properly(self, other):
+        return capi.prepared_contains_properly(self.ptr, other.ptr)
+
+    def covers(self, other):
+        return capi.prepared_covers(self.ptr, other.ptr)
+
+    def intersects(self, other):
+        return capi.prepared_intersects(self.ptr, other.ptr)
+
+    def crosses(self, other):
+        return capi.prepared_crosses(self.ptr, other.ptr)
+
+    def disjoint(self, other):
+        return capi.prepared_disjoint(self.ptr, other.ptr)
+
+    def overlaps(self, other):
+        return capi.prepared_overlaps(self.ptr, other.ptr)
+
+    def touches(self, other):
+        return capi.prepared_touches(self.ptr, other.ptr)
+
+    def within(self, other):
+        return capi.prepared_within(self.ptr, other.ptr)
Index: venv/Lib/site-packages/django/contrib/gis/geos/__init__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/gis/geos/__init__.py b/venv/Lib/site-packages/django/contrib/gis/geos/__init__.py
new file mode 100644
--- /dev/null	(date 1617030484366)
+++ b/venv/Lib/site-packages/django/contrib/gis/geos/__init__.py	(date 1617030484366)
@@ -0,0 +1,15 @@
+"""
+The GeoDjango GEOS module.  Please consult the GeoDjango documentation
+for more details: https://docs.djangoproject.com/en/dev/ref/contrib/gis/geos/
+"""
+from .collections import (  # NOQA
+    GeometryCollection, MultiLineString, MultiPoint, MultiPolygon,
+)
+from .error import GEOSException  # NOQA
+from .factory import fromfile, fromstr  # NOQA
+from .geometry import GEOSGeometry, hex_regex, wkt_regex  # NOQA
+from .io import WKBReader, WKBWriter, WKTReader, WKTWriter  # NOQA
+from .libgeos import geos_version  # NOQA
+from .linestring import LinearRing, LineString  # NOQA
+from .point import Point  # NOQA
+from .polygon import Polygon  # NOQA
Index: venv/Lib/site-packages/django/contrib/gis/admin/options.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/gis/admin/options.py b/venv/Lib/site-packages/django/contrib/gis/admin/options.py
new file mode 100644
--- /dev/null	(date 1617030484335)
+++ b/venv/Lib/site-packages/django/contrib/gis/admin/options.py	(date 1617030484335)
@@ -0,0 +1,134 @@
+from django.contrib.admin import ModelAdmin
+from django.contrib.gis.admin.widgets import OpenLayersWidget
+from django.contrib.gis.db import models
+from django.contrib.gis.gdal import OGRGeomType
+from django.forms import Media
+
+spherical_mercator_srid = 3857
+
+
+class GeoModelAdmin(ModelAdmin):
+    """
+    The administration options class for Geographic models. Map settings
+    may be overloaded from their defaults to create custom maps.
+    """
+    # The default map settings that may be overloaded -- still subject
+    # to API changes.
+    default_lon = 0
+    default_lat = 0
+    default_zoom = 4
+    display_wkt = False
+    display_srid = False
+    extra_js = []
+    num_zoom = 18
+    max_zoom = False
+    min_zoom = False
+    units = False
+    max_resolution = False
+    max_extent = False
+    modifiable = True
+    mouse_position = True
+    scale_text = True
+    layerswitcher = True
+    scrollable = True
+    map_width = 600
+    map_height = 400
+    map_srid = 4326
+    map_template = 'gis/admin/openlayers.html'
+    openlayers_url = 'https://cdnjs.cloudflare.com/ajax/libs/openlayers/2.13.1/OpenLayers.js'
+    point_zoom = num_zoom - 6
+    wms_url = 'http://vmap0.tiles.osgeo.org/wms/vmap0'
+    wms_layer = 'basic'
+    wms_name = 'OpenLayers WMS'
+    wms_options = {'format': 'image/jpeg'}
+    debug = False
+    widget = OpenLayersWidget
+
+    @property
+    def media(self):
+        "Injects OpenLayers JavaScript into the admin."
+        return super().media + Media(js=[self.openlayers_url] + self.extra_js)
+
+    def formfield_for_dbfield(self, db_field, request, **kwargs):
+        """
+        Overloaded from ModelAdmin so that an OpenLayersWidget is used
+        for viewing/editing 2D GeometryFields (OpenLayers 2 does not support
+        3D editing).
+        """
+        if isinstance(db_field, models.GeometryField) and db_field.dim < 3:
+            # Setting the widget with the newly defined widget.
+            kwargs['widget'] = self.get_map_widget(db_field)
+            return db_field.formfield(**kwargs)
+        else:
+            return super().formfield_for_dbfield(db_field, request, **kwargs)
+
+    def get_map_widget(self, db_field):
+        """
+        Return a subclass of the OpenLayersWidget (or whatever was specified
+        in the `widget` attribute) using the settings from the attributes set
+        in this class.
+        """
+        is_collection = db_field.geom_type in ('MULTIPOINT', 'MULTILINESTRING', 'MULTIPOLYGON', 'GEOMETRYCOLLECTION')
+        if is_collection:
+            if db_field.geom_type == 'GEOMETRYCOLLECTION':
+                collection_type = 'Any'
+            else:
+                collection_type = OGRGeomType(db_field.geom_type.replace('MULTI', ''))
+        else:
+            collection_type = 'None'
+
+        class OLMap(self.widget):
+            template_name = self.map_template
+            geom_type = db_field.geom_type
+
+            wms_options = ''
+            if self.wms_options:
+                wms_options = ["%s: '%s'" % pair for pair in self.wms_options.items()]
+                wms_options = ', %s' % ', '.join(wms_options)
+
+            params = {
+                'default_lon': self.default_lon,
+                'default_lat': self.default_lat,
+                'default_zoom': self.default_zoom,
+                'display_wkt': self.debug or self.display_wkt,
+                'geom_type': OGRGeomType(db_field.geom_type),
+                'field_name': db_field.name,
+                'is_collection': is_collection,
+                'scrollable': self.scrollable,
+                'layerswitcher': self.layerswitcher,
+                'collection_type': collection_type,
+                'is_generic': db_field.geom_type == 'GEOMETRY',
+                'is_linestring': db_field.geom_type in ('LINESTRING', 'MULTILINESTRING'),
+                'is_polygon': db_field.geom_type in ('POLYGON', 'MULTIPOLYGON'),
+                'is_point': db_field.geom_type in ('POINT', 'MULTIPOINT'),
+                'num_zoom': self.num_zoom,
+                'max_zoom': self.max_zoom,
+                'min_zoom': self.min_zoom,
+                'units': self.units,  # likely should get from object
+                'max_resolution': self.max_resolution,
+                'max_extent': self.max_extent,
+                'modifiable': self.modifiable,
+                'mouse_position': self.mouse_position,
+                'scale_text': self.scale_text,
+                'map_width': self.map_width,
+                'map_height': self.map_height,
+                'point_zoom': self.point_zoom,
+                'srid': self.map_srid,
+                'display_srid': self.display_srid,
+                'wms_url': self.wms_url,
+                'wms_layer': self.wms_layer,
+                'wms_name': self.wms_name,
+                'wms_options': wms_options,
+                'debug': self.debug,
+            }
+        return OLMap
+
+
+class OSMGeoAdmin(GeoModelAdmin):
+    map_template = 'gis/admin/osm.html'
+    num_zoom = 20
+    map_srid = spherical_mercator_srid
+    max_extent = '-20037508,-20037508,20037508,20037508'
+    max_resolution = '156543.0339'
+    point_zoom = num_zoom - 6
+    units = 'm'
Index: venv/Lib/site-packages/django/contrib/gis/admin/widgets.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/gis/admin/widgets.py b/venv/Lib/site-packages/django/contrib/gis/admin/widgets.py
new file mode 100644
--- /dev/null	(date 1617030484335)
+++ b/venv/Lib/site-packages/django/contrib/gis/admin/widgets.py	(date 1617030484335)
@@ -0,0 +1,117 @@
+import logging
+
+from django.contrib.gis.gdal import GDALException
+from django.contrib.gis.geos import GEOSException, GEOSGeometry
+from django.forms.widgets import Textarea
+from django.utils import translation
+
+# Creating a template context that contains Django settings
+# values needed by admin map templates.
+geo_context = {'LANGUAGE_BIDI': translation.get_language_bidi()}
+logger = logging.getLogger('django.contrib.gis')
+
+
+class OpenLayersWidget(Textarea):
+    """
+    Render an OpenLayers map using the WKT of the geometry.
+    """
+    def get_context(self, name, value, attrs):
+        # Update the template parameters with any attributes passed in.
+        if attrs:
+            self.params.update(attrs)
+            self.params['editable'] = self.params['modifiable']
+        else:
+            self.params['editable'] = True
+
+        # Defaulting the WKT value to a blank string -- this
+        # will be tested in the JavaScript and the appropriate
+        # interface will be constructed.
+        self.params['wkt'] = ''
+
+        # If a string reaches here (via a validation error on another
+        # field) then just reconstruct the Geometry.
+        if value and isinstance(value, str):
+            try:
+                value = GEOSGeometry(value)
+            except (GEOSException, ValueError) as err:
+                logger.error("Error creating geometry from value '%s' (%s)", value, err)
+                value = None
+
+        if (value and value.geom_type.upper() != self.geom_type and
+                self.geom_type != 'GEOMETRY'):
+            value = None
+
+        # Constructing the dictionary of the map options.
+        self.params['map_options'] = self.map_options()
+
+        # Constructing the JavaScript module name using the name of
+        # the GeometryField (passed in via the `attrs` keyword).
+        # Use the 'name' attr for the field name (rather than 'field')
+        self.params['name'] = name
+        # note: we must switch out dashes for underscores since js
+        # functions are created using the module variable
+        js_safe_name = self.params['name'].replace('-', '_')
+        self.params['module'] = 'geodjango_%s' % js_safe_name
+
+        if value:
+            # Transforming the geometry to the projection used on the
+            # OpenLayers map.
+            srid = self.params['srid']
+            if value.srid != srid:
+                try:
+                    ogr = value.ogr
+                    ogr.transform(srid)
+                    wkt = ogr.wkt
+                except GDALException as err:
+                    logger.error(
+                        "Error transforming geometry from srid '%s' to srid '%s' (%s)",
+                        value.srid, srid, err
+                    )
+                    wkt = ''
+            else:
+                wkt = value.wkt
+
+            # Setting the parameter WKT with that of the transformed
+            # geometry.
+            self.params['wkt'] = wkt
+
+        self.params.update(geo_context)
+        return self.params
+
+    def map_options(self):
+        """Build the map options hash for the OpenLayers template."""
+        # JavaScript construction utilities for the Bounds and Projection.
+        def ol_bounds(extent):
+            return 'new OpenLayers.Bounds(%s)' % extent
+
+        def ol_projection(srid):
+            return 'new OpenLayers.Projection("EPSG:%s")' % srid
+
+        # An array of the parameter name, the name of their OpenLayers
+        # counterpart, and the type of variable they are.
+        map_types = [('srid', 'projection', 'srid'),
+                     ('display_srid', 'displayProjection', 'srid'),
+                     ('units', 'units', str),
+                     ('max_resolution', 'maxResolution', float),
+                     ('max_extent', 'maxExtent', 'bounds'),
+                     ('num_zoom', 'numZoomLevels', int),
+                     ('max_zoom', 'maxZoomLevels', int),
+                     ('min_zoom', 'minZoomLevel', int),
+                     ]
+
+        # Building the map options hash.
+        map_options = {}
+        for param_name, js_name, option_type in map_types:
+            if self.params.get(param_name, False):
+                if option_type == 'srid':
+                    value = ol_projection(self.params[param_name])
+                elif option_type == 'bounds':
+                    value = ol_bounds(self.params[param_name])
+                elif option_type in (float, int):
+                    value = self.params[param_name]
+                elif option_type in (str,):
+                    value = '"%s"' % self.params[param_name]
+                else:
+                    raise TypeError
+                map_options[js_name] = value
+        return map_options
Index: venv/Lib/site-packages/django/contrib/gis/admin/__init__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/gis/admin/__init__.py b/venv/Lib/site-packages/django/contrib/gis/admin/__init__.py
new file mode 100644
--- /dev/null	(date 1617030484334)
+++ b/venv/Lib/site-packages/django/contrib/gis/admin/__init__.py	(date 1617030484334)
@@ -0,0 +1,12 @@
+from django.contrib.admin import (
+    HORIZONTAL, VERTICAL, AdminSite, ModelAdmin, StackedInline, TabularInline,
+    autodiscover, register, site,
+)
+from django.contrib.gis.admin.options import GeoModelAdmin, OSMGeoAdmin
+from django.contrib.gis.admin.widgets import OpenLayersWidget
+
+__all__ = [
+    'HORIZONTAL', 'VERTICAL', 'AdminSite', 'ModelAdmin', 'StackedInline',
+    'TabularInline', 'autodiscover', 'register', 'site',
+    'GeoModelAdmin', 'OSMGeoAdmin', 'OpenLayersWidget',
+]
Index: venv/Lib/site-packages/django/contrib/gis/forms/fields.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/gis/forms/fields.py b/venv/Lib/site-packages/django/contrib/gis/forms/fields.py
new file mode 100644
--- /dev/null	(date 1617030484354)
+++ b/venv/Lib/site-packages/django/contrib/gis/forms/fields.py	(date 1617030484354)
@@ -0,0 +1,133 @@
+from django import forms
+from django.contrib.gis.gdal import GDALException
+from django.contrib.gis.geos import GEOSException, GEOSGeometry
+from django.core.exceptions import ValidationError
+from django.utils.translation import gettext_lazy as _
+
+from .widgets import OpenLayersWidget
+
+
+class GeometryField(forms.Field):
+    """
+    This is the basic form field for a Geometry.  Any textual input that is
+    accepted by GEOSGeometry is accepted by this form.  By default,
+    this includes WKT, HEXEWKB, WKB (in a buffer), and GeoJSON.
+    """
+    widget = OpenLayersWidget
+    geom_type = 'GEOMETRY'
+
+    default_error_messages = {
+        'required': _('No geometry value provided.'),
+        'invalid_geom': _('Invalid geometry value.'),
+        'invalid_geom_type': _('Invalid geometry type.'),
+        'transform_error': _('An error occurred when transforming the geometry '
+                             'to the SRID of the geometry form field.'),
+    }
+
+    def __init__(self, *, srid=None, geom_type=None, **kwargs):
+        self.srid = srid
+        if geom_type is not None:
+            self.geom_type = geom_type
+        super().__init__(**kwargs)
+        self.widget.attrs['geom_type'] = self.geom_type
+
+    def to_python(self, value):
+        """Transform the value to a Geometry object."""
+        if value in self.empty_values:
+            return None
+
+        if not isinstance(value, GEOSGeometry):
+            if hasattr(self.widget, 'deserialize'):
+                try:
+                    value = self.widget.deserialize(value)
+                except GDALException:
+                    value = None
+            else:
+                try:
+                    value = GEOSGeometry(value)
+                except (GEOSException, ValueError, TypeError):
+                    value = None
+            if value is None:
+                raise ValidationError(self.error_messages['invalid_geom'], code='invalid_geom')
+
+        # Try to set the srid
+        if not value.srid:
+            try:
+                value.srid = self.widget.map_srid
+            except AttributeError:
+                if self.srid:
+                    value.srid = self.srid
+        return value
+
+    def clean(self, value):
+        """
+        Validate that the input value can be converted to a Geometry object
+        and return it. Raise a ValidationError if the value cannot be
+        instantiated as a Geometry.
+        """
+        geom = super().clean(value)
+        if geom is None:
+            return geom
+
+        # Ensuring that the geometry is of the correct type (indicated
+        # using the OGC string label).
+        if str(geom.geom_type).upper() != self.geom_type and not self.geom_type == 'GEOMETRY':
+            raise ValidationError(self.error_messages['invalid_geom_type'], code='invalid_geom_type')
+
+        # Transforming the geometry if the SRID was set.
+        if self.srid and self.srid != -1 and self.srid != geom.srid:
+            try:
+                geom.transform(self.srid)
+            except GEOSException:
+                raise ValidationError(
+                    self.error_messages['transform_error'], code='transform_error')
+
+        return geom
+
+    def has_changed(self, initial, data):
+        """ Compare geographic value of data with its initial value. """
+
+        try:
+            data = self.to_python(data)
+            initial = self.to_python(initial)
+        except ValidationError:
+            return True
+
+        # Only do a geographic comparison if both values are available
+        if initial and data:
+            data.transform(initial.srid)
+            # If the initial value was not added by the browser, the geometry
+            # provided may be slightly different, the first time it is saved.
+            # The comparison is done with a very low tolerance.
+            return not initial.equals_exact(data, tolerance=0.000001)
+        else:
+            # Check for change of state of existence
+            return bool(initial) != bool(data)
+
+
+class GeometryCollectionField(GeometryField):
+    geom_type = 'GEOMETRYCOLLECTION'
+
+
+class PointField(GeometryField):
+    geom_type = 'POINT'
+
+
+class MultiPointField(GeometryField):
+    geom_type = 'MULTIPOINT'
+
+
+class LineStringField(GeometryField):
+    geom_type = 'LINESTRING'
+
+
+class MultiLineStringField(GeometryField):
+    geom_type = 'MULTILINESTRING'
+
+
+class PolygonField(GeometryField):
+    geom_type = 'POLYGON'
+
+
+class MultiPolygonField(GeometryField):
+    geom_type = 'MULTIPOLYGON'
Index: venv/Lib/site-packages/django/contrib/gis/forms/widgets.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/gis/forms/widgets.py b/venv/Lib/site-packages/django/contrib/gis/forms/widgets.py
new file mode 100644
--- /dev/null	(date 1617030484355)
+++ b/venv/Lib/site-packages/django/contrib/gis/forms/widgets.py	(date 1617030484355)
@@ -0,0 +1,117 @@
+import logging
+
+from django.conf import settings
+from django.contrib.gis import gdal
+from django.contrib.gis.geometry import json_regex
+from django.contrib.gis.geos import GEOSException, GEOSGeometry
+from django.forms.widgets import Widget
+from django.utils import translation
+
+logger = logging.getLogger('django.contrib.gis')
+
+
+class BaseGeometryWidget(Widget):
+    """
+    The base class for rich geometry widgets.
+    Render a map using the WKT of the geometry.
+    """
+    geom_type = 'GEOMETRY'
+    map_srid = 4326
+    map_width = 600
+    map_height = 400
+    display_raw = False
+
+    supports_3d = False
+    template_name = ''  # set on subclasses
+
+    def __init__(self, attrs=None):
+        self.attrs = {}
+        for key in ('geom_type', 'map_srid', 'map_width', 'map_height', 'display_raw'):
+            self.attrs[key] = getattr(self, key)
+        if attrs:
+            self.attrs.update(attrs)
+
+    def serialize(self, value):
+        return value.wkt if value else ''
+
+    def deserialize(self, value):
+        try:
+            return GEOSGeometry(value)
+        except (GEOSException, ValueError, TypeError) as err:
+            logger.error("Error creating geometry from value '%s' (%s)", value, err)
+        return None
+
+    def get_context(self, name, value, attrs):
+        context = super().get_context(name, value, attrs)
+        # If a string reaches here (via a validation error on another
+        # field) then just reconstruct the Geometry.
+        if value and isinstance(value, str):
+            value = self.deserialize(value)
+
+        if value:
+            # Check that srid of value and map match
+            if value.srid and value.srid != self.map_srid:
+                try:
+                    ogr = value.ogr
+                    ogr.transform(self.map_srid)
+                    value = ogr
+                except gdal.GDALException as err:
+                    logger.error(
+                        "Error transforming geometry from srid '%s' to srid '%s' (%s)",
+                        value.srid, self.map_srid, err
+                    )
+
+        context.update(self.build_attrs(self.attrs, {
+            'name': name,
+            'module': 'geodjango_%s' % name.replace('-', '_'),  # JS-safe
+            'serialized': self.serialize(value),
+            'geom_type': gdal.OGRGeomType(self.attrs['geom_type']),
+            'STATIC_URL': settings.STATIC_URL,
+            'LANGUAGE_BIDI': translation.get_language_bidi(),
+            **(attrs or {}),
+        }))
+        return context
+
+
+class OpenLayersWidget(BaseGeometryWidget):
+    template_name = 'gis/openlayers.html'
+    map_srid = 3857
+
+    class Media:
+        css = {
+            'all': (
+                'https://cdnjs.cloudflare.com/ajax/libs/ol3/4.6.5/ol.css',
+                'gis/css/ol3.css',
+            )
+        }
+        js = (
+            'https://cdnjs.cloudflare.com/ajax/libs/ol3/4.6.5/ol.js',
+            'gis/js/OLMapWidget.js',
+        )
+
+    def serialize(self, value):
+        return value.json if value else ''
+
+    def deserialize(self, value):
+        geom = super().deserialize(value)
+        # GeoJSON assumes WGS84 (4326). Use the map's SRID instead.
+        if geom and json_regex.match(value) and self.map_srid != 4326:
+            geom.srid = self.map_srid
+        return geom
+
+
+class OSMWidget(OpenLayersWidget):
+    """
+    An OpenLayers/OpenStreetMap-based widget.
+    """
+    template_name = 'gis/openlayers-osm.html'
+    default_lon = 5
+    default_lat = 47
+    default_zoom = 12
+
+    def __init__(self, attrs=None):
+        super().__init__()
+        for key in ('default_lon', 'default_lat', 'default_zoom'):
+            self.attrs[key] = getattr(self, key)
+        if attrs:
+            self.attrs.update(attrs)
Index: venv/Lib/site-packages/django/contrib/gis/forms/__init__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/gis/forms/__init__.py b/venv/Lib/site-packages/django/contrib/gis/forms/__init__.py
new file mode 100644
--- /dev/null	(date 1617030484354)
+++ b/venv/Lib/site-packages/django/contrib/gis/forms/__init__.py	(date 1617030484354)
@@ -0,0 +1,8 @@
+from django.forms import *  # NOQA
+
+from .fields import (  # NOQA
+    GeometryCollectionField, GeometryField, LineStringField,
+    MultiLineStringField, MultiPointField, MultiPolygonField, PointField,
+    PolygonField,
+)
+from .widgets import BaseGeometryWidget, OpenLayersWidget, OSMWidget  # NOQA
Index: venv/Lib/site-packages/django/contrib/gis/utils/layermapping.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/gis/utils/layermapping.py b/venv/Lib/site-packages/django/contrib/gis/utils/layermapping.py
new file mode 100644
--- /dev/null	(date 1617030484469)
+++ b/venv/Lib/site-packages/django/contrib/gis/utils/layermapping.py	(date 1617030484469)
@@ -0,0 +1,636 @@
+# LayerMapping -- A Django Model/OGR Layer Mapping Utility
+"""
+ The LayerMapping class provides a way to map the contents of OGR
+ vector files (e.g. SHP files) to Geographic-enabled Django models.
+
+ For more information, please consult the GeoDjango documentation:
+   https://docs.djangoproject.com/en/dev/ref/contrib/gis/layermapping/
+"""
+import sys
+from decimal import Decimal, InvalidOperation as DecimalInvalidOperation
+
+from django.contrib.gis.db.models import GeometryField
+from django.contrib.gis.gdal import (
+    CoordTransform, DataSource, GDALException, OGRGeometry, OGRGeomType,
+    SpatialReference,
+)
+from django.contrib.gis.gdal.field import (
+    OFTDate, OFTDateTime, OFTInteger, OFTInteger64, OFTReal, OFTString,
+    OFTTime,
+)
+from django.core.exceptions import FieldDoesNotExist, ObjectDoesNotExist
+from django.db import connections, models, router, transaction
+from django.utils.encoding import force_str
+
+
+# LayerMapping exceptions.
+class LayerMapError(Exception):
+    pass
+
+
+class InvalidString(LayerMapError):
+    pass
+
+
+class InvalidDecimal(LayerMapError):
+    pass
+
+
+class InvalidInteger(LayerMapError):
+    pass
+
+
+class MissingForeignKey(LayerMapError):
+    pass
+
+
+class LayerMapping:
+    "A class that maps OGR Layers to GeoDjango Models."
+
+    # Acceptable 'base' types for a multi-geometry type.
+    MULTI_TYPES = {
+        1: OGRGeomType('MultiPoint'),
+        2: OGRGeomType('MultiLineString'),
+        3: OGRGeomType('MultiPolygon'),
+        OGRGeomType('Point25D').num: OGRGeomType('MultiPoint25D'),
+        OGRGeomType('LineString25D').num: OGRGeomType('MultiLineString25D'),
+        OGRGeomType('Polygon25D').num: OGRGeomType('MultiPolygon25D'),
+    }
+    # Acceptable Django field types and corresponding acceptable OGR
+    # counterparts.
+    FIELD_TYPES = {
+        models.AutoField: OFTInteger,
+        models.BigAutoField: OFTInteger64,
+        models.SmallAutoField: OFTInteger,
+        models.BooleanField: (OFTInteger, OFTReal, OFTString),
+        models.IntegerField: (OFTInteger, OFTReal, OFTString),
+        models.FloatField: (OFTInteger, OFTReal),
+        models.DateField: OFTDate,
+        models.DateTimeField: OFTDateTime,
+        models.EmailField: OFTString,
+        models.TimeField: OFTTime,
+        models.DecimalField: (OFTInteger, OFTReal),
+        models.CharField: OFTString,
+        models.SlugField: OFTString,
+        models.TextField: OFTString,
+        models.URLField: OFTString,
+        models.UUIDField: OFTString,
+        models.BigIntegerField: (OFTInteger, OFTReal, OFTString),
+        models.SmallIntegerField: (OFTInteger, OFTReal, OFTString),
+        models.PositiveBigIntegerField: (OFTInteger, OFTReal, OFTString),
+        models.PositiveIntegerField: (OFTInteger, OFTReal, OFTString),
+        models.PositiveSmallIntegerField: (OFTInteger, OFTReal, OFTString),
+    }
+
+    def __init__(self, model, data, mapping, layer=0,
+                 source_srs=None, encoding='utf-8',
+                 transaction_mode='commit_on_success',
+                 transform=True, unique=None, using=None):
+        """
+        A LayerMapping object is initialized using the given Model (not an instance),
+        a DataSource (or string path to an OGR-supported data file), and a mapping
+        dictionary.  See the module level docstring for more details and keyword
+        argument usage.
+        """
+        # Getting the DataSource and the associated Layer.
+        if isinstance(data, str):
+            self.ds = DataSource(data, encoding=encoding)
+        else:
+            self.ds = data
+        self.layer = self.ds[layer]
+
+        self.using = using if using is not None else router.db_for_write(model)
+        self.spatial_backend = connections[self.using].ops
+
+        # Setting the mapping & model attributes.
+        self.mapping = mapping
+        self.model = model
+
+        # Checking the layer -- initialization of the object will fail if
+        # things don't check out before hand.
+        self.check_layer()
+
+        # Getting the geometry column associated with the model (an
+        # exception will be raised if there is no geometry column).
+        if connections[self.using].features.supports_transform:
+            self.geo_field = self.geometry_field()
+        else:
+            transform = False
+
+        # Checking the source spatial reference system, and getting
+        # the coordinate transformation object (unless the `transform`
+        # keyword is set to False)
+        if transform:
+            self.source_srs = self.check_srs(source_srs)
+            self.transform = self.coord_transform()
+        else:
+            self.transform = transform
+
+        # Setting the encoding for OFTString fields, if specified.
+        if encoding:
+            # Making sure the encoding exists, if not a LookupError
+            # exception will be thrown.
+            from codecs import lookup
+            lookup(encoding)
+            self.encoding = encoding
+        else:
+            self.encoding = None
+
+        if unique:
+            self.check_unique(unique)
+            transaction_mode = 'autocommit'  # Has to be set to autocommit.
+            self.unique = unique
+        else:
+            self.unique = None
+
+        # Setting the transaction decorator with the function in the
+        # transaction modes dictionary.
+        self.transaction_mode = transaction_mode
+        if transaction_mode == 'autocommit':
+            self.transaction_decorator = None
+        elif transaction_mode == 'commit_on_success':
+            self.transaction_decorator = transaction.atomic
+        else:
+            raise LayerMapError('Unrecognized transaction mode: %s' % transaction_mode)
+
+    # #### Checking routines used during initialization ####
+    def check_fid_range(self, fid_range):
+        "Check the `fid_range` keyword."
+        if fid_range:
+            if isinstance(fid_range, (tuple, list)):
+                return slice(*fid_range)
+            elif isinstance(fid_range, slice):
+                return fid_range
+            else:
+                raise TypeError
+        else:
+            return None
+
+    def check_layer(self):
+        """
+        Check the Layer metadata and ensure that it's compatible with the
+        mapping information and model. Unlike previous revisions, there is no
+        need to increment through each feature in the Layer.
+        """
+        # The geometry field of the model is set here.
+        # TODO: Support more than one geometry field / model.  However, this
+        # depends on the GDAL Driver in use.
+        self.geom_field = False
+        self.fields = {}
+
+        # Getting lists of the field names and the field types available in
+        # the OGR Layer.
+        ogr_fields = self.layer.fields
+        ogr_field_types = self.layer.field_types
+
+        # Function for determining if the OGR mapping field is in the Layer.
+        def check_ogr_fld(ogr_map_fld):
+            try:
+                idx = ogr_fields.index(ogr_map_fld)
+            except ValueError:
+                raise LayerMapError('Given mapping OGR field "%s" not found in OGR Layer.' % ogr_map_fld)
+            return idx
+
+        # No need to increment through each feature in the model, simply check
+        # the Layer metadata against what was given in the mapping dictionary.
+        for field_name, ogr_name in self.mapping.items():
+            # Ensuring that a corresponding field exists in the model
+            # for the given field name in the mapping.
+            try:
+                model_field = self.model._meta.get_field(field_name)
+            except FieldDoesNotExist:
+                raise LayerMapError('Given mapping field "%s" not in given Model fields.' % field_name)
+
+            # Getting the string name for the Django field class (e.g., 'PointField').
+            fld_name = model_field.__class__.__name__
+
+            if isinstance(model_field, GeometryField):
+                if self.geom_field:
+                    raise LayerMapError('LayerMapping does not support more than one GeometryField per model.')
+
+                # Getting the coordinate dimension of the geometry field.
+                coord_dim = model_field.dim
+
+                try:
+                    if coord_dim == 3:
+                        gtype = OGRGeomType(ogr_name + '25D')
+                    else:
+                        gtype = OGRGeomType(ogr_name)
+                except GDALException:
+                    raise LayerMapError('Invalid mapping for GeometryField "%s".' % field_name)
+
+                # Making sure that the OGR Layer's Geometry is compatible.
+                ltype = self.layer.geom_type
+                if not (ltype.name.startswith(gtype.name) or self.make_multi(ltype, model_field)):
+                    raise LayerMapError('Invalid mapping geometry; model has %s%s, '
+                                        'layer geometry type is %s.' %
+                                        (fld_name, '(dim=3)' if coord_dim == 3 else '', ltype))
+
+                # Setting the `geom_field` attribute w/the name of the model field
+                # that is a Geometry.  Also setting the coordinate dimension
+                # attribute.
+                self.geom_field = field_name
+                self.coord_dim = coord_dim
+                fields_val = model_field
+            elif isinstance(model_field, models.ForeignKey):
+                if isinstance(ogr_name, dict):
+                    # Is every given related model mapping field in the Layer?
+                    rel_model = model_field.remote_field.model
+                    for rel_name, ogr_field in ogr_name.items():
+                        idx = check_ogr_fld(ogr_field)
+                        try:
+                            rel_model._meta.get_field(rel_name)
+                        except FieldDoesNotExist:
+                            raise LayerMapError('ForeignKey mapping field "%s" not in %s fields.' %
+                                                (rel_name, rel_model.__class__.__name__))
+                    fields_val = rel_model
+                else:
+                    raise TypeError('ForeignKey mapping must be of dictionary type.')
+            else:
+                # Is the model field type supported by LayerMapping?
+                if model_field.__class__ not in self.FIELD_TYPES:
+                    raise LayerMapError('Django field type "%s" has no OGR mapping (yet).' % fld_name)
+
+                # Is the OGR field in the Layer?
+                idx = check_ogr_fld(ogr_name)
+                ogr_field = ogr_field_types[idx]
+
+                # Can the OGR field type be mapped to the Django field type?
+                if not issubclass(ogr_field, self.FIELD_TYPES[model_field.__class__]):
+                    raise LayerMapError('OGR field "%s" (of type %s) cannot be mapped to Django %s.' %
+                                        (ogr_field, ogr_field.__name__, fld_name))
+                fields_val = model_field
+
+            self.fields[field_name] = fields_val
+
+    def check_srs(self, source_srs):
+        "Check the compatibility of the given spatial reference object."
+
+        if isinstance(source_srs, SpatialReference):
+            sr = source_srs
+        elif isinstance(source_srs, self.spatial_backend.spatial_ref_sys()):
+            sr = source_srs.srs
+        elif isinstance(source_srs, (int, str)):
+            sr = SpatialReference(source_srs)
+        else:
+            # Otherwise just pulling the SpatialReference from the layer
+            sr = self.layer.srs
+
+        if not sr:
+            raise LayerMapError('No source reference system defined.')
+        else:
+            return sr
+
+    def check_unique(self, unique):
+        "Check the `unique` keyword parameter -- may be a sequence or string."
+        if isinstance(unique, (list, tuple)):
+            # List of fields to determine uniqueness with
+            for attr in unique:
+                if attr not in self.mapping:
+                    raise ValueError
+        elif isinstance(unique, str):
+            # Only a single field passed in.
+            if unique not in self.mapping:
+                raise ValueError
+        else:
+            raise TypeError('Unique keyword argument must be set with a tuple, list, or string.')
+
+    # Keyword argument retrieval routines ####
+    def feature_kwargs(self, feat):
+        """
+        Given an OGR Feature, return a dictionary of keyword arguments for
+        constructing the mapped model.
+        """
+        # The keyword arguments for model construction.
+        kwargs = {}
+
+        # Incrementing through each model field and OGR field in the
+        # dictionary mapping.
+        for field_name, ogr_name in self.mapping.items():
+            model_field = self.fields[field_name]
+
+            if isinstance(model_field, GeometryField):
+                # Verify OGR geometry.
+                try:
+                    val = self.verify_geom(feat.geom, model_field)
+                except GDALException:
+                    raise LayerMapError('Could not retrieve geometry from feature.')
+            elif isinstance(model_field, models.base.ModelBase):
+                # The related _model_, not a field was passed in -- indicating
+                # another mapping for the related Model.
+                val = self.verify_fk(feat, model_field, ogr_name)
+            else:
+                # Otherwise, verify OGR Field type.
+                val = self.verify_ogr_field(feat[ogr_name], model_field)
+
+            # Setting the keyword arguments for the field name with the
+            # value obtained above.
+            kwargs[field_name] = val
+
+        return kwargs
+
+    def unique_kwargs(self, kwargs):
+        """
+        Given the feature keyword arguments (from `feature_kwargs`), construct
+        and return the uniqueness keyword arguments -- a subset of the feature
+        kwargs.
+        """
+        if isinstance(self.unique, str):
+            return {self.unique: kwargs[self.unique]}
+        else:
+            return {fld: kwargs[fld] for fld in self.unique}
+
+    # #### Verification routines used in constructing model keyword arguments. ####
+    def verify_ogr_field(self, ogr_field, model_field):
+        """
+        Verify if the OGR Field contents are acceptable to the model field. If
+        they are, return the verified value, otherwise raise an exception.
+        """
+        if (isinstance(ogr_field, OFTString) and
+                isinstance(model_field, (models.CharField, models.TextField))):
+            if self.encoding and ogr_field.value is not None:
+                # The encoding for OGR data sources may be specified here
+                # (e.g., 'cp437' for Census Bureau boundary files).
+                val = force_str(ogr_field.value, self.encoding)
+            else:
+                val = ogr_field.value
+            if model_field.max_length and val is not None and len(val) > model_field.max_length:
+                raise InvalidString('%s model field maximum string length is %s, given %s characters.' %
+                                    (model_field.name, model_field.max_length, len(val)))
+        elif isinstance(ogr_field, OFTReal) and isinstance(model_field, models.DecimalField):
+            try:
+                # Creating an instance of the Decimal value to use.
+                d = Decimal(str(ogr_field.value))
+            except DecimalInvalidOperation:
+                raise InvalidDecimal('Could not construct decimal from: %s' % ogr_field.value)
+
+            # Getting the decimal value as a tuple.
+            dtup = d.as_tuple()
+            digits = dtup[1]
+            d_idx = dtup[2]  # index where the decimal is
+
+            # Maximum amount of precision, or digits to the left of the decimal.
+            max_prec = model_field.max_digits - model_field.decimal_places
+
+            # Getting the digits to the left of the decimal place for the
+            # given decimal.
+            if d_idx < 0:
+                n_prec = len(digits[:d_idx])
+            else:
+                n_prec = len(digits) + d_idx
+
+            # If we have more than the maximum digits allowed, then throw an
+            # InvalidDecimal exception.
+            if n_prec > max_prec:
+                raise InvalidDecimal(
+                    'A DecimalField with max_digits %d, decimal_places %d must '
+                    'round to an absolute value less than 10^%d.' %
+                    (model_field.max_digits, model_field.decimal_places, max_prec)
+                )
+            val = d
+        elif isinstance(ogr_field, (OFTReal, OFTString)) and isinstance(model_field, models.IntegerField):
+            # Attempt to convert any OFTReal and OFTString value to an OFTInteger.
+            try:
+                val = int(ogr_field.value)
+            except ValueError:
+                raise InvalidInteger('Could not construct integer from: %s' % ogr_field.value)
+        else:
+            val = ogr_field.value
+        return val
+
+    def verify_fk(self, feat, rel_model, rel_mapping):
+        """
+        Given an OGR Feature, the related model and its dictionary mapping,
+        retrieve the related model for the ForeignKey mapping.
+        """
+        # TODO: It is expensive to retrieve a model for every record --
+        #  explore if an efficient mechanism exists for caching related
+        #  ForeignKey models.
+
+        # Constructing and verifying the related model keyword arguments.
+        fk_kwargs = {}
+        for field_name, ogr_name in rel_mapping.items():
+            fk_kwargs[field_name] = self.verify_ogr_field(feat[ogr_name], rel_model._meta.get_field(field_name))
+
+        # Attempting to retrieve and return the related model.
+        try:
+            return rel_model.objects.using(self.using).get(**fk_kwargs)
+        except ObjectDoesNotExist:
+            raise MissingForeignKey(
+                'No ForeignKey %s model found with keyword arguments: %s' %
+                (rel_model.__name__, fk_kwargs)
+            )
+
+    def verify_geom(self, geom, model_field):
+        """
+        Verify the geometry -- construct and return a GeometryCollection
+        if necessary (for example if the model field is MultiPolygonField while
+        the mapped shapefile only contains Polygons).
+        """
+        # Downgrade a 3D geom to a 2D one, if necessary.
+        if self.coord_dim != geom.coord_dim:
+            geom.coord_dim = self.coord_dim
+
+        if self.make_multi(geom.geom_type, model_field):
+            # Constructing a multi-geometry type to contain the single geometry
+            multi_type = self.MULTI_TYPES[geom.geom_type.num]
+            g = OGRGeometry(multi_type)
+            g.add(geom)
+        else:
+            g = geom
+
+        # Transforming the geometry with our Coordinate Transformation object,
+        # but only if the class variable `transform` is set w/a CoordTransform
+        # object.
+        if self.transform:
+            g.transform(self.transform)
+
+        # Returning the WKT of the geometry.
+        return g.wkt
+
+    # #### Other model methods ####
+    def coord_transform(self):
+        "Return the coordinate transformation object."
+        SpatialRefSys = self.spatial_backend.spatial_ref_sys()
+        try:
+            # Getting the target spatial reference system
+            target_srs = SpatialRefSys.objects.using(self.using).get(srid=self.geo_field.srid).srs
+
+            # Creating the CoordTransform object
+            return CoordTransform(self.source_srs, target_srs)
+        except Exception as exc:
+            raise LayerMapError(
+                'Could not translate between the data source and model geometry.'
+            ) from exc
+
+    def geometry_field(self):
+        "Return the GeometryField instance associated with the geographic column."
+        # Use `get_field()` on the model's options so that we
+        # get the correct field instance if there's model inheritance.
+        opts = self.model._meta
+        return opts.get_field(self.geom_field)
+
+    def make_multi(self, geom_type, model_field):
+        """
+        Given the OGRGeomType for a geometry and its associated GeometryField,
+        determine whether the geometry should be turned into a GeometryCollection.
+        """
+        return (geom_type.num in self.MULTI_TYPES and
+                model_field.__class__.__name__ == 'Multi%s' % geom_type.django)
+
+    def save(self, verbose=False, fid_range=False, step=False,
+             progress=False, silent=False, stream=sys.stdout, strict=False):
+        """
+        Save the contents from the OGR DataSource Layer into the database
+        according to the mapping dictionary given at initialization.
+
+        Keyword Parameters:
+         verbose:
+           If set, information will be printed subsequent to each model save
+           executed on the database.
+
+         fid_range:
+           May be set with a slice or tuple of (begin, end) feature ID's to map
+           from the data source.  In other words, this keyword enables the user
+           to selectively import a subset range of features in the geographic
+           data source.
+
+         step:
+           If set with an integer, transactions will occur at every step
+           interval. For example, if step=1000, a commit would occur after
+           the 1,000th feature, the 2,000th feature etc.
+
+         progress:
+           When this keyword is set, status information will be printed giving
+           the number of features processed and successfully saved.  By default,
+           progress information will pe printed every 1000 features processed,
+           however, this default may be overridden by setting this keyword with an
+           integer for the desired interval.
+
+         stream:
+           Status information will be written to this file handle.  Defaults to
+           using `sys.stdout`, but any object with a `write` method is supported.
+
+         silent:
+           By default, non-fatal error notifications are printed to stdout, but
+           this keyword may be set to disable these notifications.
+
+         strict:
+           Execution of the model mapping will cease upon the first error
+           encountered.  The default behavior is to attempt to continue.
+        """
+        # Getting the default Feature ID range.
+        default_range = self.check_fid_range(fid_range)
+
+        # Setting the progress interval, if requested.
+        if progress:
+            if progress is True or not isinstance(progress, int):
+                progress_interval = 1000
+            else:
+                progress_interval = progress
+
+        def _save(feat_range=default_range, num_feat=0, num_saved=0):
+            if feat_range:
+                layer_iter = self.layer[feat_range]
+            else:
+                layer_iter = self.layer
+
+            for feat in layer_iter:
+                num_feat += 1
+                # Getting the keyword arguments
+                try:
+                    kwargs = self.feature_kwargs(feat)
+                except LayerMapError as msg:
+                    # Something borked the validation
+                    if strict:
+                        raise
+                    elif not silent:
+                        stream.write('Ignoring Feature ID %s because: %s\n' % (feat.fid, msg))
+                else:
+                    # Constructing the model using the keyword args
+                    is_update = False
+                    if self.unique:
+                        # If we want unique models on a particular field, handle the
+                        # geometry appropriately.
+                        try:
+                            # Getting the keyword arguments and retrieving
+                            # the unique model.
+                            u_kwargs = self.unique_kwargs(kwargs)
+                            m = self.model.objects.using(self.using).get(**u_kwargs)
+                            is_update = True
+
+                            # Getting the geometry (in OGR form), creating
+                            # one from the kwargs WKT, adding in additional
+                            # geometries, and update the attribute with the
+                            # just-updated geometry WKT.
+                            geom_value = getattr(m, self.geom_field)
+                            if geom_value is None:
+                                geom = OGRGeometry(kwargs[self.geom_field])
+                            else:
+                                geom = geom_value.ogr
+                                new = OGRGeometry(kwargs[self.geom_field])
+                                for g in new:
+                                    geom.add(g)
+                            setattr(m, self.geom_field, geom.wkt)
+                        except ObjectDoesNotExist:
+                            # No unique model exists yet, create.
+                            m = self.model(**kwargs)
+                    else:
+                        m = self.model(**kwargs)
+
+                    try:
+                        # Attempting to save.
+                        m.save(using=self.using)
+                        num_saved += 1
+                        if verbose:
+                            stream.write('%s: %s\n' % ('Updated' if is_update else 'Saved', m))
+                    except Exception as msg:
+                        if strict:
+                            # Bailing out if the `strict` keyword is set.
+                            if not silent:
+                                stream.write(
+                                    'Failed to save the feature (id: %s) into the '
+                                    'model with the keyword arguments:\n' % feat.fid
+                                )
+                                stream.write('%s\n' % kwargs)
+                            raise
+                        elif not silent:
+                            stream.write('Failed to save %s:\n %s\nContinuing\n' % (kwargs, msg))
+
+                # Printing progress information, if requested.
+                if progress and num_feat % progress_interval == 0:
+                    stream.write('Processed %d features, saved %d ...\n' % (num_feat, num_saved))
+
+            # Only used for status output purposes -- incremental saving uses the
+            # values returned here.
+            return num_saved, num_feat
+
+        if self.transaction_decorator is not None:
+            _save = self.transaction_decorator(_save)
+
+        nfeat = self.layer.num_feat
+        if step and isinstance(step, int) and step < nfeat:
+            # Incremental saving is requested at the given interval (step)
+            if default_range:
+                raise LayerMapError('The `step` keyword may not be used in conjunction with the `fid_range` keyword.')
+            beg, num_feat, num_saved = (0, 0, 0)
+            indices = range(step, nfeat, step)
+            n_i = len(indices)
+
+            for i, end in enumerate(indices):
+                # Constructing the slice to use for this step; the last slice is
+                # special (e.g, [100:] instead of [90:100]).
+                if i + 1 == n_i:
+                    step_slice = slice(beg, None)
+                else:
+                    step_slice = slice(beg, end)
+
+                try:
+                    num_feat, num_saved = _save(step_slice, num_feat, num_saved)
+                    beg = end
+                except Exception:  # Deliberately catch everything
+                    stream.write('%s\nFailed to save slice: %s\n' % ('=-' * 20, step_slice))
+                    raise
+        else:
+            # Otherwise, just calling the previously defined _save() function.
+            _save()
Index: venv/Lib/site-packages/django/contrib/gis/utils/ogrinfo.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/gis/utils/ogrinfo.py b/venv/Lib/site-packages/django/contrib/gis/utils/ogrinfo.py
new file mode 100644
--- /dev/null	(date 1617030484469)
+++ b/venv/Lib/site-packages/django/contrib/gis/utils/ogrinfo.py	(date 1617030484469)
@@ -0,0 +1,51 @@
+"""
+This module includes some utility functions for inspecting the layout
+of a GDAL data source -- the functionality is analogous to the output
+produced by the `ogrinfo` utility.
+"""
+
+from django.contrib.gis.gdal import DataSource
+from django.contrib.gis.gdal.geometries import GEO_CLASSES
+
+
+def ogrinfo(data_source, num_features=10):
+    """
+    Walk the available layers in the supplied `data_source`, displaying
+    the fields for the first `num_features` features.
+    """
+
+    # Checking the parameters.
+    if isinstance(data_source, str):
+        data_source = DataSource(data_source)
+    elif isinstance(data_source, DataSource):
+        pass
+    else:
+        raise Exception('Data source parameter must be a string or a DataSource object.')
+
+    for i, layer in enumerate(data_source):
+        print("data source : %s" % data_source.name)
+        print("==== layer %s" % i)
+        print("  shape type: %s" % GEO_CLASSES[layer.geom_type.num].__name__)
+        print("  # features: %s" % len(layer))
+        print("         srs: %s" % layer.srs)
+        extent_tup = layer.extent.tuple
+        print("      extent: %s - %s" % (extent_tup[0:2], extent_tup[2:4]))
+        print("Displaying the first %s features ====" % num_features)
+
+        width = max(*map(len, layer.fields))
+        fmt = " %%%ss: %%s" % width
+        for j, feature in enumerate(layer[:num_features]):
+            print("=== Feature %s" % j)
+            for fld_name in layer.fields:
+                type_name = feature[fld_name].type_name
+                output = fmt % (fld_name, type_name)
+                val = feature.get(fld_name)
+                if val:
+                    if isinstance(val, str):
+                        val_fmt = ' ("%s")'
+                    else:
+                        val_fmt = ' (%s)'
+                    output += val_fmt % val
+                else:
+                    output += ' (None)'
+                print(output)
Index: venv/Lib/site-packages/django/contrib/gis/utils/ogrinspect.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/gis/utils/ogrinspect.py b/venv/Lib/site-packages/django/contrib/gis/utils/ogrinspect.py
new file mode 100644
--- /dev/null	(date 1617030484469)
+++ b/venv/Lib/site-packages/django/contrib/gis/utils/ogrinspect.py	(date 1617030484469)
@@ -0,0 +1,237 @@
+"""
+This module is for inspecting OGR data sources and generating either
+models for GeoDjango and/or mapping dictionaries for use with the
+`LayerMapping` utility.
+"""
+from django.contrib.gis.gdal import DataSource
+from django.contrib.gis.gdal.field import (
+    OFTDate, OFTDateTime, OFTInteger, OFTInteger64, OFTReal, OFTString,
+    OFTTime,
+)
+
+
+def mapping(data_source, geom_name='geom', layer_key=0, multi_geom=False):
+    """
+    Given a DataSource, generate a dictionary that may be used
+    for invoking the LayerMapping utility.
+
+    Keyword Arguments:
+     `geom_name` => The name of the geometry field to use for the model.
+
+     `layer_key` => The key for specifying which layer in the DataSource to use;
+       defaults to 0 (the first layer).  May be an integer index or a string
+       identifier for the layer.
+
+     `multi_geom` => Boolean (default: False) - specify as multigeometry.
+    """
+    if isinstance(data_source, str):
+        # Instantiating the DataSource from the string.
+        data_source = DataSource(data_source)
+    elif isinstance(data_source, DataSource):
+        pass
+    else:
+        raise TypeError('Data source parameter must be a string or a DataSource object.')
+
+    # Creating the dictionary.
+    _mapping = {}
+
+    # Generating the field name for each field in the layer.
+    for field in data_source[layer_key].fields:
+        mfield = field.lower()
+        if mfield[-1:] == '_':
+            mfield += 'field'
+        _mapping[mfield] = field
+    gtype = data_source[layer_key].geom_type
+    if multi_geom:
+        gtype.to_multi()
+    _mapping[geom_name] = str(gtype).upper()
+    return _mapping
+
+
+def ogrinspect(*args, **kwargs):
+    """
+    Given a data source (either a string or a DataSource object) and a string
+    model name this function will generate a GeoDjango model.
+
+    Usage:
+
+    >>> from django.contrib.gis.utils import ogrinspect
+    >>> ogrinspect('/path/to/shapefile.shp','NewModel')
+
+    ...will print model definition to stout
+
+    or put this in a Python script and use to redirect the output to a new
+    model like:
+
+    $ python generate_model.py > myapp/models.py
+
+    # generate_model.py
+    from django.contrib.gis.utils import ogrinspect
+    shp_file = 'data/mapping_hacks/world_borders.shp'
+    model_name = 'WorldBorders'
+
+    print(ogrinspect(shp_file, model_name, multi_geom=True, srid=4326,
+                     geom_name='shapes', blank=True))
+
+    Required Arguments
+     `datasource` => string or DataSource object to file pointer
+
+     `model name` => string of name of new model class to create
+
+    Optional Keyword Arguments
+     `geom_name` => For specifying the model name for the Geometry Field.
+       Otherwise will default to `geom`
+
+     `layer_key` => The key for specifying which layer in the DataSource to use;
+       defaults to 0 (the first layer).  May be an integer index or a string
+       identifier for the layer.
+
+     `srid` => The SRID to use for the Geometry Field.  If it can be determined,
+       the SRID of the datasource is used.
+
+     `multi_geom` => Boolean (default: False) - specify as multigeometry.
+
+     `name_field` => String - specifies a field name to return for the
+       __str__() method (which will be generated if specified).
+
+     `imports` => Boolean (default: True) - set to False to omit the
+       `from django.contrib.gis.db import models` code from the
+       autogenerated models thus avoiding duplicated imports when building
+       more than one model by batching ogrinspect()
+
+     `decimal` => Boolean or sequence (default: False).  When set to True
+       all generated model fields corresponding to the `OFTReal` type will
+       be `DecimalField` instead of `FloatField`.  A sequence of specific
+       field names to generate as `DecimalField` may also be used.
+
+     `blank` => Boolean or sequence (default: False).  When set to True all
+       generated model fields will have `blank=True`.  If the user wants to
+       give specific fields to have blank, then a list/tuple of OGR field
+       names may be used.
+
+     `null` => Boolean (default: False) - When set to True all generated
+       model fields will have `null=True`.  If the user wants to specify
+       give specific fields to have null, then a list/tuple of OGR field
+       names may be used.
+
+    Note: Call the _ogrinspect() helper to do the heavy lifting.
+    """
+    return '\n'.join(_ogrinspect(*args, **kwargs))
+
+
+def _ogrinspect(data_source, model_name, geom_name='geom', layer_key=0, srid=None,
+                multi_geom=False, name_field=None, imports=True,
+                decimal=False, blank=False, null=False):
+    """
+    Helper routine for `ogrinspect` that generates GeoDjango models corresponding
+    to the given data source.  See the `ogrinspect` docstring for more details.
+    """
+    # Getting the DataSource
+    if isinstance(data_source, str):
+        data_source = DataSource(data_source)
+    elif isinstance(data_source, DataSource):
+        pass
+    else:
+        raise TypeError('Data source parameter must be a string or a DataSource object.')
+
+    # Getting the layer corresponding to the layer key and getting
+    # a string listing of all OGR fields in the Layer.
+    layer = data_source[layer_key]
+    ogr_fields = layer.fields
+
+    # Creating lists from the `null`, `blank`, and `decimal`
+    # keyword arguments.
+    def process_kwarg(kwarg):
+        if isinstance(kwarg, (list, tuple)):
+            return [s.lower() for s in kwarg]
+        elif kwarg:
+            return [s.lower() for s in ogr_fields]
+        else:
+            return []
+    null_fields = process_kwarg(null)
+    blank_fields = process_kwarg(blank)
+    decimal_fields = process_kwarg(decimal)
+
+    # Gets the `null` and `blank` keywords for the given field name.
+    def get_kwargs_str(field_name):
+        kwlist = []
+        if field_name.lower() in null_fields:
+            kwlist.append('null=True')
+        if field_name.lower() in blank_fields:
+            kwlist.append('blank=True')
+        if kwlist:
+            return ', ' + ', '.join(kwlist)
+        else:
+            return ''
+
+    # For those wishing to disable the imports.
+    if imports:
+        yield '# This is an auto-generated Django model module created by ogrinspect.'
+        yield 'from django.contrib.gis.db import models'
+        yield ''
+        yield ''
+
+    yield 'class %s(models.Model):' % model_name
+
+    for field_name, width, precision, field_type in zip(
+            ogr_fields, layer.field_widths, layer.field_precisions, layer.field_types):
+        # The model field name.
+        mfield = field_name.lower()
+        if mfield[-1:] == '_':
+            mfield += 'field'
+
+        # Getting the keyword args string.
+        kwargs_str = get_kwargs_str(field_name)
+
+        if field_type is OFTReal:
+            # By default OFTReals are mapped to `FloatField`, however, they
+            # may also be mapped to `DecimalField` if specified in the
+            # `decimal` keyword.
+            if field_name.lower() in decimal_fields:
+                yield '    %s = models.DecimalField(max_digits=%d, decimal_places=%d%s)' % (
+                    mfield, width, precision, kwargs_str
+                )
+            else:
+                yield '    %s = models.FloatField(%s)' % (mfield, kwargs_str[2:])
+        elif field_type is OFTInteger:
+            yield '    %s = models.IntegerField(%s)' % (mfield, kwargs_str[2:])
+        elif field_type is OFTInteger64:
+            yield '    %s = models.BigIntegerField(%s)' % (mfield, kwargs_str[2:])
+        elif field_type is OFTString:
+            yield '    %s = models.CharField(max_length=%s%s)' % (mfield, width, kwargs_str)
+        elif field_type is OFTDate:
+            yield '    %s = models.DateField(%s)' % (mfield, kwargs_str[2:])
+        elif field_type is OFTDateTime:
+            yield '    %s = models.DateTimeField(%s)' % (mfield, kwargs_str[2:])
+        elif field_type is OFTTime:
+            yield '    %s = models.TimeField(%s)' % (mfield, kwargs_str[2:])
+        else:
+            raise TypeError('Unknown field type %s in %s' % (field_type, mfield))
+
+    # TODO: Autodetection of multigeometry types (see #7218).
+    gtype = layer.geom_type
+    if multi_geom:
+        gtype.to_multi()
+    geom_field = gtype.django
+
+    # Setting up the SRID keyword string.
+    if srid is None:
+        if layer.srs is None:
+            srid_str = 'srid=-1'
+        else:
+            srid = layer.srs.srid
+            if srid is None:
+                srid_str = 'srid=-1'
+            elif srid == 4326:
+                # WGS84 is already the default.
+                srid_str = ''
+            else:
+                srid_str = 'srid=%s' % srid
+    else:
+        srid_str = 'srid=%s' % srid
+
+    yield '    %s = models.%s(%s)' % (geom_name, geom_field, srid_str)
+
+    if name_field:
+        yield ''
+        yield '    def __str__(self): return self.%s' % name_field
Index: venv/Lib/site-packages/django/contrib/gis/utils/srs.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/gis/utils/srs.py b/venv/Lib/site-packages/django/contrib/gis/utils/srs.py
new file mode 100644
--- /dev/null	(date 1617030484470)
+++ b/venv/Lib/site-packages/django/contrib/gis/utils/srs.py	(date 1617030484470)
@@ -0,0 +1,76 @@
+from django.contrib.gis.gdal import SpatialReference
+from django.db import DEFAULT_DB_ALIAS, connections
+
+
+def add_srs_entry(srs, auth_name='EPSG', auth_srid=None, ref_sys_name=None,
+                  database=None):
+    """
+    Take a GDAL SpatialReference system and add its information to the
+    `spatial_ref_sys` table of the spatial backend. Doing this enables
+    database-level spatial transformations for the backend.  Thus, this utility
+    is useful for adding spatial reference systems not included by default with
+    the backend:
+
+    >>> from django.contrib.gis.utils import add_srs_entry
+    >>> add_srs_entry(3857)
+
+    Keyword Arguments:
+     auth_name:
+       This keyword may be customized with the value of the `auth_name` field.
+       Defaults to 'EPSG'.
+
+     auth_srid:
+       This keyword may be customized with the value of the `auth_srid` field.
+       Defaults to the SRID determined by GDAL.
+
+     ref_sys_name:
+       For SpatiaLite users only, sets the value of the `ref_sys_name` field.
+       Defaults to the name determined by GDAL.
+
+     database:
+      The name of the database connection to use; the default is the value
+      of `django.db.DEFAULT_DB_ALIAS` (at the time of this writing, its value
+      is 'default').
+    """
+    database = database or DEFAULT_DB_ALIAS
+    connection = connections[database]
+
+    if not hasattr(connection.ops, 'spatial_version'):
+        raise Exception('The `add_srs_entry` utility only works '
+                        'with spatial backends.')
+    if not connection.features.supports_add_srs_entry:
+        raise Exception('This utility does not support your database backend.')
+    SpatialRefSys = connection.ops.spatial_ref_sys()
+
+    # If argument is not a `SpatialReference` instance, use it as parameter
+    # to construct a `SpatialReference` instance.
+    if not isinstance(srs, SpatialReference):
+        srs = SpatialReference(srs)
+
+    if srs.srid is None:
+        raise Exception('Spatial reference requires an SRID to be '
+                        'compatible with the spatial backend.')
+
+    # Initializing the keyword arguments dictionary for both PostGIS
+    # and SpatiaLite.
+    kwargs = {
+        'srid': srs.srid,
+        'auth_name': auth_name,
+        'auth_srid': auth_srid or srs.srid,
+        'proj4text': srs.proj4,
+    }
+    # Backend-specific fields for the SpatialRefSys model.
+    srs_field_names = {f.name for f in SpatialRefSys._meta.get_fields()}
+    if 'srtext' in srs_field_names:
+        kwargs['srtext'] = srs.wkt
+    if 'ref_sys_name' in srs_field_names:
+        # SpatiaLite specific
+        kwargs['ref_sys_name'] = ref_sys_name or srs.name
+
+    # Creating the spatial_ref_sys model.
+    try:
+        # Try getting via SRID only, because using all kwargs may
+        # differ from exact wkt/proj in database.
+        SpatialRefSys.objects.using(database).get(srid=srs.srid)
+    except SpatialRefSys.DoesNotExist:
+        SpatialRefSys.objects.using(database).create(**kwargs)
Index: venv/Lib/site-packages/django/contrib/gis/utils/__init__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/gis/utils/__init__.py b/venv/Lib/site-packages/django/contrib/gis/utils/__init__.py
new file mode 100644
--- /dev/null	(date 1617030484468)
+++ b/venv/Lib/site-packages/django/contrib/gis/utils/__init__.py	(date 1617030484468)
@@ -0,0 +1,16 @@
+"""
+ This module contains useful utilities for GeoDjango.
+"""
+from django.contrib.gis.utils.ogrinfo import ogrinfo  # NOQA
+from django.contrib.gis.utils.ogrinspect import mapping, ogrinspect  # NOQA
+from django.contrib.gis.utils.srs import add_srs_entry  # NOQA
+from django.core.exceptions import ImproperlyConfigured
+
+try:
+    # LayerMapping requires DJANGO_SETTINGS_MODULE to be set,
+    # and ImproperlyConfigured is raised if that's not the case.
+    from django.contrib.gis.utils.layermapping import (  # NOQA
+        LayerMapError, LayerMapping,
+    )
+except ImproperlyConfigured:
+    pass
Index: venv/Lib/site-packages/django/contrib/gis/geoip2/base.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/gis/geoip2/base.py b/venv/Lib/site-packages/django/contrib/gis/geoip2/base.py
new file mode 100644
--- /dev/null	(date 1617030484365)
+++ b/venv/Lib/site-packages/django/contrib/gis/geoip2/base.py	(date 1617030484365)
@@ -0,0 +1,227 @@
+import socket
+
+import geoip2.database
+
+from django.conf import settings
+from django.core.exceptions import ValidationError
+from django.core.validators import validate_ipv46_address
+from django.utils._os import to_path
+
+from .resources import City, Country
+
+# Creating the settings dictionary with any settings, if needed.
+GEOIP_SETTINGS = {
+    'GEOIP_PATH': getattr(settings, 'GEOIP_PATH', None),
+    'GEOIP_CITY': getattr(settings, 'GEOIP_CITY', 'GeoLite2-City.mmdb'),
+    'GEOIP_COUNTRY': getattr(settings, 'GEOIP_COUNTRY', 'GeoLite2-Country.mmdb'),
+}
+
+
+class GeoIP2Exception(Exception):
+    pass
+
+
+class GeoIP2:
+    # The flags for GeoIP memory caching.
+    # Try MODE_MMAP_EXT, MODE_MMAP, MODE_FILE in that order.
+    MODE_AUTO = 0
+    # Use the C extension with memory map.
+    MODE_MMAP_EXT = 1
+    # Read from memory map. Pure Python.
+    MODE_MMAP = 2
+    # Read database as standard file. Pure Python.
+    MODE_FILE = 4
+    # Load database into memory. Pure Python.
+    MODE_MEMORY = 8
+    cache_options = frozenset((MODE_AUTO, MODE_MMAP_EXT, MODE_MMAP, MODE_FILE, MODE_MEMORY))
+
+    # Paths to the city & country binary databases.
+    _city_file = ''
+    _country_file = ''
+
+    # Initially, pointers to GeoIP file references are NULL.
+    _city = None
+    _country = None
+
+    def __init__(self, path=None, cache=0, country=None, city=None):
+        """
+        Initialize the GeoIP object. No parameters are required to use default
+        settings. Keyword arguments may be passed in to customize the locations
+        of the GeoIP datasets.
+
+        * path: Base directory to where GeoIP data is located or the full path
+            to where the city or country data files (*.mmdb) are located.
+            Assumes that both the city and country data sets are located in
+            this directory; overrides the GEOIP_PATH setting.
+
+        * cache: The cache settings when opening up the GeoIP datasets. May be
+            an integer in (0, 1, 2, 4, 8) corresponding to the MODE_AUTO,
+            MODE_MMAP_EXT, MODE_MMAP, MODE_FILE, and MODE_MEMORY,
+            `GeoIPOptions` C API settings,  respectively. Defaults to 0,
+            meaning MODE_AUTO.
+
+        * country: The name of the GeoIP country data file. Defaults to
+            'GeoLite2-Country.mmdb'; overrides the GEOIP_COUNTRY setting.
+
+        * city: The name of the GeoIP city data file. Defaults to
+            'GeoLite2-City.mmdb'; overrides the GEOIP_CITY setting.
+        """
+        # Checking the given cache option.
+        if cache in self.cache_options:
+            self._cache = cache
+        else:
+            raise GeoIP2Exception('Invalid GeoIP caching option: %s' % cache)
+
+        # Getting the GeoIP data path.
+        path = path or GEOIP_SETTINGS['GEOIP_PATH']
+        if not path:
+            raise GeoIP2Exception('GeoIP path must be provided via parameter or the GEOIP_PATH setting.')
+
+        path = to_path(path)
+        if path.is_dir():
+            # Constructing the GeoIP database filenames using the settings
+            # dictionary. If the database files for the GeoLite country
+            # and/or city datasets exist, then try to open them.
+            country_db = path / (country or GEOIP_SETTINGS['GEOIP_COUNTRY'])
+            if country_db.is_file():
+                self._country = geoip2.database.Reader(str(country_db), mode=cache)
+                self._country_file = country_db
+
+            city_db = path / (city or GEOIP_SETTINGS['GEOIP_CITY'])
+            if city_db.is_file():
+                self._city = geoip2.database.Reader(str(city_db), mode=cache)
+                self._city_file = city_db
+            if not self._reader:
+                raise GeoIP2Exception('Could not load a database from %s.' % path)
+        elif path.is_file():
+            # Otherwise, some detective work will be needed to figure out
+            # whether the given database path is for the GeoIP country or city
+            # databases.
+            reader = geoip2.database.Reader(str(path), mode=cache)
+            db_type = reader.metadata().database_type
+
+            if db_type.endswith('City'):
+                # GeoLite City database detected.
+                self._city = reader
+                self._city_file = path
+            elif db_type.endswith('Country'):
+                # GeoIP Country database detected.
+                self._country = reader
+                self._country_file = path
+            else:
+                raise GeoIP2Exception('Unable to recognize database edition: %s' % db_type)
+        else:
+            raise GeoIP2Exception('GeoIP path must be a valid file or directory.')
+
+    @property
+    def _reader(self):
+        return self._country or self._city
+
+    @property
+    def _country_or_city(self):
+        if self._country:
+            return self._country.country
+        else:
+            return self._city.city
+
+    def __del__(self):
+        # Cleanup any GeoIP file handles lying around.
+        if self._reader:
+            self._reader.close()
+
+    def __repr__(self):
+        meta = self._reader.metadata()
+        version = '[v%s.%s]' % (meta.binary_format_major_version, meta.binary_format_minor_version)
+        return '<%(cls)s %(version)s _country_file="%(country)s", _city_file="%(city)s">' % {
+            'cls': self.__class__.__name__,
+            'version': version,
+            'country': self._country_file,
+            'city': self._city_file,
+        }
+
+    def _check_query(self, query, country=False, city=False, city_or_country=False):
+        "Check the query and database availability."
+        # Making sure a string was passed in for the query.
+        if not isinstance(query, str):
+            raise TypeError('GeoIP query must be a string, not type %s' % type(query).__name__)
+
+        # Extra checks for the existence of country and city databases.
+        if city_or_country and not (self._country or self._city):
+            raise GeoIP2Exception('Invalid GeoIP country and city data files.')
+        elif country and not self._country:
+            raise GeoIP2Exception('Invalid GeoIP country data file: %s' % self._country_file)
+        elif city and not self._city:
+            raise GeoIP2Exception('Invalid GeoIP city data file: %s' % self._city_file)
+
+        # Return the query string back to the caller. GeoIP2 only takes IP addresses.
+        try:
+            validate_ipv46_address(query)
+        except ValidationError:
+            query = socket.gethostbyname(query)
+
+        return query
+
+    def city(self, query):
+        """
+        Return a dictionary of city information for the given IP address or
+        Fully Qualified Domain Name (FQDN). Some information in the dictionary
+        may be undefined (None).
+        """
+        enc_query = self._check_query(query, city=True)
+        return City(self._city.city(enc_query))
+
+    def country_code(self, query):
+        "Return the country code for the given IP Address or FQDN."
+        enc_query = self._check_query(query, city_or_country=True)
+        return self.country(enc_query)['country_code']
+
+    def country_name(self, query):
+        "Return the country name for the given IP Address or FQDN."
+        enc_query = self._check_query(query, city_or_country=True)
+        return self.country(enc_query)['country_name']
+
+    def country(self, query):
+        """
+        Return a dictionary with the country code and name when given an
+        IP address or a Fully Qualified Domain Name (FQDN). For example, both
+        '24.124.1.80' and 'djangoproject.com' are valid parameters.
+        """
+        # Returning the country code and name
+        enc_query = self._check_query(query, city_or_country=True)
+        return Country(self._country_or_city(enc_query))
+
+    # #### Coordinate retrieval routines ####
+    def coords(self, query, ordering=('longitude', 'latitude')):
+        cdict = self.city(query)
+        if cdict is None:
+            return None
+        else:
+            return tuple(cdict[o] for o in ordering)
+
+    def lon_lat(self, query):
+        "Return a tuple of the (longitude, latitude) for the given query."
+        return self.coords(query)
+
+    def lat_lon(self, query):
+        "Return a tuple of the (latitude, longitude) for the given query."
+        return self.coords(query, ('latitude', 'longitude'))
+
+    def geos(self, query):
+        "Return a GEOS Point object for the given query."
+        ll = self.lon_lat(query)
+        if ll:
+            from django.contrib.gis.geos import Point
+            return Point(ll, srid=4326)
+        else:
+            return None
+
+    # #### GeoIP Database Information Routines ####
+    @property
+    def info(self):
+        "Return information about the GeoIP library and databases in use."
+        meta = self._reader.metadata()
+        return 'GeoIP Library:\n\t%s.%s\n' % (meta.binary_format_major_version, meta.binary_format_minor_version)
+
+    @classmethod
+    def open(cls, full_path, cache):
+        return GeoIP2(full_path, cache)
Index: venv/Lib/site-packages/django/contrib/gis/geoip2/resources.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/gis/geoip2/resources.py b/venv/Lib/site-packages/django/contrib/gis/geoip2/resources.py
new file mode 100644
--- /dev/null	(date 1617030484366)
+++ b/venv/Lib/site-packages/django/contrib/gis/geoip2/resources.py	(date 1617030484366)
@@ -0,0 +1,22 @@
+def City(response):
+    return {
+        'city': response.city.name,
+        'continent_code': response.continent.code,
+        'continent_name': response.continent.name,
+        'country_code': response.country.iso_code,
+        'country_name': response.country.name,
+        'dma_code': response.location.metro_code,
+        'is_in_european_union': response.country.is_in_european_union,
+        'latitude': response.location.latitude,
+        'longitude': response.location.longitude,
+        'postal_code': response.postal.code,
+        'region': response.subdivisions[0].iso_code if response.subdivisions else None,
+        'time_zone': response.location.time_zone,
+    }
+
+
+def Country(response):
+    return {
+        'country_code': response.country.iso_code,
+        'country_name': response.country.name,
+    }
Index: venv/Lib/site-packages/django/contrib/gis/geoip2/__init__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/django/contrib/gis/geoip2/__init__.py b/venv/Lib/site-packages/django/contrib/gis/geoip2/__init__.py
new file mode 100644
--- /dev/null	(date 1617030484365)
+++ b/venv/Lib/site-packages/django/contrib/gis/geoip2/__init__.py	(date 1617030484365)
@@ -0,0 +1,23 @@
+"""
+This module houses the GeoIP2 object, a wrapper for the MaxMind GeoIP2(R)
+Python API (https://geoip2.readthedocs.io/). This is an alternative to the
+Python GeoIP2 interface provided by MaxMind.
+
+GeoIP(R) is a registered trademark of MaxMind, Inc.
+
+For IP-based geolocation, this module requires the GeoLite2 Country and City
+datasets, in binary format (CSV will not work!). The datasets may be
+downloaded from MaxMind at http://dev.maxmind.com/geoip/geoip2/geolite2/.
+Grab GeoLite2-Country.mmdb.gz and GeoLite2-City.mmdb.gz, and unzip them in the
+directory corresponding to settings.GEOIP_PATH.
+"""
+__all__ = ['HAS_GEOIP2']
+
+try:
+    import geoip2  # NOQA
+except ImportError:
+    HAS_GEOIP2 = False
+else:
+    from .base import GeoIP2, GeoIP2Exception
+    HAS_GEOIP2 = True
+    __all__ += ['GeoIP2', 'GeoIP2Exception']
diff --git a/venv/Lib/site-packages/django/conf/locale/fy/__init__.py b/venv/Lib/site-packages/django/conf/locale/fy/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/ga/__init__.py b/venv/Lib/site-packages/django/conf/locale/ga/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/gd/__init__.py b/venv/Lib/site-packages/django/conf/locale/gd/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/gl/__init__.py b/venv/Lib/site-packages/django/conf/locale/gl/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/contrib/gis/serializers/__init__.py b/venv/Lib/site-packages/django/contrib/gis/serializers/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/he/__init__.py b/venv/Lib/site-packages/django/conf/locale/he/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/hi/__init__.py b/venv/Lib/site-packages/django/conf/locale/hi/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/hr/__init__.py b/venv/Lib/site-packages/django/conf/locale/hr/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/hu/__init__.py b/venv/Lib/site-packages/django/conf/locale/hu/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/id/__init__.py b/venv/Lib/site-packages/django/conf/locale/id/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/ig/__init__.py b/venv/Lib/site-packages/django/conf/locale/ig/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/is/__init__.py b/venv/Lib/site-packages/django/conf/locale/is/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/it/__init__.py b/venv/Lib/site-packages/django/conf/locale/it/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/ja/__init__.py b/venv/Lib/site-packages/django/conf/locale/ja/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/ka/__init__.py b/venv/Lib/site-packages/django/conf/locale/ka/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/km/__init__.py b/venv/Lib/site-packages/django/conf/locale/km/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/kn/__init__.py b/venv/Lib/site-packages/django/conf/locale/kn/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/ko/__init__.py b/venv/Lib/site-packages/django/conf/locale/ko/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/ky/__init__.py b/venv/Lib/site-packages/django/conf/locale/ky/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/lt/__init__.py b/venv/Lib/site-packages/django/conf/locale/lt/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/lv/__init__.py b/venv/Lib/site-packages/django/conf/locale/lv/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/mk/__init__.py b/venv/Lib/site-packages/django/conf/locale/mk/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/ml/__init__.py b/venv/Lib/site-packages/django/conf/locale/ml/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/mn/__init__.py b/venv/Lib/site-packages/django/conf/locale/mn/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/nb/__init__.py b/venv/Lib/site-packages/django/conf/locale/nb/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/nl/__init__.py b/venv/Lib/site-packages/django/conf/locale/nl/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/nn/__init__.py b/venv/Lib/site-packages/django/conf/locale/nn/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/contrib/auth/handlers/__init__.py b/venv/Lib/site-packages/django/contrib/auth/handlers/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/pl/__init__.py b/venv/Lib/site-packages/django/conf/locale/pl/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/pt/__init__.py b/venv/Lib/site-packages/django/conf/locale/pt/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/ro/__init__.py b/venv/Lib/site-packages/django/conf/locale/ro/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/ru/__init__.py b/venv/Lib/site-packages/django/conf/locale/ru/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/contrib/auth/migrations/__init__.py b/venv/Lib/site-packages/django/contrib/auth/migrations/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/sk/__init__.py b/venv/Lib/site-packages/django/conf/locale/sk/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/sl/__init__.py b/venv/Lib/site-packages/django/conf/locale/sl/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/sq/__init__.py b/venv/Lib/site-packages/django/conf/locale/sq/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/sr/__init__.py b/venv/Lib/site-packages/django/conf/locale/sr/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/sv/__init__.py b/venv/Lib/site-packages/django/conf/locale/sv/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/ta/__init__.py b/venv/Lib/site-packages/django/conf/locale/ta/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/contrib/admin/views/__init__.py b/venv/Lib/site-packages/django/contrib/admin/views/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/te/__init__.py b/venv/Lib/site-packages/django/conf/locale/te/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/tg/__init__.py b/venv/Lib/site-packages/django/conf/locale/tg/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/th/__init__.py b/venv/Lib/site-packages/django/conf/locale/th/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/tk/__init__.py b/venv/Lib/site-packages/django/conf/locale/tk/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/tr/__init__.py b/venv/Lib/site-packages/django/conf/locale/tr/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/uk/__init__.py b/venv/Lib/site-packages/django/conf/locale/uk/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/uz/__init__.py b/venv/Lib/site-packages/django/conf/locale/uz/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/vi/__init__.py b/venv/Lib/site-packages/django/conf/locale/vi/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/ar_DZ/__init__.py b/venv/Lib/site-packages/django/conf/locale/ar_DZ/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/de_CH/__init__.py b/venv/Lib/site-packages/django/conf/locale/de_CH/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/en_AU/__init__.py b/venv/Lib/site-packages/django/conf/locale/en_AU/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/en_GB/__init__.py b/venv/Lib/site-packages/django/conf/locale/en_GB/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/es_AR/__init__.py b/venv/Lib/site-packages/django/conf/locale/es_AR/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/es_CO/__init__.py b/venv/Lib/site-packages/django/conf/locale/es_CO/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/es_MX/__init__.py b/venv/Lib/site-packages/django/conf/locale/es_MX/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/es_NI/__init__.py b/venv/Lib/site-packages/django/conf/locale/es_NI/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/es_PR/__init__.py b/venv/Lib/site-packages/django/conf/locale/es_PR/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/pt_BR/__init__.py b/venv/Lib/site-packages/django/conf/locale/pt_BR/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/sr_Latn/__init__.py b/venv/Lib/site-packages/django/conf/locale/sr_Latn/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/zh_Hans/__init__.py b/venv/Lib/site-packages/django/conf/locale/zh_Hans/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/conf/locale/zh_Hant/__init__.py b/venv/Lib/site-packages/django/conf/locale/zh_Hant/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/contrib/admin/migrations/__init__.py b/venv/Lib/site-packages/django/contrib/admin/migrations/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/core/cache/backends/__init__.py b/venv/Lib/site-packages/django/core/cache/backends/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/contrib/admin/templatetags/__init__.py b/venv/Lib/site-packages/django/contrib/admin/templatetags/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/core/checks/security/__init__.py b/venv/Lib/site-packages/django/core/checks/security/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/core/checks/compatibility/__init__.py b/venv/Lib/site-packages/django/core/checks/compatibility/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/django/contrib/gis/db/__init__.py b/venv/Lib/site-packages/django/contrib/gis/db/__init__.py
new file mode 100644
